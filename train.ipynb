{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:36.021530Z",
     "start_time": "2025-01-17T16:18:34.605173Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "# scikit-learn scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def month_range(start, end):\n",
    "    \"\"\"\n",
    "    Return a list of monthly dates (as strings 'YYYY-MM-01')\n",
    "    from start to end inclusive.\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    cur = datetime.strptime(start, \"%Y-%m-%d\")\n",
    "    stop = datetime.strptime(end, \"%Y-%m-%d\")\n",
    "    while cur <= stop:\n",
    "        dates.append(cur.strftime(\"%Y-%m-01\"))\n",
    "        # move forward one month\n",
    "        cur += relativedelta(months=1)\n",
    "    return dates\n",
    "\n",
    "def drop_all_nan_columns_before_cutoff(arr, cutoff_idx, table_name):\n",
    "    \"\"\"\n",
    "    Drop the columns that are all NaNs before or at the cutoff index.\n",
    "    :param arr: np.array of shape (n, m)\n",
    "    :return: np.array of shape (n, m') where m' <= m\n",
    "    \"\"\"\n",
    "    mask = np.all(np.isnan(arr[:cutoff_idx, :]), axis=0)\n",
    "    if mask.sum() > 0:\n",
    "        print(f\"Dropping {mask.sum()} columns with all NaNs before cutoff for table {table_name}\")\n",
    "\n",
    "    return arr[:, ~mask]\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "def read_and_scale_tables(\n",
    "        csv_file_paths,\n",
    "        meta_file_paths,\n",
    "        start_date=\"1960-01-01\",\n",
    "        end_date=\"2024-01-01\",\n",
    "        train_cutoff_str=\"2018-01-01\",\n",
    "        drop_cutoff_str=\"2004-01-01\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads each CSV data file and corresponding CSV meta file,\n",
    "    aligns data to a monthly timeline, scales the data,\n",
    "    and returns:\n",
    "      - table_data_dict: dict[table_name] -> np.array of shape (num_months, k_i)\n",
    "      - meta_data_dict: dict[table_name] -> dict[col_index -> freq_str]\n",
    "      - scalers: dict[table_name] -> a fitted StandardScaler\n",
    "      - monthly_dates: list of monthly date strings\n",
    "\n",
    "    :param csv_file_paths: list of str (data CSVs, one per table)\n",
    "    :param meta_file_paths: list of str (metadata CSVs, same length as above)\n",
    "    :param start_date: str, earliest date\n",
    "    :param end_date: str, latest date\n",
    "    :param train_cutoff_str: str, date boundary for training\n",
    "    :param drop_cutoff_str: str, date boundary for dropping columns with all NaNs\n",
    "    \"\"\"\n",
    "    assert len(csv_file_paths) == len(meta_file_paths), \\\n",
    "        \"Must have matching data and meta files\"\n",
    "\n",
    "    monthly_dates = month_range(start_date, end_date)\n",
    "    date_to_idx = {d: i for i, d in enumerate(monthly_dates)}\n",
    "    num_months = len(monthly_dates)\n",
    "\n",
    "    train_cutoff_idx = date_to_idx[train_cutoff_str]\n",
    "\n",
    "    table_data_dict = {}\n",
    "    meta_data_dict = {}\n",
    "    scalers = {}\n",
    "\n",
    "    for data_path, meta_path in tqdm(zip(csv_file_paths, meta_file_paths), desc=\"Reading and scaling tables\", total=len(csv_file_paths)):\n",
    "        table_name = data_path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "\n",
    "        # Read the data CSV\n",
    "        df = pd.read_csv(data_path)\n",
    "        feature_cols = [c for c in df.columns if c != \"DATE_PARSED\"]\n",
    "\n",
    "        # Read the meta CSV\n",
    "        df_meta = pd.read_csv(meta_path)\n",
    "\n",
    "        # Create a dictionary col_index -> freq_str\n",
    "        col_to_freq = {}\n",
    "        for col_index, col_name in enumerate(feature_cols):\n",
    "            row_meta = df_meta[df_meta['TITLE_FR'] == col_name]\n",
    "            if len(row_meta) == 0:\n",
    "                raise ValueError(f\"Could not find metadata for column {col_name}\")\n",
    "            else:\n",
    "                freq_str = row_meta['FREQ'].values[0]\n",
    "            col_to_freq[col_index] = freq_str\n",
    "\n",
    "        # Now create array_data (num_months, k_i)\n",
    "        array_data = np.full((num_months, len(feature_cols)), np.nan, dtype=np.float32)\n",
    "        for _, row in df.iterrows():\n",
    "            date_str = str(row[\"DATE_PARSED\"])\n",
    "            if date_str in date_to_idx:\n",
    "                idx = date_to_idx[date_str]\n",
    "                array_data[idx] = row[feature_cols].values.astype(np.float32)\n",
    "\n",
    "        # Optionally drop columns that are all NaN up to the cutoff, this should have been done in the ETL\n",
    "        array_data = drop_all_nan_columns_before_cutoff(array_data, train_cutoff_idx, table_name)\n",
    "\n",
    "        # The dropping above might reduce shape from (num_months, k_i) to fewer columns\n",
    "        # so we also need to shrink col_to_freq accordingly:\n",
    "        keep_mask = ~np.all(np.isnan(array_data[:train_cutoff_idx, :]), axis=0)\n",
    "        # new frequency map\n",
    "        old_col_indices = np.where(keep_mask)[0]\n",
    "        new_col_to_freq = {}\n",
    "        for new_i, old_i in enumerate(old_col_indices):\n",
    "            new_col_to_freq[new_i] = col_to_freq[old_i]\n",
    "        col_to_freq = new_col_to_freq\n",
    "\n",
    "        # Fit StandardScaler on training portion (ignoring NaNs by filling w/ mean)\n",
    "        scaler = StandardScaler()\n",
    "        train_data = array_data[:train_cutoff_idx]  # shape (train_cutoff_idx, k_i')\n",
    "\n",
    "        col_means = np.nanmean(train_data, axis=0)\n",
    "        train_data_copy = train_data.copy()\n",
    "        for c in range(train_data_copy.shape[1]):\n",
    "            np.place(train_data_copy[:, c], np.isnan(train_data_copy[:, c]), col_means[c])\n",
    "\n",
    "        scaler.fit(train_data_copy)\n",
    "\n",
    "        # Transform entire array, ignoring NaNs by temp-filling them\n",
    "        array_copy = array_data.copy()\n",
    "        nan_mask = np.isnan(array_copy)\n",
    "        array_copy[nan_mask] = 0.0\n",
    "        scaled_data = scaler.transform(array_copy)\n",
    "        scaled_data[nan_mask] = np.nan  # put NaNs back\n",
    "\n",
    "        # Store results\n",
    "        table_data_dict[table_name] = scaled_data\n",
    "        meta_data_dict[table_name] = col_to_freq\n",
    "        scalers[table_name] = scaler\n",
    "\n",
    "    return table_data_dict, meta_data_dict, scalers, monthly_dates\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:36.033932Z",
     "start_time": "2025-01-17T16:18:36.028844Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:36.089212Z",
     "start_time": "2025-01-17T16:18:36.087195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_expected(freq_str, date_str):\n",
    "    \"\"\"\n",
    "    freq_str: 'A', 'Q', or 'M'\n",
    "    date_str: e.g. '2021-03-01'\n",
    "    Returns True if we *should* have a value on this date.\n",
    "    \"\"\"\n",
    "    dt = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    m = dt.month\n",
    "    if freq_str == 'M':\n",
    "        return True\n",
    "    elif freq_str == 'Q':\n",
    "        # let’s say Q covers months 3,6,9,12\n",
    "        return (m in [3,6,9,12])\n",
    "    elif freq_str == 'A':\n",
    "        # annual => only january\n",
    "        return (m == 1)\n",
    "    else:\n",
    "        # default\n",
    "        return True"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:36.141076Z",
     "start_time": "2025-01-17T16:18:36.137190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_expected_mask_for_col(freq_str, months_of_date):\n",
    "    \"\"\"\n",
    "    Given a freq_str in {'A','Q','M'} and an array of month integers,\n",
    "    return a boolean mask of where we expect a value for that freq.\n",
    "    E.g. for 'Q', we might only expect months 3,6,9,12; for 'A', only month 1, etc.\n",
    "    \"\"\"\n",
    "    if freq_str == 'M':\n",
    "        return np.ones_like(months_of_date, dtype=bool)\n",
    "    elif freq_str == 'T':\n",
    "        return np.isin(months_of_date, [1, 4, 7, 10])\n",
    "    elif freq_str == 'A':\n",
    "        return (months_of_date == 1)\n",
    "    else:\n",
    "        # Default: raise error\n",
    "        raise ValueError(f\"Unknown frequency string: {freq_str}\")\n",
    "\n",
    "def generate_expected_and_truly_missing_masks_vectorized(\n",
    "    table_array,    # shape (L, k_i), might contain np.nan\n",
    "    freq_dict,      # dict[col_index -> freq_str], e.g. {0:'A',1:'Q',2:'M',...}\n",
    "    date_list       # list of date strings 'YYYY-MM-01' of length L\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates two boolean masks of shape (L, k_i):\n",
    "      - expected_missing_mask: True where the value is *missing* but that is *expected*\n",
    "                               (due to freq not reporting that month)\n",
    "      - truly_missing_mask:    True where the value is missing but it *should* have been reported\n",
    "    \"\"\"\n",
    "    L, k_i = table_array.shape\n",
    "\n",
    "    # 1) Parse months out of each date in date_list\n",
    "    #    We'll create an array of shape (L,) containing the month number.\n",
    "    months_of_date = np.array([\n",
    "        datetime.strptime(d, \"%Y-%m-%d\").month for d in date_list\n",
    "    ], dtype=int)  # shape (L,)\n",
    "\n",
    "    # 2) Build an array freq_array of shape (k_i,) from freq_dict\n",
    "    #    so freq_array[c] = freq_dict[c]\n",
    "    freq_array = np.array([freq_dict[c] for c in range(k_i)], dtype=object)  # shape (k_i,)\n",
    "\n",
    "    # 3) Build an (L, k_i) boolean array \"expected_array\"\n",
    "    #    which is True where freq says \"we expect a value\"\n",
    "    #    We'll do this by computing a mask for each column, then stacking.\n",
    "    expected_array = np.zeros((L, k_i), dtype=bool)\n",
    "    for c in range(k_i):\n",
    "        freq_str = freq_array[c]\n",
    "        expected_array[:, c] = is_expected_mask_for_col(freq_str, months_of_date)\n",
    "\n",
    "    # 4) Now check where table_array is NaN => \"missing\"\n",
    "    missing_mask = np.isnan(table_array)  # shape (L, k_i)\n",
    "\n",
    "    # 5) truly_missing => \"missing\" AND \"expected\"\n",
    "    truly_missing_mask = missing_mask & expected_array\n",
    "    # 6) expected_missing => \"missing\" AND \"NOT expected\"\n",
    "    expected_missing_mask = missing_mask & ~expected_array\n",
    "\n",
    "    return expected_missing_mask, truly_missing_mask"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:45.245153Z",
     "start_time": "2025-01-17T16:18:36.182141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"Data/all_data.json\", \"r\") as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "csv_file_paths = [f\"Data/{table_name}.csv\" for table_name in all_data]\n",
    "csv_file_paths_meta = [f\"Data/{table_name}_meta.csv\" for table_name in all_data]\n",
    "\n",
    "table_data_dict, meta_data_dict, scalers, monthly_dates = read_and_scale_tables(\n",
    "    csv_file_paths,\n",
    "    csv_file_paths_meta,\n",
    "    start_date=\"1970-01-01\",\n",
    "    end_date=\"2024-01-01\",\n",
    "    train_cutoff_str=\"2018-01-01\"\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading and scaling tables: 100%|██████████| 76/76 [00:09<00:00,  8.39it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:18:45.522231Z",
     "start_time": "2025-01-17T16:18:45.251520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_data_integrity(table_data_dict, meta_data_dict, monthly_dates):\n",
    "    # Test that all arrays have the same number of months as monthly_dates\n",
    "    num_months = len(monthly_dates)\n",
    "    for table_name, table_data in table_data_dict.items():\n",
    "        assert table_data.shape[0] == num_months, \\\n",
    "            f\"Table {table_name} has {table_data.shape[0]} months, expected {num_months}\"\n",
    "\n",
    "    # Test that all arrays have the same number of columns as meta_data_dict\n",
    "    for table_name, table_data in table_data_dict.items():\n",
    "        assert table_data.shape[1] == len(meta_data_dict[table_name]), \\\n",
    "            f\"Table {table_name} has {table_data.shape[1]} columns, expected {len(meta_data_dict[table_name])}\"\n",
    "\n",
    "    # Test that are not null where True mask AND expected mask == 0\n",
    "    for table_name, table_data in table_data_dict.items():\n",
    "        expected_mask, truly_missing_mask = generate_expected_and_truly_missing_masks_vectorized(\n",
    "            table_data, meta_data_dict[table_name], monthly_dates\n",
    "        )\n",
    "\n",
    "        place_with_value = np.where(~(expected_mask | truly_missing_mask))\n",
    "\n",
    "        # Check if there are any nans where we expect a value\n",
    "        assert not np.isnan(table_data[place_with_value]).any(), \\\n",
    "            f\"Table {table_name} has NaNs where we expect a value\"\n",
    "\n",
    "    print(\"Data integrity test passed!\")\n",
    "\n",
    "print(\"Testing data integrity...\")\n",
    "test_data_integrity(table_data_dict, meta_data_dict, monthly_dates)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data integrity...\n",
      "Data integrity test passed!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "true_mask is true wherever the value is missing and it should not be (report date is consistent with the presence of a value there)\n",
    "\n",
    "expected_mask is true wherever the value is missing and it should be (report date is consistent with the absence of a value there)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Dict, List\n",
    "\n",
    "class EconDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 table_data_dict: Dict[str, np.ndarray],\n",
    "                 monthly_dates: List[str],\n",
    "                 expected_missing_dict: Optional[Dict[str, np.ndarray]],\n",
    "                 true_missing_dict: Optional[Dict[str, np.ndarray]],\n",
    "                 min_window_length_year: int = 1,\n",
    "                 max_window_length_year: Optional[int] = None,\n",
    "                 train: bool = True,\n",
    "                 test_start_date: str = \"2018-01-01\",\n",
    "                 number_of_samples: int = 100_000,\n",
    "                 # -- Masking probabilities\n",
    "                 p_1_none: float = 0.1,\n",
    "                 p_2_uniform: float = 0.2,\n",
    "                 p_3_last1yr: float = 0.3,\n",
    "                 p_4_last2yr: float = 0.1,\n",
    "                 p_5_table: float = 0.3,\n",
    "                 p_uniform: float = 0.2,     # Probability to mask each cell in uniform masking\n",
    "                 seed: Optional[int] = None,\n",
    "                 inference_mode: bool = False):\n",
    "        \"\"\"\n",
    "        table_data_dict: dict[table_name] -> (num_months, k_i) scaled arrays\n",
    "        monthly_dates: list of str, aligned to the arrays in table_data_dict\n",
    "        expected_missing_dict: dict[table_name] -> (num_months, k_i) array of expected missing indicators\n",
    "        true_missing_dict: dict[table_name] -> (num_months, k_i) array of true missing indicators\n",
    "        min_window_length_year: minimum window length (in years)\n",
    "        max_window_length_year: maximum window length (in years), if None => no upper bound\n",
    "        train: whether this dataset is for training or test\n",
    "        test_start_date: str, e.g. \"2018-01-01\"\n",
    "        number_of_samples: total number of random samples (i.e. random time windows) to generate\n",
    "        p_1_none, p_2_uniform, p_3_last1yr, p_4_last2yr, p_5_table: probabilities for the 5 masking modes\n",
    "        p_uniform: for the uniform random mask, each cell has this probability of being masked\n",
    "        seed: optional random seed for reproducibility\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # -- Basic checks\n",
    "        if not inference_mode:\n",
    "            p_sum = p_1_none + p_2_uniform + p_3_last1yr + p_4_last2yr + p_5_table\n",
    "            assert abs(p_sum - 1.0) < 1e-7, \"Mask probabilities must sum to 1.0!\"\n",
    "        else:\n",
    "            p_1_none, p_2_uniform, p_3_last1yr, p_4_last2yr, p_5_table = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "\n",
    "        self.monthly_dates = monthly_dates\n",
    "\n",
    "        # -- Build train/test boundary\n",
    "        self.test_start_idx = self.monthly_dates.index(test_start_date)\n",
    "\n",
    "        self.num_months = len(monthly_dates)\n",
    "        self.train = train\n",
    "        self.min_window_length_months = 12 * min_window_length_year\n",
    "        if max_window_length_year is not None:\n",
    "            self.max_window_length_months = 12 * max_window_length_year\n",
    "        else:\n",
    "            # If not specified, let’s default to using up to the entire range - 1\n",
    "            self.max_window_length_months = self.test_start_idx - 1 if self.train else self.num_months - self.test_start_idx - 1\n",
    "\n",
    "        # -- Masking probabilities\n",
    "        self.p_1_none = p_1_none\n",
    "        self.p_2_uniform = p_2_uniform\n",
    "        self.p_3_last1yr = p_3_last1yr\n",
    "        self.p_4_last2yr = p_4_last2yr\n",
    "        self.p_5_table = p_5_table\n",
    "        self.p_uniform = p_uniform\n",
    "\n",
    "        # We store the total number of random samples\n",
    "        self.number_of_samples = number_of_samples\n",
    "\n",
    "        # Optionally set random seed\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        # Transform each table from (L, k_i) => (L, 3*k_i)\n",
    "        # ~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        self.table_names = list(table_data_dict.keys())\n",
    "        new_table_data_dict = {}\n",
    "\n",
    "        for table_name in self.table_names:\n",
    "            raw_table = table_data_dict[table_name]             # shape (L, k_i)\n",
    "            exp_missing = expected_missing_dict[table_name]     # shape (L, k_i), boolean\n",
    "            true_missing = true_missing_dict[table_name]        # shape (L, k_i)\n",
    "\n",
    "            # Check where raw_table is NaN\n",
    "            is_nan = np.isnan(raw_table)\n",
    "\n",
    "            # Fill out each triple (value, expected_missing_bit, unexpected_missing_bit)\n",
    "            L, k_i = raw_table.shape\n",
    "            transformed_table = np.zeros((L, 3 * k_i), dtype=raw_table.dtype)\n",
    "\n",
    "            # 1) First feature: if not NaN => x, if NaN => 0.0\n",
    "            transformed_table[:, 0::3] = np.where(is_nan, 0.0, raw_table)\n",
    "\n",
    "            # 2) Second feature: 1 if NaN & expected == True, else 0\n",
    "            transformed_table[:, 1::3] = np.where(is_nan & exp_missing, 1.0, 0.0)\n",
    "\n",
    "            # 3) Third feature: 1 if NaN & expected == False, else 0\n",
    "            transformed_table[:, 2::3] = np.where(is_nan & true_missing, 1.0, 0.0)\n",
    "\n",
    "            # Store the transformed array\n",
    "            new_table_data_dict[table_name] = transformed_table.astype(np.float32)\n",
    "\n",
    "        # Now replace the original table_data_dict with our new 3*k_i version\n",
    "        self.table_data_dict = new_table_data_dict\n",
    "        self.num_tables = len(self.table_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.number_of_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a dict:\n",
    "            {\n",
    "              \"full_data\": { table_name -> np.ndarray of shape (window_length, 3*k_i) },\n",
    "              \"mask\": np.ndarray of shape (window_length, num_tables),\n",
    "            }\n",
    "        \"\"\"\n",
    "        # 1) Sample a random window length\n",
    "        window_length = np.random.randint(self.min_window_length_months,\n",
    "                                          self.max_window_length_months + 1)\n",
    "\n",
    "        # 2) Sample a random start within either train or test\n",
    "        if self.train:\n",
    "            max_start = self.test_start_idx - window_length\n",
    "            if max_start < 0:\n",
    "                raise ValueError(\"Not enough months for the requested window in training set.\")\n",
    "            start_idx = np.random.randint(0, max_start + 1)\n",
    "        else:\n",
    "            max_start = self.num_months - window_length\n",
    "            if max_start < self.test_start_idx:\n",
    "                raise ValueError(\"Not enough months for the requested window in test set.\")\n",
    "            start_idx = np.random.randint(self.test_start_idx, max_start + 1)\n",
    "\n",
    "        end_idx = start_idx + window_length\n",
    "\n",
    "        # 3) Prepare output data structures\n",
    "        full_data = {}\n",
    "        # shape: (window_length, num_tables), default zeros\n",
    "        mask = np.zeros((window_length, self.num_tables), dtype=np.float32)\n",
    "\n",
    "        # 4) Decide which masking mode to apply\n",
    "        r = np.random.rand()\n",
    "        if r < self.p_1_none:\n",
    "            mask_mode = \"none\"\n",
    "        elif r < self.p_1_none + self.p_2_uniform:\n",
    "            mask_mode = \"uniform\"\n",
    "        elif r < self.p_1_none + self.p_2_uniform + self.p_3_last1yr:\n",
    "            mask_mode = \"last1yr\"\n",
    "        elif r < (self.p_1_none + self.p_2_uniform + self.p_3_last1yr + self.p_4_last2yr):\n",
    "            mask_mode = \"last2yr\"\n",
    "        else:\n",
    "            mask_mode = \"table\"\n",
    "\n",
    "        # 5) Slice out the transformed data (now shape = (L, 3*k_i))\n",
    "        for i, tn in enumerate(self.table_names):\n",
    "            # the array is now (L, 3*k_i)\n",
    "            table_array = self.table_data_dict[tn]\n",
    "            full_data[tn] = table_array[start_idx:end_idx, :]\n",
    "\n",
    "        # 6) Fill the mask\n",
    "        if mask_mode == \"none\":\n",
    "            # do nothing\n",
    "            pass\n",
    "\n",
    "        elif mask_mode == \"uniform\":\n",
    "            # For each (t, i), mask with probability p_uniform\n",
    "            random_matrix = np.random.rand(window_length, self.num_tables)\n",
    "            mask[random_matrix < self.p_uniform] = 1.0\n",
    "\n",
    "        elif mask_mode == \"last1yr\":\n",
    "            omit_start = max(0, window_length - 12)\n",
    "            mask[omit_start:, :] = 1.0\n",
    "\n",
    "        elif mask_mode == \"last2yr\":\n",
    "            omit_start = max(0, window_length - 24)\n",
    "            mask[omit_start:, :] = 1.0\n",
    "\n",
    "        elif mask_mode == \"table\":\n",
    "            n_mask_tables = np.random.randint(1, self.num_tables + 1)\n",
    "            table_indices_to_mask = np.random.choice(self.num_tables,\n",
    "                                                     size=n_mask_tables,\n",
    "                                                     replace=False)\n",
    "            mask[:, table_indices_to_mask] = 1.0\n",
    "\n",
    "        # 7) Return the sample\n",
    "        return {\n",
    "            \"full_data\": full_data,    # dict[str, np.ndarray], each (window_length, 3*k_i)\n",
    "            \"mask\": mask,              # np.ndarray of shape (window_length, num_tables)\n",
    "        }\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T11:01:55.252123Z",
     "start_time": "2025-01-18T11:01:55.242576Z"
    }
   },
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T11:01:55.601380Z",
     "start_time": "2025-01-18T11:01:55.598156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(table_data_dict: Dict[str, np.ndarray],\n",
    "                   meta_data_dict: Dict[str, Dict[int, str]],\n",
    "                   monthly_dates: List[str],\n",
    "                   train: bool=True,\n",
    "                   min_window_length_year: int = 1,\n",
    "                   max_window_length_year: Optional[int] = None,\n",
    "                   test_start_date: str = \"2018-01-01\",\n",
    "                   number_of_samples: int = 100_000,\n",
    "                   # -- Masking probabilities\n",
    "                   p_1_none: float = 0.1,\n",
    "                   p_2_uniform: float = 0.2,\n",
    "                   p_3_last1yr: float = 0.2,\n",
    "                   p_4_last2yr: float = 0.2,\n",
    "                   p_5_table: float = 0.3,\n",
    "                   p_uniform: float = 0.3,     # Probability to mask each cell in uniform masking\n",
    "                   seed: Optional[int] = None,\n",
    "                   inference_mode: bool = False\n",
    "                ):\n",
    "    expected_missing_dict, true_missing_dict = {}, {}\n",
    "    for table_name, table_data in table_data_dict.items():\n",
    "        expected_missing, true_missing = generate_expected_and_truly_missing_masks_vectorized(table_data_dict[table_name], meta_data_dict[table_name], monthly_dates)\n",
    "        expected_missing_dict[table_name] = expected_missing\n",
    "        true_missing_dict[table_name] = true_missing\n",
    "\n",
    "    dataset = EconDataset(\n",
    "        table_data_dict=table_data_dict,\n",
    "        monthly_dates=monthly_dates,\n",
    "        expected_missing_dict=expected_missing_dict,\n",
    "        true_missing_dict=true_missing_dict,\n",
    "        min_window_length_year=min_window_length_year,\n",
    "        max_window_length_year=max_window_length_year,\n",
    "        train=train,\n",
    "        test_start_date=test_start_date,\n",
    "        number_of_samples=number_of_samples,\n",
    "        p_1_none=p_1_none,\n",
    "        p_2_uniform=p_2_uniform,\n",
    "        p_3_last1yr=p_3_last1yr,\n",
    "        p_4_last2yr=p_4_last2yr,\n",
    "        p_5_table=p_5_table,\n",
    "        p_uniform=p_uniform,\n",
    "        seed=seed,\n",
    "        inference_mode=inference_mode\n",
    "    )\n",
    "\n",
    "    return dataset"
   ],
   "outputs": [],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T16:48:27.486713Z",
     "start_time": "2025-01-17T16:48:27.171264Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = create_dataset(table_data_dict, meta_data_dict, monthly_dates, train=True, max_window_length_year=6)",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:13:42.674184Z",
     "start_time": "2025-01-17T17:13:42.670840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def econ_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for EconDataset.\n",
    "\n",
    "    Args:\n",
    "        batch: List of size B, each element is a dict:\n",
    "            {\n",
    "              \"full_data\": { table_name -> np.ndarray (L, 3*k_i) },\n",
    "              \"mask\": np.ndarray (L, num_tables),\n",
    "            }\n",
    "\n",
    "    Returns a dict:\n",
    "      {\n",
    "        \"full_data\": { table_name -> FloatTensor of shape (B, L_max, 3*k_i) },\n",
    "        \"mask\": BoolTensor of shape (B, L_max, N),\n",
    "        \"padding_mask\": BoolTensor of shape (B, L_max, N),\n",
    "      }\n",
    "    where:\n",
    "      - B = batch size\n",
    "      - L_max = maximum sequence length in this batch\n",
    "      - N = number of tables\n",
    "      - k_i = dimension of the expanded features per table\n",
    "    \"\"\"\n",
    "    # -------------------------\n",
    "    # 1. Basic info\n",
    "    # -------------------------\n",
    "    batch_size = len(batch)\n",
    "    lengths = [item[\"mask\"].shape[0] for item in batch]      # each item[\"mask\"] is (L, num_tables)\n",
    "    L_max = max(lengths)                                     # maximum L among the batch\n",
    "    num_tables = batch[0][\"mask\"].shape[1]\n",
    "\n",
    "    # Build boolean masks\n",
    "    mask_tensor = torch.zeros((batch_size, L_max, num_tables), dtype=torch.bool)\n",
    "    padding_mask = torch.ones((batch_size, L_max, num_tables), dtype=torch.bool)\n",
    "\n",
    "    # Fill them\n",
    "    for b, item in enumerate(batch):\n",
    "        L = item['mask'].shape[0]\n",
    "        mask_tensor[b, :L, :] = torch.from_numpy(item['mask']).bool()\n",
    "        padding_mask[b, :L, :] = False\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 2. Build 'full_data' for each table\n",
    "    #    We'll create a dict {table_name -> FloatTensor (B, L_max, k_i)}\n",
    "    # -------------------------------------------------------\n",
    "    table_names = list(batch[0][\"full_data\"].keys())\n",
    "    full_data_dict = {}\n",
    "\n",
    "    t41 = 0\n",
    "    t42 = 0\n",
    "    # For each table, we figure out its feature dimension k_i by looking at the first item\n",
    "    for tn in table_names:\n",
    "        # shape of the first item is (L, k_i). We'll use that k_i for the entire batch\n",
    "        _, k_i = batch[0][\"full_data\"][tn].shape\n",
    "\n",
    "        # Allocate a PyTorch tensor (B, L_max, k_i) for this table, filled with 0.0 (pad value)\n",
    "        s41 = time.time()\n",
    "        data_np = np.empty((batch_size, L_max, k_i), dtype=np.float32)\n",
    "        data_np.fill(0.0)\n",
    "        t41 += time.time() - s41\n",
    "\n",
    "        s42 = time.time()\n",
    "        # Fill it with each item’s data\n",
    "        for b, item in enumerate(batch):\n",
    "            arr_np = item[\"full_data\"][tn]   # shape = (L, 3*k_i)\n",
    "            L = arr_np.shape[0]\n",
    "            data_np[b, :L, :] = arr_np\n",
    "\n",
    "        data_tensor = torch.from_numpy(data_np)\n",
    "        t42 += time.time() - s42\n",
    "\n",
    "        # Store this in our dictionary\n",
    "        full_data_dict[tn] = data_tensor\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # 5. Return the collated batch as a dict\n",
    "    # -------------------------------------------------------\n",
    "    batch_output = {\n",
    "        \"full_data\": full_data_dict,         # {table_name -> FloatTensor (B, L_max, k_i)}\n",
    "        \"mask\": mask_tensor,                 # BoolTensor (B, L_max, num_tables)\n",
    "        \"padding_mask\": padding_mask,        # BoolTensor (B, L_max, num_tables)\n",
    "    }\n",
    "\n",
    "    return batch_output\n"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:10:43.632110Z",
     "start_time": "2025-01-17T17:10:39.535725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s = time.time()\n",
    "for _ in range(500):\n",
    "    x = torch.zeros(8, 100, 100, 500, dtype=torch.float32)\n",
    "print(\"Created 500 tensors in\", time.time() - s, \"seconds\")\n",
    "\n",
    "s = time.time()\n",
    "for _ in range(500):\n",
    "    x = np.zeros((8, 100, 100, 500), dtype=np.float32)\n",
    "print(\"Created 500 numpy arrays in\", time.time() - s, \"seconds\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 500 tensors in 4.085897922515869 seconds\n",
      "Created 500 numpy arrays in 0.008311033248901367 seconds\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:10:44.517150Z",
     "start_time": "2025-01-17T17:10:43.659098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "s = time.time()\n",
    "for i in range(100*4):\n",
    "    x = dataset[i]\n",
    "\n",
    "print(\"Loaded 400 samples in\", time.time() - s, \"seconds\")\n",
    "\n",
    "s = time.time()\n",
    "tt41, tt42 = 0, 0\n",
    "for i in range(100):\n",
    "    x, t41, t42 = econ_collate_fn([dataset[4*i + j] for j in range(4)])\n",
    "    tt41 += t41\n",
    "    tt42 += t42\n",
    "\n",
    "print(\"Collated 100 batches in\", time.time() - s, \"seconds\")\n",
    "print(\"Time breakdown:\", tt41, tt42)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400 samples in 0.009163618087768555 seconds\n",
      "Collated 100 batches in 0.8471071720123291 seconds\n",
      "Time breakdown: 0.45110011100769043 0.3578493595123291\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:10:50.133314Z",
     "start_time": "2025-01-17T17:10:49.243376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=econ_collate_fn)\n",
    "\n",
    "s = time.time()\n",
    "for i, batch in enumerate(dataloader):\n",
    "    if i == 100:\n",
    "        break\n",
    "    pass\n",
    "print(\"Iterated over the dataloader in\", time.time() - s, \"seconds\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterated over the dataloader in 0.8882815837860107 seconds\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:10:59.685922Z",
     "start_time": "2025-01-17T17:10:59.684107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TableEmbedding(nn.Module):\n",
    "    def __init__(self, k_in, embed_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(k_in, embed_dim)\n",
    "        self.l2 = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, L, k_in)\n",
    "        returns: (B, L, embed_dim)\n",
    "        \"\"\"\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:10:59.953083Z",
     "start_time": "2025-01-17T17:10:59.950849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def key_padding_mask_to_attention_mask(key_padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a key_padding_mask of shape (B, S) to an attention_mask of shape (B, S, S).\n",
    "\n",
    "    Args:\n",
    "        key_padding_mask: Boolean tensor of shape (B, S) where True indicates padding tokens\n",
    "                         and False indicates actual tokens.\n",
    "\n",
    "    Returns:\n",
    "        attention_mask: Boolean tensor of shape (B, S, S) where False indicates allowed\n",
    "                       attention and True indicates masked (blocked) attention.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = key_padding_mask.size()\n",
    "\n",
    "    # First, we need to convert the key_padding_mask to the right shape\n",
    "    # We want each position to not attend to padding tokens\n",
    "    # So we expand the key_padding_mask to (B, 1, S) and broadcast it to (B, S, S)\n",
    "    # Make it contiguous to ensure the memory layout allows setting elements\n",
    "    expanded_mask = key_padding_mask.unsqueeze(1).expand(batch_size, seq_len, seq_len).contiguous()\n",
    "\n",
    "    return expanded_mask\n",
    "\n",
    "def fix_fully_masked_rows(attn_mask_3d: torch.Tensor, key_padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    For any row b where key_padding_mask[b] is all True (i.e., fully masked),\n",
    "    replace that entire (L, L) block in attn_mask_3d with ~torch.eye(L).\n",
    "    This makes each token attend only to itself, preventing NaNs.\n",
    "    \"\"\"\n",
    "    B, L, _ = attn_mask_3d.shape\n",
    "    fully_masked_rows = key_padding_mask.all(dim=1)  # shape (B,)\n",
    "    attn_mask_3d = attn_mask_3d.clone()\n",
    "    attn_mask_3d[fully_masked_rows] = ~torch.eye(L, L, dtype=torch.bool, device=attn_mask_3d.device, requires_grad=False)\n",
    "    return attn_mask_3d"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DoubleAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Perform two-step attention on data of shape (B, L, N, E):\n",
    "    1) Attention over N dimension (tables)\n",
    "    2) Attention over L dimension (time)\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(DoubleAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # We'll define two MultiheadAttention modules:\n",
    "        # - attnN: handles attention across N\n",
    "        # - attnL: handles attention across L\n",
    "        self.attnN = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        self.attnL = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, padding_mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, L, N, E)\n",
    "        padding_mask: BoolTensor of shape (B, L, N). True will be ignored in attention.\n",
    "        returns: Tensor of shape (B, L, N, E) after double attention\n",
    "        \"\"\"\n",
    "        B, L, N, E = x.shape\n",
    "\n",
    "        # Clone padding mask to prevent any modification from affecting its reference\n",
    "        padding_mask = padding_mask.clone()\n",
    "\n",
    "        # -- Attention across N --\n",
    "        # Flatten into (B*L, N, E)\n",
    "        x_reshape = x.view(B * L, N, E).contiguous()\n",
    "        padding_mask = padding_mask.view(B * L, N)\n",
    "        # -----------------\n",
    "        # This is where some issues can be introduced. We padded sequences to have same length.\n",
    "        # We do attention across all clues for all pairs of month and elements in the batch.\n",
    "        # /!\\ We transform the padding mask into an attention mask and let padded elements attend to themselves.\n",
    "        # /!\\ We zero-out the attention scores for sequences that are entirely padded.\n",
    "        # -----------------\n",
    "        attn_mask = key_padding_mask_to_attention_mask(padding_mask)\n",
    "        attn_mask = fix_fully_masked_rows(attn_mask, padding_mask) # (B*L, N, N)\n",
    "\n",
    "        # Expand the mask for the number of heads\n",
    "        attn_mask = attn_mask.unsqueeze(1).expand(B * L, self.num_heads, N, N).reshape(B * L * self.num_heads, N, N).contiguous()\n",
    "\n",
    "\n",
    "        # Multi-head attention across N\n",
    "        attn_outN, _ = self.attnN(x_reshape, x_reshape, x_reshape, attn_mask=attn_mask) # (B*L, N, E)\n",
    "        attn_outN = attn_outN.masked_fill(padding_mask.all(dim=1).view(-1, 1, 1), 0.0)\n",
    "\n",
    "        # Reshape back to (B, L, N, E)\n",
    "        xN = attn_outN.view(B, L, N, E)\n",
    "        padding_mask = padding_mask.view(B, L, N)\n",
    "\n",
    "        # -- Attention across L --\n",
    "        # Permute to (B, N, L, E) and (B, N, L)\n",
    "        xN = xN.permute(0, 2, 1, 3).contiguous()\n",
    "        padding_mask = padding_mask.permute(0, 2, 1).contiguous()\n",
    "\n",
    "        # Flatten into (B*N, L, E)\n",
    "        xN_reshape = xN.view(B * N, L, E)\n",
    "        padding_mask = padding_mask.view(B * N, L)\n",
    "\n",
    "        # Multi-head attention across L\n",
    "        attn_outL, _ = self.attnL(xN_reshape, xN_reshape, xN_reshape, key_padding_mask=padding_mask)\n",
    "\n",
    "        # -----------------\n",
    "        # No issue should arise here as we are only attending across time dimension.\n",
    "        # Elements replaced by 0.0 are masked elements in the second attention.\n",
    "        # Each pair of batch element and table should have at least 1 month of data as min_time_window_year > 0.\n",
    "        # -----------------\n",
    "\n",
    "        # Reshape back to (B, N, L, E), we discard padding_mask\n",
    "        xL = attn_outL.view(B, N, L, E)\n",
    "\n",
    "        # Permute back to (B, L, N, E)\n",
    "        out = xL.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:00.582393Z",
     "start_time": "2025-01-17T17:11:00.577692Z"
    }
   },
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "source": [
    "class TableDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim, k_out):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(embed_dim, k_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, L, embed_dim)\n",
    "        -> (B, L, k_out)\n",
    "        \"\"\"\n",
    "        return self.linear(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:01.222929Z",
     "start_time": "2025-01-17T17:11:01.220688Z"
    }
   },
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:01.612099Z",
     "start_time": "2025-01-17T17:11:01.598143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:02.440348Z",
     "start_time": "2025-01-17T17:11:02.435796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard transformer feed-forward network with GELU activation\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, ff_dim: int, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TransformerLayer2D(nn.Module):\n",
    "    \"\"\"\n",
    "    A single transformer layer using DoubleAttention\n",
    "    Uses pre-norm architecture (norm before attention/FFN)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        ff_dim: int,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.attention = DoubleAttention(embed_dim, num_heads)\n",
    "        self.ff = FeedForward(embed_dim, ff_dim, dropout)\n",
    "\n",
    "        # Layer norms before attention and FF\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Dropout for attention output\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, padding_mask):\n",
    "        # Pre-norm architecture\n",
    "        # Attention block\n",
    "        normed_x = self.norm1(x)\n",
    "        attn_out = self.attention(normed_x, padding_mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "\n",
    "        # FFN block\n",
    "        normed_x = self.norm2(x)\n",
    "        ff_out = self.ff(normed_x)\n",
    "        x = x + ff_out\n",
    "\n",
    "        return x\n",
    "\n",
    "class PositionalEncoding2D(nn.Module):\n",
    "    \"\"\"\n",
    "    2D positional encoding that handles both time (L) and table (N) dimensions\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Create a standard 1D positional encoding for the time dimension\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim)\n",
    "        )\n",
    "\n",
    "        # Apply sin to even indices and cos to odd indices\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Register as buffer so it's not a learnable parameter\n",
    "        self.register_buffer('pe', pe.unsqueeze(0).unsqueeze(2))\n",
    "        print('Created 2D positional encoding with shape:', self.pe.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: tensor of shape (B, L, N, E)\n",
    "        returns: same tensor with positional encoding added to time dimension\n",
    "        \"\"\"\n",
    "        B, L, N, E = x.shape\n",
    "        # Slice the positional embeddings to match L, then broadcast across B and N\n",
    "        pos_encoding = self.pe[:, :L, :, :]\n",
    "\n",
    "        # Add positional encoding to x\n",
    "        return x + pos_encoding\n",
    "\n",
    "class Transformer2D(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete 2D transformer with multiple layers\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        num_layers: int,\n",
    "        ff_dim: int,\n",
    "        dropout: float = 0.1,\n",
    "        max_len: int = 5000,\n",
    "        use_pos_encoding: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Optional positional encoding\n",
    "        self.pos_encoding = PositionalEncoding2D(embed_dim, max_len) if use_pos_encoding else None\n",
    "\n",
    "        # Stack of transformer layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerLayer2D(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final layer norm (following BERT)\n",
    "        self.final_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, padding_mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: tensor of shape (B, L, N, E)\n",
    "        padding_mask: boolean tensor of shape (B, L, N)\n",
    "        returns: transformed tensor of shape (B, L, N, E)\n",
    "        \"\"\"\n",
    "        # Optional positional encoding\n",
    "        if self.pos_encoding is not None:\n",
    "            x = self.pos_encoding(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Pass through all transformer layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, padding_mask)\n",
    "\n",
    "\n",
    "        # Final layer norm\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "class EconModel(nn.Module):\n",
    "    def __init__(self, table_names, table_shapes,\n",
    "                 embed_dim=32, n_heads=4, ff_dim=128, num_layers=2,\n",
    "                 dropout=0.1, use_pos_encoding=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.table_names = table_names\n",
    "        self.N = len(table_names)\n",
    "\n",
    "        self.table_embeds = nn.ModuleDict()\n",
    "        self.table_decoders = nn.ModuleDict()\n",
    "\n",
    "        # Create embeddings/decoders\n",
    "        for tn, k_in in zip(table_names, table_shapes):\n",
    "            self.table_embeds[tn] = TableEmbedding(3*k_in, embed_dim)\n",
    "            self.table_decoders[tn] = TableDecoder(embed_dim, k_in) # Since we tripled the features for Nan representation\n",
    "\n",
    "        # 2D Transformer core\n",
    "        self.core_transformer = Transformer2D(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=n_heads,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=ff_dim,\n",
    "            dropout=dropout,\n",
    "            use_pos_encoding=use_pos_encoding\n",
    "        )\n",
    "\n",
    "        # Learned parameter for masking\n",
    "        self.mask_embedding = nn.Parameter(\n",
    "            torch.randn(embed_dim) * 0.02  # Shape: (E), scale down following Transformer implementation\n",
    "        )\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def forward(self, batch_data):\n",
    "        \"\"\"\n",
    "        batch_data:\n",
    "          {\n",
    "            \"full_data\": {tn -> (B, L_max, 3*k_i)},\n",
    "            \"mask\": BoolTensor (B, L_max, N)\n",
    "            \"padding_mask\": BoolTensor (B, L_max, N)\n",
    "          }\n",
    "        Returns a dict {tn -> (B, L, k_i)} of predictions.\n",
    "        \"\"\"\n",
    "        # Embed each table\n",
    "        embed_list = []\n",
    "\n",
    "        for tn in self.table_names:\n",
    "            x = batch_data[\"full_data\"][tn]  # (B, L_max, 3*k_i)\n",
    "\n",
    "            # embed\n",
    "            x_emb = self.table_embeds[tn](x)  # -> (B, L, E)\n",
    "\n",
    "            embed_list.append(x_emb)\n",
    "\n",
    "        # Stack into (B, L, N, E)\n",
    "        embed_stack = torch.stack(embed_list, dim=2)\n",
    "\n",
    "        # Apply the mask with the learned masking vector. Where mask=1, we'll use the learned mask.\n",
    "        mask = batch_data[\"mask\"]  # (B, L_max, N)\n",
    "        masked_embedding = torch.where(\n",
    "            mask.unsqueeze(-1),  # (B, L, N, 1)\n",
    "            self.mask_embedding,      # Will broadcast to (B, L, N, E)\n",
    "            embed_stack              # (B, L, N, E)\n",
    "        )\n",
    "\n",
    "        # Pass through the transformer\n",
    "        padding_mask = batch_data[\"padding_mask\"]  # (B, L, N)\n",
    "        out_2d = self.core_transformer(masked_embedding, padding_mask=padding_mask) # (B, L, N, E)\n",
    "\n",
    "        # Flatten to get a single tensor for all tables\n",
    "        out_2d = out_2d[:, :, 0, :] # (B, L, E)\n",
    "\n",
    "        # 3) decode table by table\n",
    "        decoded = {}\n",
    "        for i, tn in enumerate(self.table_names):\n",
    "            out = self.table_decoders[tn](out_2d)  # (B, L, k_i)\n",
    "            decoded[tn] = out\n",
    "\n",
    "        return decoded\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:03.279457Z",
     "start_time": "2025-01-17T17:11:03.276464Z"
    }
   },
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:08:13.488123Z",
     "start_time": "2025-01-17T15:08:13.486292Z"
    }
   },
   "cell_type": "code",
   "source": "table_shapes = [table_data_dict[tn].shape[1] for tn in dataset.table_names]",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:01:18.457084Z",
     "start_time": "2025-01-17T15:01:17.726445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "module_c = EconModel(dataset.table_names, table_shapes, embed_dim=32, n_heads=4, ff_dim=128, num_layers=2, dropout=0.1, use_pos_encoding=True).to(device)\n",
    "module_c = torch.compile(module_c)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2D positional encoding with shape: torch.Size([1, 5000, 1, 32])\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:19:37.325182Z",
     "start_time": "2025-01-17T15:19:37.323680Z"
    }
   },
   "cell_type": "code",
   "source": "dataloader1 = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=econ_collate_fn, pin_memory=True)",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:20:46.012437Z",
     "start_time": "2025-01-17T15:20:45.187414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start = time.time()\n",
    "moving_to_gpu = 0\n",
    "i = 0\n",
    "for data in dataloader1:\n",
    "    if i > 200:\n",
    "        break\n",
    "    i += 1\n",
    "    s = time.time()\n",
    "    data = {\n",
    "        \"full_data\": {tn: v.to(device, non_blocking=True) for tn, v in data[\"full_data\"].items()},\n",
    "        \"mask\": data[\"mask\"].to(device, non_blocking=True),\n",
    "        \"padding_mask\": data[\"padding_mask\"].to(device, non_blocking=True)\n",
    "    }\n",
    "    moving_to_gpu += time.time() - s\n",
    "    out = module_c(data)\n",
    "\n",
    "print(\"Time taken:\", time.time() - start)\n",
    "print(\"Moving to GPU:\", moving_to_gpu)"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[84], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m moving_to_gpu \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      3\u001B[0m i \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdataloader1\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m:\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mbreak\u001B[39;49;00m\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:00:24.301032Z",
     "start_time": "2025-01-17T15:00:24.230678Z"
    }
   },
   "cell_type": "code",
   "source": "module_c = EconModel(dataset.table_names, table_shapes, embed_dim=32, n_heads=4, ff_dim=128, num_layers=2, dropout=0.1, use_pos_encoding=True).to(device)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2D positional encoding with shape: torch.Size([1, 5000, 1, 32])\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T15:01:54.326983Z",
     "start_time": "2025-01-17T15:01:52.143987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataloader1 = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=econ_collate_fn, pin_memory=True)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "i = 0\n",
    "for data in dataloader1:\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break\n",
    "\n",
    "    for tn in data[\"full_data\"].keys():\n",
    "        data[\"full_data\"][tn] = data[\"full_data\"][tn].to(device)\n",
    "    data[\"mask\"] = data[\"mask\"].to(device)\n",
    "    data[\"padding_mask\"] = data[\"padding_mask\"].to(device)\n",
    "    out = module(data)\n",
    "\n",
    "print(\"Time taken:\", time.time() - start)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 2.181070566177368\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": [
    "def masked_mse_loss(pred: torch.Tensor, target: torch.Tensor, mask: torch.BoolTensor):\n",
    "    \"\"\"\n",
    "    pred: (B, L, k_i)\n",
    "    target: (B, L, k_i)\n",
    "    mask: (B, L, k_i)  # 1 where ground truth is valid, 0 where no ground truth\n",
    "    Returns average MSE over valid entries.\n",
    "    \"\"\"\n",
    "    diff = (pred - target) ** 2\n",
    "    diff = diff * mask\n",
    "    valid_count = mask.sum()\n",
    "    if valid_count > 0:\n",
    "        return diff.sum() / valid_count\n",
    "    else:\n",
    "        return torch.tensor(0.0, device=pred.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:11:14.551103Z",
     "start_time": "2025-01-17T17:11:14.549211Z"
    }
   },
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def train_econ_model(csv_file_paths,\n",
    "                     meta_file_paths,\n",
    "                     epochs=5,\n",
    "                     batch_size=8,\n",
    "                     min_window_length_year=2,\n",
    "                     max_window_length_year=25,\n",
    "                     embed_dim=32,\n",
    "                     lr=1e-2,\n",
    "                     num_train_samples=25_000,\n",
    "                     num_test_samples=500):\n",
    "    \"\"\"\n",
    "    Full pipeline:\n",
    "    1) Read & scale data with scikit-learn\n",
    "    2) Create train/test datasets\n",
    "    3) Model + optimizer\n",
    "    4) Training loop with masked MSE\n",
    "    \"\"\"\n",
    "    # Read and scale tables\n",
    "    table_data_dict, meta_data_dict, scalers, monthly_dates = read_and_scale_tables(\n",
    "        csv_file_paths,\n",
    "        meta_file_paths,\n",
    "        start_date=\"1970-01-01\",\n",
    "        end_date=\"2024-01-01\",\n",
    "        train_cutoff_str=\"2018-01-01\",\n",
    "    )\n",
    "\n",
    "    # Create train and test dataset\n",
    "    train_dataset = create_dataset(table_data_dict, meta_data_dict, monthly_dates, train=True, min_window_length_year=min_window_length_year, max_window_length_year=max_window_length_year, number_of_samples=num_train_samples)\n",
    "    test_dataset = create_dataset(table_data_dict, meta_data_dict, monthly_dates, train=False, min_window_length_year=min_window_length_year, max_window_length_year=4, number_of_samples=num_test_samples)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=econ_collate_fn\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=econ_collate_fn\n",
    "    )\n",
    "\n",
    "    # 3) model + optimizer\n",
    "    table_names = list(table_data_dict.keys())\n",
    "    table_shapes = [table_data_dict[tn].shape[1] for tn in table_names]\n",
    "\n",
    "    print(table_names[0])\n",
    "    print(table_shapes[0])\n",
    "    print(table_data_dict[table_names[0]].shape)\n",
    "\n",
    "    model = EconModel(\n",
    "        table_names,\n",
    "        table_shapes,\n",
    "        embed_dim=embed_dim,\n",
    "        n_heads=4,\n",
    "        ff_dim=128,\n",
    "        num_layers=4,\n",
    "        dropout=0.15,\n",
    "        use_pos_encoding=True\n",
    "    )\n",
    "\n",
    "    update_loss_every = 100\n",
    "    batch_count = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model = torch.compile(model)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    num_training_steps = len(train_loader) * epochs\n",
    "    num_warmup_steps = len(train_loader) * 2\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=num_warmup_steps,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "\n",
    "    # 4) Training loop\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        # Training loop with tqdm\n",
    "        for b_idx, batch_data in tqdm(enumerate(train_loader), desc=\"Training\", total=len(train_loader)):\n",
    "            # Move data to device\n",
    "            for tn in batch_data[\"full_data\"]:\n",
    "                batch_data[\"full_data\"][tn] = batch_data[\"full_data\"][tn].to(device)\n",
    "            batch_data[\"mask\"] = batch_data[\"mask\"].to(device)\n",
    "            batch_data[\"padding_mask\"] = batch_data[\"padding_mask\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_data)  # dict {tn -> (B, L, k_i)}\n",
    "\n",
    "            # Compute loss\n",
    "            losses = []\n",
    "            padding_mask = batch_data[\"padding_mask\"][:, :, 0].unsqueeze(-1)  # (B, L, N) => (B, L, 1)\n",
    "            for tn in table_names:\n",
    "                pred = outputs[tn]\n",
    "                tgt = batch_data[\"full_data\"][tn][:, :, 0::3]  # (B, L, 3*k_i) => (B, L, k_i)\n",
    "                expected_missing_mask = batch_data[\"full_data\"][tn][:, :, 1::3] == 1.0  # (B, L, k_i)\n",
    "                true_missing_mask = batch_data[\"full_data\"][tn][:, :, 2::3] == 1.0  # (B, L, k_i)\n",
    "                valid_mask = ~(expected_missing_mask | true_missing_mask | padding_mask)  # (B, L, k_i)\n",
    "                losses.append(masked_mse_loss(pred, tgt, valid_mask))\n",
    "\n",
    "            loss_val = torch.stack(losses).mean()\n",
    "            with record_function(\"backward\"):\n",
    "                loss_val.backward()\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "            # Update running and total loss\n",
    "            running_loss += loss_val.item()\n",
    "            total_train_loss += loss_val.item()\n",
    "\n",
    "            batch_count += 1\n",
    "\n",
    "            # Update tqdm every 50 batches\n",
    "            if batch_count % update_loss_every == 0:\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                tqdm.write(f\"Average loss (last {update_loss_every} batches): {running_loss / update_loss_every:.4f}, lr: {current_lr:.2e}\")\n",
    "                running_loss = 0.0  # Reset running loss\n",
    "\n",
    "        avg_train_loss = total_train_loss / (b_idx + 1)\n",
    "\n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for b_idx, batch_data in tqdm(enumerate(test_loader), desc=\"Testing\"):\n",
    "                for tn in batch_data[\"full_data\"]:\n",
    "                    batch_data[\"full_data\"][tn] = batch_data[\"full_data\"][tn].to(device)\n",
    "                batch_data[\"mask\"] = batch_data[\"mask\"].to(device)\n",
    "                batch_data[\"padding_mask\"] = batch_data[\"padding_mask\"].to(device)\n",
    "\n",
    "\n",
    "                outputs = model(batch_data)\n",
    "                losses = []\n",
    "                padding_mask = batch_data[\"padding_mask\"][:, :, 0].unsqueeze(-1)\n",
    "                for tn in table_names:\n",
    "                    pred = outputs[tn]\n",
    "                    tgt = batch_data[\"full_data\"][tn][:, :, 0::3]\n",
    "                    expected_missing_mask = batch_data[\"full_data\"][tn][:, :, 1::3] == 1.0\n",
    "                    true_missing_mask = batch_data[\"full_data\"][tn][:, :, 2::3] == 1.0\n",
    "                    valid_mask = ~(expected_missing_mask | true_missing_mask | padding_mask)\n",
    "                    losses.append(masked_mse_loss(pred, tgt, valid_mask))\n",
    "\n",
    "                loss_val = torch.stack(losses).mean()\n",
    "                total_test_loss += loss_val.item()\n",
    "\n",
    "            avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "\n",
    "        print(f\"Epoch {ep+1}/{epochs} - Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    print(\"Training complete!\")\n",
    "    return model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-17T17:20:44.756539Z",
     "start_time": "2025-01-17T17:20:44.750138Z"
    }
   },
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"Data/all_data.json\", \"r\") as f:\n",
    "    all_data = json.load(f)\n",
    "\n",
    "csv_file_paths = [f\"Data/{table_name}.csv\" for table_name in all_data]\n",
    "csv_file_paths_meta = [f\"Data/{table_name}_meta.csv\" for table_name in all_data]\n",
    "\n",
    "model = train_econ_model(\n",
    "    csv_file_paths,\n",
    "    csv_file_paths_meta,\n",
    "    batch_size=8,\n",
    "    lr=5e-4,\n",
    "    min_window_length_year=2,\n",
    "    max_window_length_year=5,\n",
    "    num_train_samples=200_000,\n",
    "    num_test_samples=100,\n",
    "    epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-18T00:12:19.824806Z",
     "start_time": "2025-01-17T17:20:45.230285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reading and scaling tables:   0%|          | 0/76 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08d74a5c22544579a9c4e7b21cc893ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALANCE-PAIEMENTS\n",
      "193\n",
      "(649, 193)\n",
      "Created 2D positional encoding with shape: torch.Size([1, 5000, 1, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05377e8666ba4ea296aedb4498ca9b7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 13.2726, lr: 1.00e-06\n",
      "Average loss (last 100 batches): 12.4859, lr: 2.00e-06\n",
      "Average loss (last 100 batches): 12.6743, lr: 3.00e-06\n",
      "Average loss (last 100 batches): 13.1723, lr: 4.00e-06\n",
      "Average loss (last 100 batches): 13.5393, lr: 5.00e-06\n",
      "Average loss (last 100 batches): 13.1617, lr: 6.00e-06\n",
      "Average loss (last 100 batches): 13.5773, lr: 7.00e-06\n",
      "Average loss (last 100 batches): 13.1624, lr: 8.00e-06\n",
      "Average loss (last 100 batches): 12.8970, lr: 9.00e-06\n",
      "Average loss (last 100 batches): 13.3026, lr: 1.00e-05\n",
      "Average loss (last 100 batches): 13.8302, lr: 1.10e-05\n",
      "Average loss (last 100 batches): 12.3023, lr: 1.20e-05\n",
      "Average loss (last 100 batches): 13.2099, lr: 1.30e-05\n",
      "Average loss (last 100 batches): 12.5497, lr: 1.40e-05\n",
      "Average loss (last 100 batches): 11.9360, lr: 1.50e-05\n",
      "Average loss (last 100 batches): 12.7197, lr: 1.60e-05\n",
      "Average loss (last 100 batches): 12.4442, lr: 1.70e-05\n",
      "Average loss (last 100 batches): 12.4517, lr: 1.80e-05\n",
      "Average loss (last 100 batches): 11.6429, lr: 1.90e-05\n",
      "Average loss (last 100 batches): 12.7972, lr: 2.00e-05\n",
      "Average loss (last 100 batches): 12.1019, lr: 2.10e-05\n",
      "Average loss (last 100 batches): 12.6363, lr: 2.20e-05\n",
      "Average loss (last 100 batches): 12.5542, lr: 2.30e-05\n",
      "Average loss (last 100 batches): 12.3115, lr: 2.40e-05\n",
      "Average loss (last 100 batches): 11.4389, lr: 2.50e-05\n",
      "Average loss (last 100 batches): 11.9620, lr: 2.60e-05\n",
      "Average loss (last 100 batches): 11.6789, lr: 2.70e-05\n",
      "Average loss (last 100 batches): 11.2376, lr: 2.80e-05\n",
      "Average loss (last 100 batches): 11.5352, lr: 2.90e-05\n",
      "Average loss (last 100 batches): 10.6189, lr: 3.00e-05\n",
      "Average loss (last 100 batches): 11.1501, lr: 3.10e-05\n",
      "Average loss (last 100 batches): 10.3808, lr: 3.20e-05\n",
      "Average loss (last 100 batches): 10.4562, lr: 3.30e-05\n",
      "Average loss (last 100 batches): 10.7062, lr: 3.40e-05\n",
      "Average loss (last 100 batches): 10.9605, lr: 3.50e-05\n",
      "Average loss (last 100 batches): 11.1729, lr: 3.60e-05\n",
      "Average loss (last 100 batches): 10.0008, lr: 3.70e-05\n",
      "Average loss (last 100 batches): 9.0892, lr: 3.80e-05\n",
      "Average loss (last 100 batches): 9.8868, lr: 3.90e-05\n",
      "Average loss (last 100 batches): 9.4457, lr: 4.00e-05\n",
      "Average loss (last 100 batches): 9.8987, lr: 4.10e-05\n",
      "Average loss (last 100 batches): 9.3466, lr: 4.20e-05\n",
      "Average loss (last 100 batches): 9.1314, lr: 4.30e-05\n",
      "Average loss (last 100 batches): 8.9616, lr: 4.40e-05\n",
      "Average loss (last 100 batches): 9.4111, lr: 4.50e-05\n",
      "Average loss (last 100 batches): 8.9316, lr: 4.60e-05\n",
      "Average loss (last 100 batches): 8.6825, lr: 4.70e-05\n",
      "Average loss (last 100 batches): 9.0309, lr: 4.80e-05\n",
      "Average loss (last 100 batches): 8.1770, lr: 4.90e-05\n",
      "Average loss (last 100 batches): 8.4752, lr: 5.00e-05\n",
      "Average loss (last 100 batches): 8.3929, lr: 5.10e-05\n",
      "Average loss (last 100 batches): 7.8849, lr: 5.20e-05\n",
      "Average loss (last 100 batches): 7.7161, lr: 5.30e-05\n",
      "Average loss (last 100 batches): 7.6744, lr: 5.40e-05\n",
      "Average loss (last 100 batches): 7.4312, lr: 5.50e-05\n",
      "Average loss (last 100 batches): 7.5594, lr: 5.60e-05\n",
      "Average loss (last 100 batches): 7.5556, lr: 5.70e-05\n",
      "Average loss (last 100 batches): 7.3885, lr: 5.80e-05\n",
      "Average loss (last 100 batches): 7.3351, lr: 5.90e-05\n",
      "Average loss (last 100 batches): 7.1054, lr: 6.00e-05\n",
      "Average loss (last 100 batches): 7.3039, lr: 6.10e-05\n",
      "Average loss (last 100 batches): 6.6210, lr: 6.20e-05\n",
      "Average loss (last 100 batches): 6.6017, lr: 6.30e-05\n",
      "Average loss (last 100 batches): 6.8669, lr: 6.40e-05\n",
      "Average loss (last 100 batches): 6.7825, lr: 6.50e-05\n",
      "Average loss (last 100 batches): 6.9290, lr: 6.60e-05\n",
      "Average loss (last 100 batches): 6.7780, lr: 6.70e-05\n",
      "Average loss (last 100 batches): 6.4497, lr: 6.80e-05\n",
      "Average loss (last 100 batches): 6.2792, lr: 6.90e-05\n",
      "Average loss (last 100 batches): 6.1261, lr: 7.00e-05\n",
      "Average loss (last 100 batches): 6.1580, lr: 7.10e-05\n",
      "Average loss (last 100 batches): 6.0021, lr: 7.20e-05\n",
      "Average loss (last 100 batches): 6.5844, lr: 7.30e-05\n",
      "Average loss (last 100 batches): 5.9901, lr: 7.40e-05\n",
      "Average loss (last 100 batches): 5.8599, lr: 7.50e-05\n",
      "Average loss (last 100 batches): 6.0767, lr: 7.60e-05\n",
      "Average loss (last 100 batches): 5.9654, lr: 7.70e-05\n",
      "Average loss (last 100 batches): 5.7491, lr: 7.80e-05\n",
      "Average loss (last 100 batches): 5.3118, lr: 7.90e-05\n",
      "Average loss (last 100 batches): 5.6286, lr: 8.00e-05\n",
      "Average loss (last 100 batches): 4.9832, lr: 8.10e-05\n",
      "Average loss (last 100 batches): 5.6126, lr: 8.20e-05\n",
      "Average loss (last 100 batches): 5.2021, lr: 8.30e-05\n",
      "Average loss (last 100 batches): 5.5786, lr: 8.40e-05\n",
      "Average loss (last 100 batches): 4.7547, lr: 8.50e-05\n",
      "Average loss (last 100 batches): 4.7954, lr: 8.60e-05\n",
      "Average loss (last 100 batches): 4.7290, lr: 8.70e-05\n",
      "Average loss (last 100 batches): 4.4574, lr: 8.80e-05\n",
      "Average loss (last 100 batches): 4.7164, lr: 8.90e-05\n",
      "Average loss (last 100 batches): 4.3256, lr: 9.00e-05\n",
      "Average loss (last 100 batches): 4.6666, lr: 9.10e-05\n",
      "Average loss (last 100 batches): 4.2152, lr: 9.20e-05\n",
      "Average loss (last 100 batches): 4.1924, lr: 9.30e-05\n",
      "Average loss (last 100 batches): 3.8942, lr: 9.40e-05\n",
      "Average loss (last 100 batches): 4.5572, lr: 9.50e-05\n",
      "Average loss (last 100 batches): 3.9198, lr: 9.60e-05\n",
      "Average loss (last 100 batches): 3.7676, lr: 9.70e-05\n",
      "Average loss (last 100 batches): 3.8292, lr: 9.80e-05\n",
      "Average loss (last 100 batches): 3.8548, lr: 9.90e-05\n",
      "Average loss (last 100 batches): 3.7966, lr: 1.00e-04\n",
      "Average loss (last 100 batches): 3.6898, lr: 1.01e-04\n",
      "Average loss (last 100 batches): 3.6722, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 3.6495, lr: 1.03e-04\n",
      "Average loss (last 100 batches): 3.7379, lr: 1.04e-04\n",
      "Average loss (last 100 batches): 3.7390, lr: 1.05e-04\n",
      "Average loss (last 100 batches): 3.1465, lr: 1.06e-04\n",
      "Average loss (last 100 batches): 3.3680, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 3.3763, lr: 1.08e-04\n",
      "Average loss (last 100 batches): 3.7062, lr: 1.09e-04\n",
      "Average loss (last 100 batches): 3.3794, lr: 1.10e-04\n",
      "Average loss (last 100 batches): 3.2512, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 3.2631, lr: 1.12e-04\n",
      "Average loss (last 100 batches): 3.3394, lr: 1.13e-04\n",
      "Average loss (last 100 batches): 3.0645, lr: 1.14e-04\n",
      "Average loss (last 100 batches): 3.2483, lr: 1.15e-04\n",
      "Average loss (last 100 batches): 3.2596, lr: 1.16e-04\n",
      "Average loss (last 100 batches): 3.1009, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 3.3475, lr: 1.18e-04\n",
      "Average loss (last 100 batches): 3.2850, lr: 1.19e-04\n",
      "Average loss (last 100 batches): 2.7953, lr: 1.20e-04\n",
      "Average loss (last 100 batches): 3.3808, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 2.8391, lr: 1.22e-04\n",
      "Average loss (last 100 batches): 3.2099, lr: 1.23e-04\n",
      "Average loss (last 100 batches): 2.7901, lr: 1.24e-04\n",
      "Average loss (last 100 batches): 3.0218, lr: 1.25e-04\n",
      "Average loss (last 100 batches): 3.1144, lr: 1.26e-04\n",
      "Average loss (last 100 batches): 3.2918, lr: 1.27e-04\n",
      "Average loss (last 100 batches): 2.8634, lr: 1.28e-04\n",
      "Average loss (last 100 batches): 2.9163, lr: 1.29e-04\n",
      "Average loss (last 100 batches): 2.8247, lr: 1.30e-04\n",
      "Average loss (last 100 batches): 2.7320, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 3.0892, lr: 1.32e-04\n",
      "Average loss (last 100 batches): 2.6484, lr: 1.33e-04\n",
      "Average loss (last 100 batches): 2.8178, lr: 1.34e-04\n",
      "Average loss (last 100 batches): 2.8887, lr: 1.35e-04\n",
      "Average loss (last 100 batches): 2.6037, lr: 1.36e-04\n",
      "Average loss (last 100 batches): 2.4399, lr: 1.37e-04\n",
      "Average loss (last 100 batches): 2.6597, lr: 1.38e-04\n",
      "Average loss (last 100 batches): 2.5113, lr: 1.39e-04\n",
      "Average loss (last 100 batches): 2.4960, lr: 1.40e-04\n",
      "Average loss (last 100 batches): 2.5373, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 2.4328, lr: 1.42e-04\n",
      "Average loss (last 100 batches): 2.4481, lr: 1.43e-04\n",
      "Average loss (last 100 batches): 2.3607, lr: 1.44e-04\n",
      "Average loss (last 100 batches): 2.5813, lr: 1.45e-04\n",
      "Average loss (last 100 batches): 2.3918, lr: 1.46e-04\n",
      "Average loss (last 100 batches): 2.5560, lr: 1.47e-04\n",
      "Average loss (last 100 batches): 2.3420, lr: 1.48e-04\n",
      "Average loss (last 100 batches): 2.2470, lr: 1.49e-04\n",
      "Average loss (last 100 batches): 2.3003, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 2.3775, lr: 1.51e-04\n",
      "Average loss (last 100 batches): 2.5357, lr: 1.52e-04\n",
      "Average loss (last 100 batches): 2.1663, lr: 1.53e-04\n",
      "Average loss (last 100 batches): 2.7392, lr: 1.54e-04\n",
      "Average loss (last 100 batches): 2.2748, lr: 1.55e-04\n",
      "Average loss (last 100 batches): 2.3553, lr: 1.56e-04\n",
      "Average loss (last 100 batches): 2.2966, lr: 1.57e-04\n",
      "Average loss (last 100 batches): 2.2808, lr: 1.58e-04\n",
      "Average loss (last 100 batches): 2.2313, lr: 1.59e-04\n",
      "Average loss (last 100 batches): 2.4432, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 1.9977, lr: 1.61e-04\n",
      "Average loss (last 100 batches): 2.0502, lr: 1.62e-04\n",
      "Average loss (last 100 batches): 2.2223, lr: 1.63e-04\n",
      "Average loss (last 100 batches): 2.1776, lr: 1.64e-04\n",
      "Average loss (last 100 batches): 2.3327, lr: 1.65e-04\n",
      "Average loss (last 100 batches): 2.0697, lr: 1.66e-04\n",
      "Average loss (last 100 batches): 2.1082, lr: 1.67e-04\n",
      "Average loss (last 100 batches): 2.0050, lr: 1.68e-04\n",
      "Average loss (last 100 batches): 2.0276, lr: 1.69e-04\n",
      "Average loss (last 100 batches): 1.9989, lr: 1.70e-04\n",
      "Average loss (last 100 batches): 2.0169, lr: 1.71e-04\n",
      "Average loss (last 100 batches): 2.1806, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 2.4274, lr: 1.73e-04\n",
      "Average loss (last 100 batches): 1.8634, lr: 1.74e-04\n",
      "Average loss (last 100 batches): 2.1071, lr: 1.75e-04\n",
      "Average loss (last 100 batches): 1.9269, lr: 1.76e-04\n",
      "Average loss (last 100 batches): 1.9609, lr: 1.77e-04\n",
      "Average loss (last 100 batches): 1.9147, lr: 1.78e-04\n",
      "Average loss (last 100 batches): 1.8572, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 1.7572, lr: 1.80e-04\n",
      "Average loss (last 100 batches): 1.7664, lr: 1.81e-04\n",
      "Average loss (last 100 batches): 1.9024, lr: 1.82e-04\n",
      "Average loss (last 100 batches): 1.7976, lr: 1.83e-04\n",
      "Average loss (last 100 batches): 1.8184, lr: 1.84e-04\n",
      "Average loss (last 100 batches): 1.9077, lr: 1.85e-04\n",
      "Average loss (last 100 batches): 1.9436, lr: 1.86e-04\n",
      "Average loss (last 100 batches): 1.8454, lr: 1.87e-04\n",
      "Average loss (last 100 batches): 1.7005, lr: 1.88e-04\n",
      "Average loss (last 100 batches): 2.2116, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 1.8630, lr: 1.90e-04\n",
      "Average loss (last 100 batches): 1.7978, lr: 1.91e-04\n",
      "Average loss (last 100 batches): 1.9070, lr: 1.92e-04\n",
      "Average loss (last 100 batches): 1.8911, lr: 1.93e-04\n",
      "Average loss (last 100 batches): 1.8630, lr: 1.94e-04\n",
      "Average loss (last 100 batches): 1.9880, lr: 1.95e-04\n",
      "Average loss (last 100 batches): 1.9259, lr: 1.96e-04\n",
      "Average loss (last 100 batches): 1.8646, lr: 1.97e-04\n",
      "Average loss (last 100 batches): 1.8441, lr: 1.98e-04\n",
      "Average loss (last 100 batches): 1.7625, lr: 1.99e-04\n",
      "Average loss (last 100 batches): 1.7022, lr: 2.00e-04\n",
      "Average loss (last 100 batches): 1.9050, lr: 2.01e-04\n",
      "Average loss (last 100 batches): 1.7334, lr: 2.02e-04\n",
      "Average loss (last 100 batches): 1.5550, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 1.5608, lr: 2.04e-04\n",
      "Average loss (last 100 batches): 1.5341, lr: 2.05e-04\n",
      "Average loss (last 100 batches): 1.7516, lr: 2.06e-04\n",
      "Average loss (last 100 batches): 1.6553, lr: 2.07e-04\n",
      "Average loss (last 100 batches): 1.8736, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 1.4686, lr: 2.09e-04\n",
      "Average loss (last 100 batches): 1.5664, lr: 2.10e-04\n",
      "Average loss (last 100 batches): 1.4940, lr: 2.11e-04\n",
      "Average loss (last 100 batches): 1.4384, lr: 2.12e-04\n",
      "Average loss (last 100 batches): 1.6160, lr: 2.13e-04\n",
      "Average loss (last 100 batches): 1.5073, lr: 2.14e-04\n",
      "Average loss (last 100 batches): 1.6390, lr: 2.15e-04\n",
      "Average loss (last 100 batches): 1.8415, lr: 2.16e-04\n",
      "Average loss (last 100 batches): 1.4625, lr: 2.17e-04\n",
      "Average loss (last 100 batches): 1.4949, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 1.3502, lr: 2.19e-04\n",
      "Average loss (last 100 batches): 1.7124, lr: 2.20e-04\n",
      "Average loss (last 100 batches): 1.6006, lr: 2.21e-04\n",
      "Average loss (last 100 batches): 1.5987, lr: 2.22e-04\n",
      "Average loss (last 100 batches): 1.3078, lr: 2.23e-04\n",
      "Average loss (last 100 batches): 1.6399, lr: 2.24e-04\n",
      "Average loss (last 100 batches): 1.2801, lr: 2.25e-04\n",
      "Average loss (last 100 batches): 1.5475, lr: 2.26e-04\n",
      "Average loss (last 100 batches): 1.9164, lr: 2.27e-04\n",
      "Average loss (last 100 batches): 1.4250, lr: 2.28e-04\n",
      "Average loss (last 100 batches): 1.3382, lr: 2.29e-04\n",
      "Average loss (last 100 batches): 1.4369, lr: 2.30e-04\n",
      "Average loss (last 100 batches): 1.2362, lr: 2.31e-04\n",
      "Average loss (last 100 batches): 1.5169, lr: 2.32e-04\n",
      "Average loss (last 100 batches): 1.6818, lr: 2.33e-04\n",
      "Average loss (last 100 batches): 1.4742, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 1.3934, lr: 2.35e-04\n",
      "Average loss (last 100 batches): 1.4648, lr: 2.36e-04\n",
      "Average loss (last 100 batches): 1.4126, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 1.4411, lr: 2.38e-04\n",
      "Average loss (last 100 batches): 1.4207, lr: 2.39e-04\n",
      "Average loss (last 100 batches): 1.1781, lr: 2.40e-04\n",
      "Average loss (last 100 batches): 1.2278, lr: 2.41e-04\n",
      "Average loss (last 100 batches): 1.4605, lr: 2.42e-04\n",
      "Average loss (last 100 batches): 1.4738, lr: 2.43e-04\n",
      "Average loss (last 100 batches): 1.2177, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 1.6122, lr: 2.45e-04\n",
      "Average loss (last 100 batches): 1.2311, lr: 2.46e-04\n",
      "Average loss (last 100 batches): 1.1631, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 1.1939, lr: 2.48e-04\n",
      "Average loss (last 100 batches): 1.1439, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 1.2435, lr: 2.50e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea557293bbed46e49f27ed0b5ae16130"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Train Loss: 4.7426 | Test Loss: 47632388009258.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd8b8a543fe5481c88fc67c01dec2ee5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 1.2096, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 1.4338, lr: 2.52e-04\n",
      "Average loss (last 100 batches): 1.2666, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 1.2669, lr: 2.54e-04\n",
      "Average loss (last 100 batches): 1.1993, lr: 2.55e-04\n",
      "Average loss (last 100 batches): 1.2912, lr: 2.56e-04\n",
      "Average loss (last 100 batches): 1.3233, lr: 2.57e-04\n",
      "Average loss (last 100 batches): 1.1999, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 1.4589, lr: 2.59e-04\n",
      "Average loss (last 100 batches): 1.2408, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 1.0920, lr: 2.61e-04\n",
      "Average loss (last 100 batches): 1.2881, lr: 2.62e-04\n",
      "Average loss (last 100 batches): 1.4501, lr: 2.63e-04\n",
      "Average loss (last 100 batches): 1.1006, lr: 2.64e-04\n",
      "Average loss (last 100 batches): 1.3288, lr: 2.65e-04\n",
      "Average loss (last 100 batches): 1.1885, lr: 2.66e-04\n",
      "Average loss (last 100 batches): 1.1111, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 1.2471, lr: 2.68e-04\n",
      "Average loss (last 100 batches): 1.1267, lr: 2.69e-04\n",
      "Average loss (last 100 batches): 1.1639, lr: 2.70e-04\n",
      "Average loss (last 100 batches): 1.1429, lr: 2.71e-04\n",
      "Average loss (last 100 batches): 1.2607, lr: 2.72e-04\n",
      "Average loss (last 100 batches): 1.2923, lr: 2.73e-04\n",
      "Average loss (last 100 batches): 1.1238, lr: 2.74e-04\n",
      "Average loss (last 100 batches): 1.3260, lr: 2.75e-04\n",
      "Average loss (last 100 batches): 1.2414, lr: 2.76e-04\n",
      "Average loss (last 100 batches): 1.2935, lr: 2.77e-04\n",
      "Average loss (last 100 batches): 1.1513, lr: 2.78e-04\n",
      "Average loss (last 100 batches): 1.8044, lr: 2.79e-04\n",
      "Average loss (last 100 batches): 1.1287, lr: 2.80e-04\n",
      "Average loss (last 100 batches): 1.0789, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 1.1923, lr: 2.82e-04\n",
      "Average loss (last 100 batches): 1.3461, lr: 2.83e-04\n",
      "Average loss (last 100 batches): 1.1301, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 1.3349, lr: 2.85e-04\n",
      "Average loss (last 100 batches): 1.2339, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 1.1333, lr: 2.87e-04\n",
      "Average loss (last 100 batches): 1.2575, lr: 2.88e-04\n",
      "Average loss (last 100 batches): 1.1326, lr: 2.89e-04\n",
      "Average loss (last 100 batches): 1.0080, lr: 2.90e-04\n",
      "Average loss (last 100 batches): 1.1040, lr: 2.91e-04\n",
      "Average loss (last 100 batches): 0.9672, lr: 2.92e-04\n",
      "Average loss (last 100 batches): 0.9750, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 1.5198, lr: 2.94e-04\n",
      "Average loss (last 100 batches): 1.1657, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 1.2475, lr: 2.96e-04\n",
      "Average loss (last 100 batches): 1.4132, lr: 2.97e-04\n",
      "Average loss (last 100 batches): 1.5643, lr: 2.98e-04\n",
      "Average loss (last 100 batches): 1.1727, lr: 2.99e-04\n",
      "Average loss (last 100 batches): 1.3706, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.9672, lr: 3.01e-04\n",
      "Average loss (last 100 batches): 1.0768, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 1.0822, lr: 3.03e-04\n",
      "Average loss (last 100 batches): 1.2875, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.9790, lr: 3.05e-04\n",
      "Average loss (last 100 batches): 1.0506, lr: 3.06e-04\n",
      "Average loss (last 100 batches): 1.1056, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 1.0083, lr: 3.08e-04\n",
      "Average loss (last 100 batches): 1.0718, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 1.1187, lr: 3.10e-04\n",
      "Average loss (last 100 batches): 1.1924, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.9766, lr: 3.12e-04\n",
      "Average loss (last 100 batches): 1.0891, lr: 3.13e-04\n",
      "Average loss (last 100 batches): 1.1653, lr: 3.14e-04\n",
      "Average loss (last 100 batches): 1.1418, lr: 3.15e-04\n",
      "Average loss (last 100 batches): 1.2286, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 1.1692, lr: 3.17e-04\n",
      "Average loss (last 100 batches): 1.2638, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 1.2372, lr: 3.19e-04\n",
      "Average loss (last 100 batches): 1.1043, lr: 3.20e-04\n",
      "Average loss (last 100 batches): 1.0686, lr: 3.21e-04\n",
      "Average loss (last 100 batches): 0.9605, lr: 3.22e-04\n",
      "Average loss (last 100 batches): 1.0107, lr: 3.23e-04\n",
      "Average loss (last 100 batches): 1.0982, lr: 3.24e-04\n",
      "Average loss (last 100 batches): 0.9494, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 1.2094, lr: 3.26e-04\n",
      "Average loss (last 100 batches): 1.0004, lr: 3.27e-04\n",
      "Average loss (last 100 batches): 1.1434, lr: 3.28e-04\n",
      "Average loss (last 100 batches): 1.1475, lr: 3.29e-04\n",
      "Average loss (last 100 batches): 1.0511, lr: 3.30e-04\n",
      "Average loss (last 100 batches): 1.0846, lr: 3.31e-04\n",
      "Average loss (last 100 batches): 1.1217, lr: 3.32e-04\n",
      "Average loss (last 100 batches): 0.9580, lr: 3.33e-04\n",
      "Average loss (last 100 batches): 1.0908, lr: 3.34e-04\n",
      "Average loss (last 100 batches): 0.9106, lr: 3.35e-04\n",
      "Average loss (last 100 batches): 0.9435, lr: 3.36e-04\n",
      "Average loss (last 100 batches): 1.0266, lr: 3.37e-04\n",
      "Average loss (last 100 batches): 1.3614, lr: 3.38e-04\n",
      "Average loss (last 100 batches): 1.3177, lr: 3.39e-04\n",
      "Average loss (last 100 batches): 1.2142, lr: 3.40e-04\n",
      "Average loss (last 100 batches): 1.1516, lr: 3.41e-04\n",
      "Average loss (last 100 batches): 1.1291, lr: 3.42e-04\n",
      "Average loss (last 100 batches): 0.9674, lr: 3.43e-04\n",
      "Average loss (last 100 batches): 1.1095, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 1.1136, lr: 3.45e-04\n",
      "Average loss (last 100 batches): 1.1175, lr: 3.46e-04\n",
      "Average loss (last 100 batches): 1.0248, lr: 3.47e-04\n",
      "Average loss (last 100 batches): 0.9167, lr: 3.48e-04\n",
      "Average loss (last 100 batches): 0.9405, lr: 3.49e-04\n",
      "Average loss (last 100 batches): 1.0922, lr: 3.50e-04\n",
      "Average loss (last 100 batches): 0.9447, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.9826, lr: 3.52e-04\n",
      "Average loss (last 100 batches): 0.9328, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 1.0280, lr: 3.54e-04\n",
      "Average loss (last 100 batches): 1.0613, lr: 3.55e-04\n",
      "Average loss (last 100 batches): 1.1811, lr: 3.56e-04\n",
      "Average loss (last 100 batches): 1.0711, lr: 3.57e-04\n",
      "Average loss (last 100 batches): 1.2197, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 1.1666, lr: 3.59e-04\n",
      "Average loss (last 100 batches): 1.1903, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 1.0547, lr: 3.61e-04\n",
      "Average loss (last 100 batches): 1.0090, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.8809, lr: 3.63e-04\n",
      "Average loss (last 100 batches): 1.2017, lr: 3.64e-04\n",
      "Average loss (last 100 batches): 1.0330, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.9543, lr: 3.66e-04\n",
      "Average loss (last 100 batches): 1.1593, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 1.2008, lr: 3.68e-04\n",
      "Average loss (last 100 batches): 0.9518, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 1.3369, lr: 3.70e-04\n",
      "Average loss (last 100 batches): 0.9185, lr: 3.71e-04\n",
      "Average loss (last 100 batches): 1.2215, lr: 3.72e-04\n",
      "Average loss (last 100 batches): 0.9677, lr: 3.73e-04\n",
      "Average loss (last 100 batches): 0.9499, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 1.2596, lr: 3.75e-04\n",
      "Average loss (last 100 batches): 1.1848, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 1.0284, lr: 3.77e-04\n",
      "Average loss (last 100 batches): 1.0311, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 1.0253, lr: 3.79e-04\n",
      "Average loss (last 100 batches): 0.9542, lr: 3.80e-04\n",
      "Average loss (last 100 batches): 1.0426, lr: 3.81e-04\n",
      "Average loss (last 100 batches): 1.0355, lr: 3.82e-04\n",
      "Average loss (last 100 batches): 0.9867, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 1.0312, lr: 3.84e-04\n",
      "Average loss (last 100 batches): 0.8543, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.9677, lr: 3.86e-04\n",
      "Average loss (last 100 batches): 0.8798, lr: 3.87e-04\n",
      "Average loss (last 100 batches): 1.0328, lr: 3.88e-04\n",
      "Average loss (last 100 batches): 1.0231, lr: 3.89e-04\n",
      "Average loss (last 100 batches): 0.8909, lr: 3.90e-04\n",
      "Average loss (last 100 batches): 0.8552, lr: 3.91e-04\n",
      "Average loss (last 100 batches): 0.8905, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 1.2393, lr: 3.93e-04\n",
      "Average loss (last 100 batches): 1.0133, lr: 3.94e-04\n",
      "Average loss (last 100 batches): 0.9143, lr: 3.95e-04\n",
      "Average loss (last 100 batches): 0.8934, lr: 3.96e-04\n",
      "Average loss (last 100 batches): 1.0974, lr: 3.97e-04\n",
      "Average loss (last 100 batches): 1.2311, lr: 3.98e-04\n",
      "Average loss (last 100 batches): 1.1578, lr: 3.99e-04\n",
      "Average loss (last 100 batches): 0.8920, lr: 4.00e-04\n",
      "Average loss (last 100 batches): 1.0074, lr: 4.01e-04\n",
      "Average loss (last 100 batches): 1.6452, lr: 4.02e-04\n",
      "Average loss (last 100 batches): 1.0849, lr: 4.03e-04\n",
      "Average loss (last 100 batches): 1.0419, lr: 4.04e-04\n",
      "Average loss (last 100 batches): 0.8371, lr: 4.05e-04\n",
      "Average loss (last 100 batches): 0.9843, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.8441, lr: 4.07e-04\n",
      "Average loss (last 100 batches): 1.0851, lr: 4.08e-04\n",
      "Average loss (last 100 batches): 1.0241, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 1.1186, lr: 4.10e-04\n",
      "Average loss (last 100 batches): 0.9465, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.9492, lr: 4.12e-04\n",
      "Average loss (last 100 batches): 1.0187, lr: 4.13e-04\n",
      "Average loss (last 100 batches): 0.9668, lr: 4.14e-04\n",
      "Average loss (last 100 batches): 0.8922, lr: 4.15e-04\n",
      "Average loss (last 100 batches): 0.9846, lr: 4.16e-04\n",
      "Average loss (last 100 batches): 0.9034, lr: 4.17e-04\n",
      "Average loss (last 100 batches): 0.9270, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 0.9079, lr: 4.19e-04\n",
      "Average loss (last 100 batches): 0.9580, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 1.0382, lr: 4.21e-04\n",
      "Average loss (last 100 batches): 1.0158, lr: 4.22e-04\n",
      "Average loss (last 100 batches): 1.1253, lr: 4.23e-04\n",
      "Average loss (last 100 batches): 1.0448, lr: 4.24e-04\n",
      "Average loss (last 100 batches): 1.0816, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 1.0346, lr: 4.26e-04\n",
      "Average loss (last 100 batches): 0.8068, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.7742, lr: 4.28e-04\n",
      "Average loss (last 100 batches): 1.1465, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.8380, lr: 4.30e-04\n",
      "Average loss (last 100 batches): 0.9558, lr: 4.31e-04\n",
      "Average loss (last 100 batches): 0.8253, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 1.0166, lr: 4.33e-04\n",
      "Average loss (last 100 batches): 0.9393, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.9409, lr: 4.35e-04\n",
      "Average loss (last 100 batches): 0.8831, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 0.8204, lr: 4.37e-04\n",
      "Average loss (last 100 batches): 0.8137, lr: 4.38e-04\n",
      "Average loss (last 100 batches): 1.0228, lr: 4.39e-04\n",
      "Average loss (last 100 batches): 0.9905, lr: 4.40e-04\n",
      "Average loss (last 100 batches): 1.0847, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 1.0366, lr: 4.42e-04\n",
      "Average loss (last 100 batches): 1.0556, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.8931, lr: 4.44e-04\n",
      "Average loss (last 100 batches): 0.9121, lr: 4.45e-04\n",
      "Average loss (last 100 batches): 0.8972, lr: 4.46e-04\n",
      "Average loss (last 100 batches): 0.8370, lr: 4.47e-04\n",
      "Average loss (last 100 batches): 0.8718, lr: 4.48e-04\n",
      "Average loss (last 100 batches): 0.7524, lr: 4.49e-04\n",
      "Average loss (last 100 batches): 0.7842, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 1.0193, lr: 4.51e-04\n",
      "Average loss (last 100 batches): 1.1054, lr: 4.52e-04\n",
      "Average loss (last 100 batches): 1.1426, lr: 4.53e-04\n",
      "Average loss (last 100 batches): 1.0706, lr: 4.54e-04\n",
      "Average loss (last 100 batches): 1.2089, lr: 4.55e-04\n",
      "Average loss (last 100 batches): 0.9531, lr: 4.56e-04\n",
      "Average loss (last 100 batches): 1.1619, lr: 4.57e-04\n",
      "Average loss (last 100 batches): 0.8778, lr: 4.58e-04\n",
      "Average loss (last 100 batches): 0.9968, lr: 4.59e-04\n",
      "Average loss (last 100 batches): 0.9242, lr: 4.60e-04\n",
      "Average loss (last 100 batches): 1.3040, lr: 4.61e-04\n",
      "Average loss (last 100 batches): 0.8575, lr: 4.62e-04\n",
      "Average loss (last 100 batches): 1.0108, lr: 4.63e-04\n",
      "Average loss (last 100 batches): 0.8276, lr: 4.64e-04\n",
      "Average loss (last 100 batches): 0.9498, lr: 4.65e-04\n",
      "Average loss (last 100 batches): 0.9820, lr: 4.66e-04\n",
      "Average loss (last 100 batches): 0.9507, lr: 4.67e-04\n",
      "Average loss (last 100 batches): 1.0135, lr: 4.68e-04\n",
      "Average loss (last 100 batches): 1.1225, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.8409, lr: 4.70e-04\n",
      "Average loss (last 100 batches): 1.0093, lr: 4.71e-04\n",
      "Average loss (last 100 batches): 0.8299, lr: 4.72e-04\n",
      "Average loss (last 100 batches): 0.8818, lr: 4.73e-04\n",
      "Average loss (last 100 batches): 0.8603, lr: 4.74e-04\n",
      "Average loss (last 100 batches): 0.8384, lr: 4.75e-04\n",
      "Average loss (last 100 batches): 0.8183, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 0.8933, lr: 4.77e-04\n",
      "Average loss (last 100 batches): 0.9885, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 0.7943, lr: 4.79e-04\n",
      "Average loss (last 100 batches): 0.8908, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 0.7909, lr: 4.81e-04\n",
      "Average loss (last 100 batches): 0.7770, lr: 4.82e-04\n",
      "Average loss (last 100 batches): 0.8004, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.7924, lr: 4.84e-04\n",
      "Average loss (last 100 batches): 0.7760, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 1.0402, lr: 4.86e-04\n",
      "Average loss (last 100 batches): 0.9381, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 0.9699, lr: 4.88e-04\n",
      "Average loss (last 100 batches): 1.1791, lr: 4.89e-04\n",
      "Average loss (last 100 batches): 0.8597, lr: 4.90e-04\n",
      "Average loss (last 100 batches): 0.7912, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 0.9844, lr: 4.92e-04\n",
      "Average loss (last 100 batches): 0.9739, lr: 4.93e-04\n",
      "Average loss (last 100 batches): 0.9135, lr: 4.94e-04\n",
      "Average loss (last 100 batches): 0.8629, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 0.8203, lr: 4.96e-04\n",
      "Average loss (last 100 batches): 1.1019, lr: 4.97e-04\n",
      "Average loss (last 100 batches): 0.9301, lr: 4.98e-04\n",
      "Average loss (last 100 batches): 0.8006, lr: 4.99e-04\n",
      "Average loss (last 100 batches): 1.0280, lr: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d2f278e872a4216b4ddf3c84c5e739f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Train Loss: 1.0572 | Test Loss: 46683249248206.3203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "904eeb8a43a4448eb498aac2712d365e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.8456, lr: 5.00e-04\n",
      "Average loss (last 100 batches): 1.1094, lr: 5.00e-04\n",
      "Average loss (last 100 batches): 0.9049, lr: 4.99e-04\n",
      "Average loss (last 100 batches): 1.0024, lr: 4.99e-04\n",
      "Average loss (last 100 batches): 1.0204, lr: 4.99e-04\n",
      "Average loss (last 100 batches): 1.1085, lr: 4.99e-04\n",
      "Average loss (last 100 batches): 0.9810, lr: 4.98e-04\n",
      "Average loss (last 100 batches): 0.9987, lr: 4.98e-04\n",
      "Average loss (last 100 batches): 0.8545, lr: 4.98e-04\n",
      "Average loss (last 100 batches): 0.9192, lr: 4.98e-04\n",
      "Average loss (last 100 batches): 0.8779, lr: 4.97e-04\n",
      "Average loss (last 100 batches): 0.8613, lr: 4.97e-04\n",
      "Average loss (last 100 batches): 0.8256, lr: 4.97e-04\n",
      "Average loss (last 100 batches): 1.0480, lr: 4.96e-04\n",
      "Average loss (last 100 batches): 0.9077, lr: 4.96e-04\n",
      "Average loss (last 100 batches): 1.0123, lr: 4.96e-04\n",
      "Average loss (last 100 batches): 0.8837, lr: 4.96e-04\n",
      "Average loss (last 100 batches): 0.8094, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 0.8035, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 0.9032, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 0.7732, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 0.8183, lr: 4.95e-04\n",
      "Average loss (last 100 batches): 1.1189, lr: 4.94e-04\n",
      "Average loss (last 100 batches): 1.1092, lr: 4.94e-04\n",
      "Average loss (last 100 batches): 1.2752, lr: 4.94e-04\n",
      "Average loss (last 100 batches): 1.2995, lr: 4.94e-04\n",
      "Average loss (last 100 batches): 1.0620, lr: 4.93e-04\n",
      "Average loss (last 100 batches): 1.0083, lr: 4.93e-04\n",
      "Average loss (last 100 batches): 1.1314, lr: 4.93e-04\n",
      "Average loss (last 100 batches): 0.8606, lr: 4.92e-04\n",
      "Average loss (last 100 batches): 1.2270, lr: 4.92e-04\n",
      "Average loss (last 100 batches): 0.9598, lr: 4.92e-04\n",
      "Average loss (last 100 batches): 1.0474, lr: 4.92e-04\n",
      "Average loss (last 100 batches): 0.8140, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 0.8903, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 0.9775, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 0.9768, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 0.8515, lr: 4.91e-04\n",
      "Average loss (last 100 batches): 1.0068, lr: 4.90e-04\n",
      "Average loss (last 100 batches): 0.8969, lr: 4.90e-04\n",
      "Average loss (last 100 batches): 0.9546, lr: 4.90e-04\n",
      "Average loss (last 100 batches): 0.9956, lr: 4.90e-04\n",
      "Average loss (last 100 batches): 0.7523, lr: 4.89e-04\n",
      "Average loss (last 100 batches): 0.8573, lr: 4.89e-04\n",
      "Average loss (last 100 batches): 0.6930, lr: 4.89e-04\n",
      "Average loss (last 100 batches): 0.8165, lr: 4.89e-04\n",
      "Average loss (last 100 batches): 0.7740, lr: 4.88e-04\n",
      "Average loss (last 100 batches): 0.7721, lr: 4.88e-04\n",
      "Average loss (last 100 batches): 0.8419, lr: 4.88e-04\n",
      "Average loss (last 100 batches): 0.7523, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 1.0059, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 1.0588, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 1.0262, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 0.8593, lr: 4.87e-04\n",
      "Average loss (last 100 batches): 0.7178, lr: 4.86e-04\n",
      "Average loss (last 100 batches): 0.7363, lr: 4.86e-04\n",
      "Average loss (last 100 batches): 0.7592, lr: 4.86e-04\n",
      "Average loss (last 100 batches): 0.7631, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 0.8362, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 1.0684, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 0.7952, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 0.8702, lr: 4.85e-04\n",
      "Average loss (last 100 batches): 0.7854, lr: 4.84e-04\n",
      "Average loss (last 100 batches): 0.7752, lr: 4.84e-04\n",
      "Average loss (last 100 batches): 0.9197, lr: 4.84e-04\n",
      "Average loss (last 100 batches): 0.9856, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.7574, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.9151, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.8351, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.8270, lr: 4.83e-04\n",
      "Average loss (last 100 batches): 0.8623, lr: 4.82e-04\n",
      "Average loss (last 100 batches): 0.7434, lr: 4.82e-04\n",
      "Average loss (last 100 batches): 0.9454, lr: 4.82e-04\n",
      "Average loss (last 100 batches): 1.1524, lr: 4.81e-04\n",
      "Average loss (last 100 batches): 0.8813, lr: 4.81e-04\n",
      "Average loss (last 100 batches): 0.7551, lr: 4.81e-04\n",
      "Average loss (last 100 batches): 0.7652, lr: 4.81e-04\n",
      "Average loss (last 100 batches): 0.8252, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 0.8793, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 0.7242, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 0.8632, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 1.0178, lr: 4.80e-04\n",
      "Average loss (last 100 batches): 0.8653, lr: 4.79e-04\n",
      "Average loss (last 100 batches): 0.7989, lr: 4.79e-04\n",
      "Average loss (last 100 batches): 0.8327, lr: 4.79e-04\n",
      "Average loss (last 100 batches): 0.6813, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 0.8866, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 1.0787, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 0.8231, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 0.8967, lr: 4.78e-04\n",
      "Average loss (last 100 batches): 1.2362, lr: 4.77e-04\n",
      "Average loss (last 100 batches): 0.8153, lr: 4.77e-04\n",
      "Average loss (last 100 batches): 0.8190, lr: 4.77e-04\n",
      "Average loss (last 100 batches): 1.2405, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 0.7759, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 0.9004, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 0.7333, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 0.7346, lr: 4.76e-04\n",
      "Average loss (last 100 batches): 1.0697, lr: 4.75e-04\n",
      "Average loss (last 100 batches): 0.9315, lr: 4.75e-04\n",
      "Average loss (last 100 batches): 0.9309, lr: 4.75e-04\n",
      "Average loss (last 100 batches): 0.7168, lr: 4.74e-04\n",
      "Average loss (last 100 batches): 0.6755, lr: 4.74e-04\n",
      "Average loss (last 100 batches): 0.7248, lr: 4.74e-04\n",
      "Average loss (last 100 batches): 1.0825, lr: 4.74e-04\n",
      "Average loss (last 100 batches): 0.7472, lr: 4.73e-04\n",
      "Average loss (last 100 batches): 0.9384, lr: 4.73e-04\n",
      "Average loss (last 100 batches): 1.0158, lr: 4.73e-04\n",
      "Average loss (last 100 batches): 0.8238, lr: 4.73e-04\n",
      "Average loss (last 100 batches): 0.7619, lr: 4.72e-04\n",
      "Average loss (last 100 batches): 0.8523, lr: 4.72e-04\n",
      "Average loss (last 100 batches): 0.7758, lr: 4.72e-04\n",
      "Average loss (last 100 batches): 0.7893, lr: 4.72e-04\n",
      "Average loss (last 100 batches): 0.9555, lr: 4.71e-04\n",
      "Average loss (last 100 batches): 1.0100, lr: 4.71e-04\n",
      "Average loss (last 100 batches): 0.9071, lr: 4.71e-04\n",
      "Average loss (last 100 batches): 0.8888, lr: 4.71e-04\n",
      "Average loss (last 100 batches): 0.8751, lr: 4.70e-04\n",
      "Average loss (last 100 batches): 0.7157, lr: 4.70e-04\n",
      "Average loss (last 100 batches): 0.7997, lr: 4.70e-04\n",
      "Average loss (last 100 batches): 0.6307, lr: 4.70e-04\n",
      "Average loss (last 100 batches): 0.7348, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.8891, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.9886, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.9374, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.8166, lr: 4.69e-04\n",
      "Average loss (last 100 batches): 0.9841, lr: 4.68e-04\n",
      "Average loss (last 100 batches): 0.9519, lr: 4.68e-04\n",
      "Average loss (last 100 batches): 0.8162, lr: 4.68e-04\n",
      "Average loss (last 100 batches): 0.9168, lr: 4.68e-04\n",
      "Average loss (last 100 batches): 0.8253, lr: 4.67e-04\n",
      "Average loss (last 100 batches): 1.0025, lr: 4.67e-04\n",
      "Average loss (last 100 batches): 0.7538, lr: 4.67e-04\n",
      "Average loss (last 100 batches): 1.0017, lr: 4.67e-04\n",
      "Average loss (last 100 batches): 0.9482, lr: 4.66e-04\n",
      "Average loss (last 100 batches): 0.8518, lr: 4.66e-04\n",
      "Average loss (last 100 batches): 1.1070, lr: 4.66e-04\n",
      "Average loss (last 100 batches): 0.9762, lr: 4.66e-04\n",
      "Average loss (last 100 batches): 0.8619, lr: 4.65e-04\n",
      "Average loss (last 100 batches): 0.7551, lr: 4.65e-04\n",
      "Average loss (last 100 batches): 0.9201, lr: 4.65e-04\n",
      "Average loss (last 100 batches): 0.8301, lr: 4.65e-04\n",
      "Average loss (last 100 batches): 0.8687, lr: 4.64e-04\n",
      "Average loss (last 100 batches): 0.7445, lr: 4.64e-04\n",
      "Average loss (last 100 batches): 0.7117, lr: 4.64e-04\n",
      "Average loss (last 100 batches): 0.9784, lr: 4.64e-04\n",
      "Average loss (last 100 batches): 0.6373, lr: 4.63e-04\n",
      "Average loss (last 100 batches): 0.6980, lr: 4.63e-04\n",
      "Average loss (last 100 batches): 0.6666, lr: 4.63e-04\n",
      "Average loss (last 100 batches): 0.7694, lr: 4.63e-04\n",
      "Average loss (last 100 batches): 0.7295, lr: 4.62e-04\n",
      "Average loss (last 100 batches): 0.7727, lr: 4.62e-04\n",
      "Average loss (last 100 batches): 0.8761, lr: 4.62e-04\n",
      "Average loss (last 100 batches): 0.7517, lr: 4.62e-04\n",
      "Average loss (last 100 batches): 0.7539, lr: 4.61e-04\n",
      "Average loss (last 100 batches): 1.1662, lr: 4.61e-04\n",
      "Average loss (last 100 batches): 0.8415, lr: 4.61e-04\n",
      "Average loss (last 100 batches): 0.9126, lr: 4.61e-04\n",
      "Average loss (last 100 batches): 1.0807, lr: 4.60e-04\n",
      "Average loss (last 100 batches): 0.7314, lr: 4.60e-04\n",
      "Average loss (last 100 batches): 0.7853, lr: 4.60e-04\n",
      "Average loss (last 100 batches): 0.8328, lr: 4.60e-04\n",
      "Average loss (last 100 batches): 0.7548, lr: 4.59e-04\n",
      "Average loss (last 100 batches): 0.7800, lr: 4.59e-04\n",
      "Average loss (last 100 batches): 0.9555, lr: 4.59e-04\n",
      "Average loss (last 100 batches): 0.7593, lr: 4.59e-04\n",
      "Average loss (last 100 batches): 0.9204, lr: 4.58e-04\n",
      "Average loss (last 100 batches): 0.9632, lr: 4.58e-04\n",
      "Average loss (last 100 batches): 0.8216, lr: 4.58e-04\n",
      "Average loss (last 100 batches): 0.7083, lr: 4.58e-04\n",
      "Average loss (last 100 batches): 0.8681, lr: 4.57e-04\n",
      "Average loss (last 100 batches): 0.7761, lr: 4.57e-04\n",
      "Average loss (last 100 batches): 0.7138, lr: 4.57e-04\n",
      "Average loss (last 100 batches): 0.7256, lr: 4.57e-04\n",
      "Average loss (last 100 batches): 0.7300, lr: 4.56e-04\n",
      "Average loss (last 100 batches): 0.6555, lr: 4.56e-04\n",
      "Average loss (last 100 batches): 0.6313, lr: 4.56e-04\n",
      "Average loss (last 100 batches): 0.6466, lr: 4.56e-04\n",
      "Average loss (last 100 batches): 0.6124, lr: 4.55e-04\n",
      "Average loss (last 100 batches): 1.0420, lr: 4.55e-04\n",
      "Average loss (last 100 batches): 0.7362, lr: 4.55e-04\n",
      "Average loss (last 100 batches): 0.7210, lr: 4.55e-04\n",
      "Average loss (last 100 batches): 0.9557, lr: 4.54e-04\n",
      "Average loss (last 100 batches): 0.9241, lr: 4.54e-04\n",
      "Average loss (last 100 batches): 0.7712, lr: 4.54e-04\n",
      "Average loss (last 100 batches): 0.7780, lr: 4.54e-04\n",
      "Average loss (last 100 batches): 0.9793, lr: 4.53e-04\n",
      "Average loss (last 100 batches): 0.9662, lr: 4.53e-04\n",
      "Average loss (last 100 batches): 1.2215, lr: 4.53e-04\n",
      "Average loss (last 100 batches): 0.7470, lr: 4.53e-04\n",
      "Average loss (last 100 batches): 0.7778, lr: 4.52e-04\n",
      "Average loss (last 100 batches): 0.8205, lr: 4.52e-04\n",
      "Average loss (last 100 batches): 0.6638, lr: 4.52e-04\n",
      "Average loss (last 100 batches): 0.7036, lr: 4.52e-04\n",
      "Average loss (last 100 batches): 0.7492, lr: 4.51e-04\n",
      "Average loss (last 100 batches): 0.7474, lr: 4.51e-04\n",
      "Average loss (last 100 batches): 0.8017, lr: 4.51e-04\n",
      "Average loss (last 100 batches): 0.7227, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 0.6537, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 0.8437, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 0.8826, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 0.7249, lr: 4.50e-04\n",
      "Average loss (last 100 batches): 0.7015, lr: 4.49e-04\n",
      "Average loss (last 100 batches): 0.7151, lr: 4.49e-04\n",
      "Average loss (last 100 batches): 0.6926, lr: 4.49e-04\n",
      "Average loss (last 100 batches): 0.9113, lr: 4.49e-04\n",
      "Average loss (last 100 batches): 0.6476, lr: 4.48e-04\n",
      "Average loss (last 100 batches): 1.0100, lr: 4.48e-04\n",
      "Average loss (last 100 batches): 0.7143, lr: 4.48e-04\n",
      "Average loss (last 100 batches): 0.7220, lr: 4.48e-04\n",
      "Average loss (last 100 batches): 0.8851, lr: 4.47e-04\n",
      "Average loss (last 100 batches): 0.6766, lr: 4.47e-04\n",
      "Average loss (last 100 batches): 0.7987, lr: 4.47e-04\n",
      "Average loss (last 100 batches): 0.9393, lr: 4.47e-04\n",
      "Average loss (last 100 batches): 0.7183, lr: 4.46e-04\n",
      "Average loss (last 100 batches): 0.9534, lr: 4.46e-04\n",
      "Average loss (last 100 batches): 0.7881, lr: 4.46e-04\n",
      "Average loss (last 100 batches): 0.8323, lr: 4.46e-04\n",
      "Average loss (last 100 batches): 0.7550, lr: 4.45e-04\n",
      "Average loss (last 100 batches): 0.8548, lr: 4.45e-04\n",
      "Average loss (last 100 batches): 0.6996, lr: 4.45e-04\n",
      "Average loss (last 100 batches): 0.7135, lr: 4.45e-04\n",
      "Average loss (last 100 batches): 0.7130, lr: 4.44e-04\n",
      "Average loss (last 100 batches): 0.8265, lr: 4.44e-04\n",
      "Average loss (last 100 batches): 0.7758, lr: 4.44e-04\n",
      "Average loss (last 100 batches): 0.8504, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.7646, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.6073, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.7597, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.7379, lr: 4.43e-04\n",
      "Average loss (last 100 batches): 0.8239, lr: 4.42e-04\n",
      "Average loss (last 100 batches): 0.7850, lr: 4.42e-04\n",
      "Average loss (last 100 batches): 0.6973, lr: 4.42e-04\n",
      "Average loss (last 100 batches): 0.7491, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 1.0591, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 0.8001, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 0.8633, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 0.7598, lr: 4.41e-04\n",
      "Average loss (last 100 batches): 0.7772, lr: 4.40e-04\n",
      "Average loss (last 100 batches): 0.8680, lr: 4.40e-04\n",
      "Average loss (last 100 batches): 0.7776, lr: 4.40e-04\n",
      "Average loss (last 100 batches): 0.6870, lr: 4.40e-04\n",
      "Average loss (last 100 batches): 0.6485, lr: 4.39e-04\n",
      "Average loss (last 100 batches): 0.7847, lr: 4.39e-04\n",
      "Average loss (last 100 batches): 0.8874, lr: 4.39e-04\n",
      "Average loss (last 100 batches): 0.6394, lr: 4.39e-04\n",
      "Average loss (last 100 batches): 0.6359, lr: 4.38e-04\n",
      "Average loss (last 100 batches): 0.6481, lr: 4.38e-04\n",
      "Average loss (last 100 batches): 0.6056, lr: 4.38e-04\n",
      "Average loss (last 100 batches): 0.6690, lr: 4.38e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "838bfb732e3441d498eabfd532e69b50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Train Loss: 0.8500 | Test Loss: 49260364628865.7188\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c99921b7bfd545238ae91d03d91de96b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.5990, lr: 4.37e-04\n",
      "Average loss (last 100 batches): 0.8301, lr: 4.37e-04\n",
      "Average loss (last 100 batches): 0.7893, lr: 4.37e-04\n",
      "Average loss (last 100 batches): 0.6204, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 1.0170, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 0.8431, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 0.8215, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 0.6496, lr: 4.36e-04\n",
      "Average loss (last 100 batches): 0.7371, lr: 4.35e-04\n",
      "Average loss (last 100 batches): 0.9302, lr: 4.35e-04\n",
      "Average loss (last 100 batches): 0.7298, lr: 4.35e-04\n",
      "Average loss (last 100 batches): 0.9703, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.7597, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.6552, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.8019, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.6256, lr: 4.34e-04\n",
      "Average loss (last 100 batches): 0.7226, lr: 4.33e-04\n",
      "Average loss (last 100 batches): 0.9142, lr: 4.33e-04\n",
      "Average loss (last 100 batches): 0.7080, lr: 4.33e-04\n",
      "Average loss (last 100 batches): 0.8349, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 0.7294, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 0.7806, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 0.7880, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 0.7608, lr: 4.32e-04\n",
      "Average loss (last 100 batches): 0.6575, lr: 4.31e-04\n",
      "Average loss (last 100 batches): 0.6309, lr: 4.31e-04\n",
      "Average loss (last 100 batches): 0.9047, lr: 4.31e-04\n",
      "Average loss (last 100 batches): 0.7429, lr: 4.31e-04\n",
      "Average loss (last 100 batches): 0.6140, lr: 4.30e-04\n",
      "Average loss (last 100 batches): 0.7023, lr: 4.30e-04\n",
      "Average loss (last 100 batches): 0.6397, lr: 4.30e-04\n",
      "Average loss (last 100 batches): 0.6630, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.8907, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.9794, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.9234, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.7077, lr: 4.29e-04\n",
      "Average loss (last 100 batches): 0.7178, lr: 4.28e-04\n",
      "Average loss (last 100 batches): 0.6478, lr: 4.28e-04\n",
      "Average loss (last 100 batches): 0.6355, lr: 4.28e-04\n",
      "Average loss (last 100 batches): 0.6347, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.6430, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.6158, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.6586, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.7586, lr: 4.27e-04\n",
      "Average loss (last 100 batches): 0.7582, lr: 4.26e-04\n",
      "Average loss (last 100 batches): 0.7056, lr: 4.26e-04\n",
      "Average loss (last 100 batches): 0.6320, lr: 4.26e-04\n",
      "Average loss (last 100 batches): 0.7965, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 0.6668, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 0.7307, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 0.6307, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 0.6539, lr: 4.25e-04\n",
      "Average loss (last 100 batches): 0.6638, lr: 4.24e-04\n",
      "Average loss (last 100 batches): 0.7068, lr: 4.24e-04\n",
      "Average loss (last 100 batches): 0.7119, lr: 4.24e-04\n",
      "Average loss (last 100 batches): 0.6000, lr: 4.23e-04\n",
      "Average loss (last 100 batches): 0.6184, lr: 4.23e-04\n",
      "Average loss (last 100 batches): 0.6064, lr: 4.23e-04\n",
      "Average loss (last 100 batches): 0.6225, lr: 4.23e-04\n",
      "Average loss (last 100 batches): 0.9546, lr: 4.22e-04\n",
      "Average loss (last 100 batches): 0.7339, lr: 4.22e-04\n",
      "Average loss (last 100 batches): 0.7576, lr: 4.22e-04\n",
      "Average loss (last 100 batches): 0.8061, lr: 4.22e-04\n",
      "Average loss (last 100 batches): 0.7580, lr: 4.21e-04\n",
      "Average loss (last 100 batches): 0.6672, lr: 4.21e-04\n",
      "Average loss (last 100 batches): 0.6300, lr: 4.21e-04\n",
      "Average loss (last 100 batches): 0.7814, lr: 4.21e-04\n",
      "Average loss (last 100 batches): 0.6008, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 0.6310, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 0.5980, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 0.6891, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 0.7060, lr: 4.20e-04\n",
      "Average loss (last 100 batches): 0.6252, lr: 4.19e-04\n",
      "Average loss (last 100 batches): 0.7568, lr: 4.19e-04\n",
      "Average loss (last 100 batches): 0.6463, lr: 4.19e-04\n",
      "Average loss (last 100 batches): 0.7146, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 0.7812, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 0.9528, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 1.0041, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 0.6721, lr: 4.18e-04\n",
      "Average loss (last 100 batches): 0.7170, lr: 4.17e-04\n",
      "Average loss (last 100 batches): 0.8682, lr: 4.17e-04\n",
      "Average loss (last 100 batches): 0.6482, lr: 4.17e-04\n",
      "Average loss (last 100 batches): 0.6725, lr: 4.16e-04\n",
      "Average loss (last 100 batches): 0.5881, lr: 4.16e-04\n",
      "Average loss (last 100 batches): 0.6357, lr: 4.16e-04\n",
      "Average loss (last 100 batches): 0.6242, lr: 4.16e-04\n",
      "Average loss (last 100 batches): 0.7075, lr: 4.15e-04\n",
      "Average loss (last 100 batches): 0.6513, lr: 4.15e-04\n",
      "Average loss (last 100 batches): 0.7233, lr: 4.15e-04\n",
      "Average loss (last 100 batches): 1.0251, lr: 4.15e-04\n",
      "Average loss (last 100 batches): 0.6658, lr: 4.14e-04\n",
      "Average loss (last 100 batches): 0.6791, lr: 4.14e-04\n",
      "Average loss (last 100 batches): 0.8385, lr: 4.14e-04\n",
      "Average loss (last 100 batches): 0.6068, lr: 4.14e-04\n",
      "Average loss (last 100 batches): 0.6184, lr: 4.13e-04\n",
      "Average loss (last 100 batches): 0.6641, lr: 4.13e-04\n",
      "Average loss (last 100 batches): 0.8458, lr: 4.13e-04\n",
      "Average loss (last 100 batches): 0.6522, lr: 4.13e-04\n",
      "Average loss (last 100 batches): 0.7563, lr: 4.12e-04\n",
      "Average loss (last 100 batches): 0.5776, lr: 4.12e-04\n",
      "Average loss (last 100 batches): 0.5969, lr: 4.12e-04\n",
      "Average loss (last 100 batches): 0.6139, lr: 4.12e-04\n",
      "Average loss (last 100 batches): 0.6185, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.8640, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.6961, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.6282, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.6890, lr: 4.11e-04\n",
      "Average loss (last 100 batches): 0.5920, lr: 4.10e-04\n",
      "Average loss (last 100 batches): 0.7154, lr: 4.10e-04\n",
      "Average loss (last 100 batches): 0.5421, lr: 4.10e-04\n",
      "Average loss (last 100 batches): 0.5686, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 0.5726, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 0.6912, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 0.6796, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 0.6919, lr: 4.09e-04\n",
      "Average loss (last 100 batches): 0.8722, lr: 4.08e-04\n",
      "Average loss (last 100 batches): 0.6856, lr: 4.08e-04\n",
      "Average loss (last 100 batches): 0.7129, lr: 4.08e-04\n",
      "Average loss (last 100 batches): 0.7741, lr: 4.07e-04\n",
      "Average loss (last 100 batches): 0.7442, lr: 4.07e-04\n",
      "Average loss (last 100 batches): 0.6068, lr: 4.07e-04\n",
      "Average loss (last 100 batches): 0.7315, lr: 4.07e-04\n",
      "Average loss (last 100 batches): 0.7636, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.6702, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.8883, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.6249, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.9563, lr: 4.06e-04\n",
      "Average loss (last 100 batches): 0.6077, lr: 4.05e-04\n",
      "Average loss (last 100 batches): 0.5780, lr: 4.05e-04\n",
      "Average loss (last 100 batches): 0.5936, lr: 4.05e-04\n",
      "Average loss (last 100 batches): 0.6396, lr: 4.05e-04\n",
      "Average loss (last 100 batches): 0.6618, lr: 4.04e-04\n",
      "Average loss (last 100 batches): 0.6132, lr: 4.04e-04\n",
      "Average loss (last 100 batches): 0.6589, lr: 4.04e-04\n",
      "Average loss (last 100 batches): 0.8520, lr: 4.04e-04\n",
      "Average loss (last 100 batches): 0.5606, lr: 4.03e-04\n",
      "Average loss (last 100 batches): 0.6360, lr: 4.03e-04\n",
      "Average loss (last 100 batches): 0.5932, lr: 4.03e-04\n",
      "Average loss (last 100 batches): 0.5752, lr: 4.03e-04\n",
      "Average loss (last 100 batches): 0.6316, lr: 4.02e-04\n",
      "Average loss (last 100 batches): 0.6715, lr: 4.02e-04\n",
      "Average loss (last 100 batches): 0.5652, lr: 4.02e-04\n",
      "Average loss (last 100 batches): 0.6370, lr: 4.02e-04\n",
      "Average loss (last 100 batches): 0.5792, lr: 4.01e-04\n",
      "Average loss (last 100 batches): 0.5857, lr: 4.01e-04\n",
      "Average loss (last 100 batches): 0.6053, lr: 4.01e-04\n",
      "Average loss (last 100 batches): 0.7027, lr: 4.01e-04\n",
      "Average loss (last 100 batches): 0.7380, lr: 4.00e-04\n",
      "Average loss (last 100 batches): 0.7892, lr: 4.00e-04\n",
      "Average loss (last 100 batches): 0.6363, lr: 4.00e-04\n",
      "Average loss (last 100 batches): 0.6628, lr: 4.00e-04\n",
      "Average loss (last 100 batches): 0.7092, lr: 3.99e-04\n",
      "Average loss (last 100 batches): 0.7103, lr: 3.99e-04\n",
      "Average loss (last 100 batches): 0.8104, lr: 3.99e-04\n",
      "Average loss (last 100 batches): 0.6809, lr: 3.99e-04\n",
      "Average loss (last 100 batches): 0.6050, lr: 3.98e-04\n",
      "Average loss (last 100 batches): 0.6122, lr: 3.98e-04\n",
      "Average loss (last 100 batches): 0.5788, lr: 3.98e-04\n",
      "Average loss (last 100 batches): 0.8643, lr: 3.98e-04\n",
      "Average loss (last 100 batches): 0.7118, lr: 3.97e-04\n",
      "Average loss (last 100 batches): 0.6331, lr: 3.97e-04\n",
      "Average loss (last 100 batches): 0.6472, lr: 3.97e-04\n",
      "Average loss (last 100 batches): 0.7150, lr: 3.97e-04\n",
      "Average loss (last 100 batches): 0.7127, lr: 3.96e-04\n",
      "Average loss (last 100 batches): 0.6277, lr: 3.96e-04\n",
      "Average loss (last 100 batches): 0.6378, lr: 3.96e-04\n",
      "Average loss (last 100 batches): 0.6757, lr: 3.96e-04\n",
      "Average loss (last 100 batches): 0.6709, lr: 3.95e-04\n",
      "Average loss (last 100 batches): 0.6418, lr: 3.95e-04\n",
      "Average loss (last 100 batches): 0.9002, lr: 3.95e-04\n",
      "Average loss (last 100 batches): 0.7349, lr: 3.95e-04\n",
      "Average loss (last 100 batches): 0.5597, lr: 3.94e-04\n",
      "Average loss (last 100 batches): 0.7750, lr: 3.94e-04\n",
      "Average loss (last 100 batches): 0.7828, lr: 3.94e-04\n",
      "Average loss (last 100 batches): 0.8418, lr: 3.94e-04\n",
      "Average loss (last 100 batches): 0.7137, lr: 3.93e-04\n",
      "Average loss (last 100 batches): 0.7829, lr: 3.93e-04\n",
      "Average loss (last 100 batches): 0.6648, lr: 3.93e-04\n",
      "Average loss (last 100 batches): 0.5896, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 0.7096, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 0.9325, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 0.6036, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 0.5283, lr: 3.92e-04\n",
      "Average loss (last 100 batches): 0.5607, lr: 3.91e-04\n",
      "Average loss (last 100 batches): 0.6246, lr: 3.91e-04\n",
      "Average loss (last 100 batches): 0.5834, lr: 3.91e-04\n",
      "Average loss (last 100 batches): 0.6255, lr: 3.91e-04\n",
      "Average loss (last 100 batches): 0.5203, lr: 3.90e-04\n",
      "Average loss (last 100 batches): 0.5474, lr: 3.90e-04\n",
      "Average loss (last 100 batches): 0.5804, lr: 3.90e-04\n",
      "Average loss (last 100 batches): 0.5325, lr: 3.90e-04\n",
      "Average loss (last 100 batches): 0.5331, lr: 3.89e-04\n",
      "Average loss (last 100 batches): 0.5873, lr: 3.89e-04\n",
      "Average loss (last 100 batches): 0.6157, lr: 3.89e-04\n",
      "Average loss (last 100 batches): 0.6746, lr: 3.89e-04\n",
      "Average loss (last 100 batches): 0.5863, lr: 3.88e-04\n",
      "Average loss (last 100 batches): 0.5937, lr: 3.88e-04\n",
      "Average loss (last 100 batches): 0.6114, lr: 3.88e-04\n",
      "Average loss (last 100 batches): 0.7120, lr: 3.88e-04\n",
      "Average loss (last 100 batches): 0.7285, lr: 3.87e-04\n",
      "Average loss (last 100 batches): 0.5661, lr: 3.87e-04\n",
      "Average loss (last 100 batches): 0.6564, lr: 3.87e-04\n",
      "Average loss (last 100 batches): 0.7364, lr: 3.87e-04\n",
      "Average loss (last 100 batches): 0.7733, lr: 3.86e-04\n",
      "Average loss (last 100 batches): 0.5449, lr: 3.86e-04\n",
      "Average loss (last 100 batches): 0.7966, lr: 3.86e-04\n",
      "Average loss (last 100 batches): 0.8181, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.6476, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.7835, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.7065, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.8181, lr: 3.85e-04\n",
      "Average loss (last 100 batches): 0.8208, lr: 3.84e-04\n",
      "Average loss (last 100 batches): 0.6147, lr: 3.84e-04\n",
      "Average loss (last 100 batches): 0.5385, lr: 3.84e-04\n",
      "Average loss (last 100 batches): 0.7204, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 0.6568, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 0.7149, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 0.6813, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 0.5578, lr: 3.83e-04\n",
      "Average loss (last 100 batches): 0.6528, lr: 3.82e-04\n",
      "Average loss (last 100 batches): 0.7097, lr: 3.82e-04\n",
      "Average loss (last 100 batches): 0.8136, lr: 3.82e-04\n",
      "Average loss (last 100 batches): 0.6613, lr: 3.82e-04\n",
      "Average loss (last 100 batches): 0.8787, lr: 3.81e-04\n",
      "Average loss (last 100 batches): 0.9134, lr: 3.81e-04\n",
      "Average loss (last 100 batches): 1.0164, lr: 3.81e-04\n",
      "Average loss (last 100 batches): 0.6178, lr: 3.81e-04\n",
      "Average loss (last 100 batches): 0.5981, lr: 3.80e-04\n",
      "Average loss (last 100 batches): 0.6341, lr: 3.80e-04\n",
      "Average loss (last 100 batches): 0.6381, lr: 3.80e-04\n",
      "Average loss (last 100 batches): 0.6791, lr: 3.80e-04\n",
      "Average loss (last 100 batches): 0.6302, lr: 3.79e-04\n",
      "Average loss (last 100 batches): 0.7872, lr: 3.79e-04\n",
      "Average loss (last 100 batches): 0.6108, lr: 3.79e-04\n",
      "Average loss (last 100 batches): 0.7117, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 0.5719, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 0.5956, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 0.6489, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 0.6512, lr: 3.78e-04\n",
      "Average loss (last 100 batches): 0.8212, lr: 3.77e-04\n",
      "Average loss (last 100 batches): 0.6013, lr: 3.77e-04\n",
      "Average loss (last 100 batches): 0.5291, lr: 3.77e-04\n",
      "Average loss (last 100 batches): 0.5544, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 0.6853, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 0.7157, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 0.6180, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 0.8790, lr: 3.76e-04\n",
      "Average loss (last 100 batches): 0.6480, lr: 3.75e-04\n",
      "Average loss (last 100 batches): 0.6861, lr: 3.75e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42ff8a84cb704cfb97f00e5e0047d797"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Train Loss: 0.6959 | Test Loss: 43563699629367.8047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b82d04a8b7f4eb28d01229360438017"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.6437, lr: 3.75e-04\n",
      "Average loss (last 100 batches): 0.9844, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 0.5588, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 0.5997, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 0.7170, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 0.5703, lr: 3.74e-04\n",
      "Average loss (last 100 batches): 0.5274, lr: 3.73e-04\n",
      "Average loss (last 100 batches): 0.6636, lr: 3.73e-04\n",
      "Average loss (last 100 batches): 0.5563, lr: 3.73e-04\n",
      "Average loss (last 100 batches): 0.6481, lr: 3.73e-04\n",
      "Average loss (last 100 batches): 0.6727, lr: 3.72e-04\n",
      "Average loss (last 100 batches): 0.5965, lr: 3.72e-04\n",
      "Average loss (last 100 batches): 0.5959, lr: 3.72e-04\n",
      "Average loss (last 100 batches): 0.5696, lr: 3.72e-04\n",
      "Average loss (last 100 batches): 0.6058, lr: 3.71e-04\n",
      "Average loss (last 100 batches): 0.5895, lr: 3.71e-04\n",
      "Average loss (last 100 batches): 0.6420, lr: 3.71e-04\n",
      "Average loss (last 100 batches): 0.5754, lr: 3.71e-04\n",
      "Average loss (last 100 batches): 0.6155, lr: 3.70e-04\n",
      "Average loss (last 100 batches): 0.5875, lr: 3.70e-04\n",
      "Average loss (last 100 batches): 0.5386, lr: 3.70e-04\n",
      "Average loss (last 100 batches): 0.6257, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 0.5285, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 0.8094, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 0.5181, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 0.5767, lr: 3.69e-04\n",
      "Average loss (last 100 batches): 0.5800, lr: 3.68e-04\n",
      "Average loss (last 100 batches): 0.7733, lr: 3.68e-04\n",
      "Average loss (last 100 batches): 0.7120, lr: 3.68e-04\n",
      "Average loss (last 100 batches): 0.5686, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 0.6229, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 0.5804, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 0.8582, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 0.6756, lr: 3.67e-04\n",
      "Average loss (last 100 batches): 0.6216, lr: 3.66e-04\n",
      "Average loss (last 100 batches): 0.5917, lr: 3.66e-04\n",
      "Average loss (last 100 batches): 0.5556, lr: 3.66e-04\n",
      "Average loss (last 100 batches): 0.5732, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.7205, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.5401, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.6562, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.5813, lr: 3.65e-04\n",
      "Average loss (last 100 batches): 0.5402, lr: 3.64e-04\n",
      "Average loss (last 100 batches): 0.8493, lr: 3.64e-04\n",
      "Average loss (last 100 batches): 0.6268, lr: 3.64e-04\n",
      "Average loss (last 100 batches): 0.5192, lr: 3.63e-04\n",
      "Average loss (last 100 batches): 0.5076, lr: 3.63e-04\n",
      "Average loss (last 100 batches): 0.5659, lr: 3.63e-04\n",
      "Average loss (last 100 batches): 0.5485, lr: 3.63e-04\n",
      "Average loss (last 100 batches): 0.6343, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.5527, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.7238, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.6327, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.5833, lr: 3.62e-04\n",
      "Average loss (last 100 batches): 0.8881, lr: 3.61e-04\n",
      "Average loss (last 100 batches): 0.5905, lr: 3.61e-04\n",
      "Average loss (last 100 batches): 0.7611, lr: 3.61e-04\n",
      "Average loss (last 100 batches): 0.6718, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 0.6227, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 0.6854, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 0.8296, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 1.0298, lr: 3.60e-04\n",
      "Average loss (last 100 batches): 0.6532, lr: 3.59e-04\n",
      "Average loss (last 100 batches): 0.5799, lr: 3.59e-04\n",
      "Average loss (last 100 batches): 0.6813, lr: 3.59e-04\n",
      "Average loss (last 100 batches): 0.5956, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 0.6489, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 0.5807, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 0.5816, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 0.6052, lr: 3.58e-04\n",
      "Average loss (last 100 batches): 0.5970, lr: 3.57e-04\n",
      "Average loss (last 100 batches): 0.5850, lr: 3.57e-04\n",
      "Average loss (last 100 batches): 0.5340, lr: 3.57e-04\n",
      "Average loss (last 100 batches): 0.5374, lr: 3.56e-04\n",
      "Average loss (last 100 batches): 0.6408, lr: 3.56e-04\n",
      "Average loss (last 100 batches): 0.5175, lr: 3.56e-04\n",
      "Average loss (last 100 batches): 0.6379, lr: 3.56e-04\n",
      "Average loss (last 100 batches): 0.5953, lr: 3.55e-04\n",
      "Average loss (last 100 batches): 0.7174, lr: 3.55e-04\n",
      "Average loss (last 100 batches): 0.6126, lr: 3.55e-04\n",
      "Average loss (last 100 batches): 0.9402, lr: 3.55e-04\n",
      "Average loss (last 100 batches): 0.6577, lr: 3.54e-04\n",
      "Average loss (last 100 batches): 0.6261, lr: 3.54e-04\n",
      "Average loss (last 100 batches): 0.6274, lr: 3.54e-04\n",
      "Average loss (last 100 batches): 0.7289, lr: 3.54e-04\n",
      "Average loss (last 100 batches): 0.6967, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 0.5836, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 0.6212, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 0.6809, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 1.2440, lr: 3.53e-04\n",
      "Average loss (last 100 batches): 0.8195, lr: 3.52e-04\n",
      "Average loss (last 100 batches): 0.6405, lr: 3.52e-04\n",
      "Average loss (last 100 batches): 0.5895, lr: 3.52e-04\n",
      "Average loss (last 100 batches): 0.5548, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.8290, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.5939, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.6331, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.6474, lr: 3.51e-04\n",
      "Average loss (last 100 batches): 0.5368, lr: 3.50e-04\n",
      "Average loss (last 100 batches): 0.6664, lr: 3.50e-04\n",
      "Average loss (last 100 batches): 0.6152, lr: 3.50e-04\n",
      "Average loss (last 100 batches): 0.6763, lr: 3.49e-04\n",
      "Average loss (last 100 batches): 0.5099, lr: 3.49e-04\n",
      "Average loss (last 100 batches): 0.5826, lr: 3.49e-04\n",
      "Average loss (last 100 batches): 0.7619, lr: 3.49e-04\n",
      "Average loss (last 100 batches): 0.5931, lr: 3.48e-04\n",
      "Average loss (last 100 batches): 0.6687, lr: 3.48e-04\n",
      "Average loss (last 100 batches): 0.5602, lr: 3.48e-04\n",
      "Average loss (last 100 batches): 0.5145, lr: 3.48e-04\n",
      "Average loss (last 100 batches): 0.5966, lr: 3.47e-04\n",
      "Average loss (last 100 batches): 0.9132, lr: 3.47e-04\n",
      "Average loss (last 100 batches): 0.7949, lr: 3.47e-04\n",
      "Average loss (last 100 batches): 0.5750, lr: 3.47e-04\n",
      "Average loss (last 100 batches): 0.5362, lr: 3.46e-04\n",
      "Average loss (last 100 batches): 0.6680, lr: 3.46e-04\n",
      "Average loss (last 100 batches): 0.7114, lr: 3.46e-04\n",
      "Average loss (last 100 batches): 0.5428, lr: 3.46e-04\n",
      "Average loss (last 100 batches): 0.5930, lr: 3.45e-04\n",
      "Average loss (last 100 batches): 0.5342, lr: 3.45e-04\n",
      "Average loss (last 100 batches): 0.6862, lr: 3.45e-04\n",
      "Average loss (last 100 batches): 0.9880, lr: 3.45e-04\n",
      "Average loss (last 100 batches): 0.5440, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 0.5681, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 0.5457, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 0.4897, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 0.6453, lr: 3.44e-04\n",
      "Average loss (last 100 batches): 0.5707, lr: 3.43e-04\n",
      "Average loss (last 100 batches): 0.5723, lr: 3.43e-04\n",
      "Average loss (last 100 batches): 0.6622, lr: 3.43e-04\n",
      "Average loss (last 100 batches): 0.7383, lr: 3.43e-04\n",
      "Average loss (last 100 batches): 0.9185, lr: 3.42e-04\n",
      "Average loss (last 100 batches): 0.6725, lr: 3.42e-04\n",
      "Average loss (last 100 batches): 0.7253, lr: 3.42e-04\n",
      "Average loss (last 100 batches): 0.5222, lr: 3.42e-04\n",
      "Average loss (last 100 batches): 0.5970, lr: 3.41e-04\n",
      "Average loss (last 100 batches): 0.7637, lr: 3.41e-04\n",
      "Average loss (last 100 batches): 0.5080, lr: 3.41e-04\n",
      "Average loss (last 100 batches): 0.5187, lr: 3.41e-04\n",
      "Average loss (last 100 batches): 0.7060, lr: 3.40e-04\n",
      "Average loss (last 100 batches): 0.6356, lr: 3.40e-04\n",
      "Average loss (last 100 batches): 0.7269, lr: 3.40e-04\n",
      "Average loss (last 100 batches): 0.5006, lr: 3.40e-04\n",
      "Average loss (last 100 batches): 0.5592, lr: 3.39e-04\n",
      "Average loss (last 100 batches): 0.8741, lr: 3.39e-04\n",
      "Average loss (last 100 batches): 0.6853, lr: 3.39e-04\n",
      "Average loss (last 100 batches): 0.5454, lr: 3.39e-04\n",
      "Average loss (last 100 batches): 0.5973, lr: 3.38e-04\n",
      "Average loss (last 100 batches): 0.6429, lr: 3.38e-04\n",
      "Average loss (last 100 batches): 0.7792, lr: 3.38e-04\n",
      "Average loss (last 100 batches): 0.5688, lr: 3.38e-04\n",
      "Average loss (last 100 batches): 0.5895, lr: 3.37e-04\n",
      "Average loss (last 100 batches): 0.5530, lr: 3.37e-04\n",
      "Average loss (last 100 batches): 0.5418, lr: 3.37e-04\n",
      "Average loss (last 100 batches): 0.5091, lr: 3.37e-04\n",
      "Average loss (last 100 batches): 0.6577, lr: 3.36e-04\n",
      "Average loss (last 100 batches): 0.6919, lr: 3.36e-04\n",
      "Average loss (last 100 batches): 0.5337, lr: 3.36e-04\n",
      "Average loss (last 100 batches): 0.6099, lr: 3.36e-04\n",
      "Average loss (last 100 batches): 0.5438, lr: 3.35e-04\n",
      "Average loss (last 100 batches): 0.5075, lr: 3.35e-04\n",
      "Average loss (last 100 batches): 0.4804, lr: 3.35e-04\n",
      "Average loss (last 100 batches): 0.6101, lr: 3.35e-04\n",
      "Average loss (last 100 batches): 0.5836, lr: 3.34e-04\n",
      "Average loss (last 100 batches): 0.6541, lr: 3.34e-04\n",
      "Average loss (last 100 batches): 0.5651, lr: 3.34e-04\n",
      "Average loss (last 100 batches): 0.7080, lr: 3.34e-04\n",
      "Average loss (last 100 batches): 0.4943, lr: 3.33e-04\n",
      "Average loss (last 100 batches): 0.5958, lr: 3.33e-04\n",
      "Average loss (last 100 batches): 0.5829, lr: 3.33e-04\n",
      "Average loss (last 100 batches): 0.5722, lr: 3.33e-04\n",
      "Average loss (last 100 batches): 0.5331, lr: 3.32e-04\n",
      "Average loss (last 100 batches): 0.7275, lr: 3.32e-04\n",
      "Average loss (last 100 batches): 0.5997, lr: 3.32e-04\n",
      "Average loss (last 100 batches): 0.6280, lr: 3.32e-04\n",
      "Average loss (last 100 batches): 0.5313, lr: 3.31e-04\n",
      "Average loss (last 100 batches): 0.5739, lr: 3.31e-04\n",
      "Average loss (last 100 batches): 0.6124, lr: 3.31e-04\n",
      "Average loss (last 100 batches): 0.5808, lr: 3.31e-04\n",
      "Average loss (last 100 batches): 0.5211, lr: 3.30e-04\n",
      "Average loss (last 100 batches): 0.6053, lr: 3.30e-04\n",
      "Average loss (last 100 batches): 0.6939, lr: 3.30e-04\n",
      "Average loss (last 100 batches): 0.5228, lr: 3.30e-04\n",
      "Average loss (last 100 batches): 0.6645, lr: 3.29e-04\n",
      "Average loss (last 100 batches): 0.5558, lr: 3.29e-04\n",
      "Average loss (last 100 batches): 0.9220, lr: 3.29e-04\n",
      "Average loss (last 100 batches): 0.4959, lr: 3.29e-04\n",
      "Average loss (last 100 batches): 0.5413, lr: 3.28e-04\n",
      "Average loss (last 100 batches): 0.4878, lr: 3.28e-04\n",
      "Average loss (last 100 batches): 0.9288, lr: 3.28e-04\n",
      "Average loss (last 100 batches): 0.6042, lr: 3.28e-04\n",
      "Average loss (last 100 batches): 0.5796, lr: 3.27e-04\n",
      "Average loss (last 100 batches): 0.5856, lr: 3.27e-04\n",
      "Average loss (last 100 batches): 0.6266, lr: 3.27e-04\n",
      "Average loss (last 100 batches): 0.5526, lr: 3.27e-04\n",
      "Average loss (last 100 batches): 0.6706, lr: 3.26e-04\n",
      "Average loss (last 100 batches): 0.5147, lr: 3.26e-04\n",
      "Average loss (last 100 batches): 0.5652, lr: 3.26e-04\n",
      "Average loss (last 100 batches): 0.5864, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 0.4991, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 0.4851, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 0.4799, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 0.6022, lr: 3.25e-04\n",
      "Average loss (last 100 batches): 0.5068, lr: 3.24e-04\n",
      "Average loss (last 100 batches): 0.4624, lr: 3.24e-04\n",
      "Average loss (last 100 batches): 0.5333, lr: 3.24e-04\n",
      "Average loss (last 100 batches): 0.5424, lr: 3.24e-04\n",
      "Average loss (last 100 batches): 0.5875, lr: 3.23e-04\n",
      "Average loss (last 100 batches): 0.5606, lr: 3.23e-04\n",
      "Average loss (last 100 batches): 0.5114, lr: 3.23e-04\n",
      "Average loss (last 100 batches): 0.5617, lr: 3.23e-04\n",
      "Average loss (last 100 batches): 0.4943, lr: 3.22e-04\n",
      "Average loss (last 100 batches): 0.5047, lr: 3.22e-04\n",
      "Average loss (last 100 batches): 0.6403, lr: 3.22e-04\n",
      "Average loss (last 100 batches): 0.4981, lr: 3.22e-04\n",
      "Average loss (last 100 batches): 0.6943, lr: 3.21e-04\n",
      "Average loss (last 100 batches): 0.5831, lr: 3.21e-04\n",
      "Average loss (last 100 batches): 0.5499, lr: 3.21e-04\n",
      "Average loss (last 100 batches): 0.5296, lr: 3.21e-04\n",
      "Average loss (last 100 batches): 0.5118, lr: 3.20e-04\n",
      "Average loss (last 100 batches): 0.5069, lr: 3.20e-04\n",
      "Average loss (last 100 batches): 0.8216, lr: 3.20e-04\n",
      "Average loss (last 100 batches): 0.4885, lr: 3.20e-04\n",
      "Average loss (last 100 batches): 0.6553, lr: 3.19e-04\n",
      "Average loss (last 100 batches): 0.5280, lr: 3.19e-04\n",
      "Average loss (last 100 batches): 0.6308, lr: 3.19e-04\n",
      "Average loss (last 100 batches): 0.8885, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 0.5304, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 0.7241, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 0.5779, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 0.4740, lr: 3.18e-04\n",
      "Average loss (last 100 batches): 0.6513, lr: 3.17e-04\n",
      "Average loss (last 100 batches): 0.5294, lr: 3.17e-04\n",
      "Average loss (last 100 batches): 0.5132, lr: 3.17e-04\n",
      "Average loss (last 100 batches): 0.4714, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 0.5432, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 0.5780, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 0.6282, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 0.5618, lr: 3.16e-04\n",
      "Average loss (last 100 batches): 0.6170, lr: 3.15e-04\n",
      "Average loss (last 100 batches): 0.5299, lr: 3.15e-04\n",
      "Average loss (last 100 batches): 0.4705, lr: 3.15e-04\n",
      "Average loss (last 100 batches): 0.5618, lr: 3.15e-04\n",
      "Average loss (last 100 batches): 0.4835, lr: 3.14e-04\n",
      "Average loss (last 100 batches): 0.5627, lr: 3.14e-04\n",
      "Average loss (last 100 batches): 0.5189, lr: 3.14e-04\n",
      "Average loss (last 100 batches): 0.5286, lr: 3.14e-04\n",
      "Average loss (last 100 batches): 0.5187, lr: 3.13e-04\n",
      "Average loss (last 100 batches): 0.5472, lr: 3.13e-04\n",
      "Average loss (last 100 batches): 0.5047, lr: 3.13e-04\n",
      "Average loss (last 100 batches): 0.6408, lr: 3.13e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f30bdb2849c4b21831d5870481305bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Train Loss: 0.6169 | Test Loss: 58964718498220.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c27d2af9d244464990e2145dac434943"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.6333, lr: 3.12e-04\n",
      "Average loss (last 100 batches): 0.5560, lr: 3.12e-04\n",
      "Average loss (last 100 batches): 0.4952, lr: 3.12e-04\n",
      "Average loss (last 100 batches): 0.5703, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.4954, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.4736, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.6059, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.5067, lr: 3.11e-04\n",
      "Average loss (last 100 batches): 0.5794, lr: 3.10e-04\n",
      "Average loss (last 100 batches): 0.4942, lr: 3.10e-04\n",
      "Average loss (last 100 batches): 0.6017, lr: 3.10e-04\n",
      "Average loss (last 100 batches): 0.4988, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 0.5638, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 0.5144, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 0.5041, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 0.4731, lr: 3.09e-04\n",
      "Average loss (last 100 batches): 0.5795, lr: 3.08e-04\n",
      "Average loss (last 100 batches): 0.5745, lr: 3.08e-04\n",
      "Average loss (last 100 batches): 0.7484, lr: 3.08e-04\n",
      "Average loss (last 100 batches): 0.7914, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 0.6034, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 0.6856, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 0.5428, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 0.5420, lr: 3.07e-04\n",
      "Average loss (last 100 batches): 0.4722, lr: 3.06e-04\n",
      "Average loss (last 100 batches): 0.5287, lr: 3.06e-04\n",
      "Average loss (last 100 batches): 0.6284, lr: 3.06e-04\n",
      "Average loss (last 100 batches): 0.4961, lr: 3.05e-04\n",
      "Average loss (last 100 batches): 0.4886, lr: 3.05e-04\n",
      "Average loss (last 100 batches): 0.5628, lr: 3.05e-04\n",
      "Average loss (last 100 batches): 0.5288, lr: 3.05e-04\n",
      "Average loss (last 100 batches): 0.8913, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.5152, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.5652, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.5110, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.6274, lr: 3.04e-04\n",
      "Average loss (last 100 batches): 0.4972, lr: 3.03e-04\n",
      "Average loss (last 100 batches): 0.8378, lr: 3.03e-04\n",
      "Average loss (last 100 batches): 0.4672, lr: 3.03e-04\n",
      "Average loss (last 100 batches): 0.5953, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 0.4881, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 0.5099, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 0.5245, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 0.6738, lr: 3.02e-04\n",
      "Average loss (last 100 batches): 0.6007, lr: 3.01e-04\n",
      "Average loss (last 100 batches): 0.5335, lr: 3.01e-04\n",
      "Average loss (last 100 batches): 0.4628, lr: 3.01e-04\n",
      "Average loss (last 100 batches): 0.5568, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.4830, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.6862, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.4666, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.5955, lr: 3.00e-04\n",
      "Average loss (last 100 batches): 0.5149, lr: 2.99e-04\n",
      "Average loss (last 100 batches): 0.5637, lr: 2.99e-04\n",
      "Average loss (last 100 batches): 0.5911, lr: 2.99e-04\n",
      "Average loss (last 100 batches): 0.4821, lr: 2.98e-04\n",
      "Average loss (last 100 batches): 0.5226, lr: 2.98e-04\n",
      "Average loss (last 100 batches): 0.5515, lr: 2.98e-04\n",
      "Average loss (last 100 batches): 0.6414, lr: 2.98e-04\n",
      "Average loss (last 100 batches): 0.4922, lr: 2.97e-04\n",
      "Average loss (last 100 batches): 0.5020, lr: 2.97e-04\n",
      "Average loss (last 100 batches): 0.5701, lr: 2.97e-04\n",
      "Average loss (last 100 batches): 0.4436, lr: 2.97e-04\n",
      "Average loss (last 100 batches): 0.7098, lr: 2.96e-04\n",
      "Average loss (last 100 batches): 0.5439, lr: 2.96e-04\n",
      "Average loss (last 100 batches): 0.5418, lr: 2.96e-04\n",
      "Average loss (last 100 batches): 0.5622, lr: 2.96e-04\n",
      "Average loss (last 100 batches): 0.5386, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 0.6465, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 0.4521, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 0.6052, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 0.4888, lr: 2.95e-04\n",
      "Average loss (last 100 batches): 0.5121, lr: 2.94e-04\n",
      "Average loss (last 100 batches): 0.5868, lr: 2.94e-04\n",
      "Average loss (last 100 batches): 0.5889, lr: 2.94e-04\n",
      "Average loss (last 100 batches): 0.4578, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 0.5904, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 0.6180, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 0.5317, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 0.7118, lr: 2.93e-04\n",
      "Average loss (last 100 batches): 0.4564, lr: 2.92e-04\n",
      "Average loss (last 100 batches): 0.5654, lr: 2.92e-04\n",
      "Average loss (last 100 batches): 0.5073, lr: 2.92e-04\n",
      "Average loss (last 100 batches): 0.4671, lr: 2.91e-04\n",
      "Average loss (last 100 batches): 0.4873, lr: 2.91e-04\n",
      "Average loss (last 100 batches): 0.4444, lr: 2.91e-04\n",
      "Average loss (last 100 batches): 0.4712, lr: 2.91e-04\n",
      "Average loss (last 100 batches): 0.5068, lr: 2.90e-04\n",
      "Average loss (last 100 batches): 0.4701, lr: 2.90e-04\n",
      "Average loss (last 100 batches): 0.5068, lr: 2.90e-04\n",
      "Average loss (last 100 batches): 0.6693, lr: 2.90e-04\n",
      "Average loss (last 100 batches): 0.5639, lr: 2.89e-04\n",
      "Average loss (last 100 batches): 0.5000, lr: 2.89e-04\n",
      "Average loss (last 100 batches): 0.7196, lr: 2.89e-04\n",
      "Average loss (last 100 batches): 0.6218, lr: 2.89e-04\n",
      "Average loss (last 100 batches): 0.5609, lr: 2.88e-04\n",
      "Average loss (last 100 batches): 0.6481, lr: 2.88e-04\n",
      "Average loss (last 100 batches): 0.5358, lr: 2.88e-04\n",
      "Average loss (last 100 batches): 0.8392, lr: 2.88e-04\n",
      "Average loss (last 100 batches): 0.4963, lr: 2.87e-04\n",
      "Average loss (last 100 batches): 0.4776, lr: 2.87e-04\n",
      "Average loss (last 100 batches): 0.5236, lr: 2.87e-04\n",
      "Average loss (last 100 batches): 0.5428, lr: 2.87e-04\n",
      "Average loss (last 100 batches): 0.4588, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 0.5229, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 0.6332, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 0.6838, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 0.4893, lr: 2.86e-04\n",
      "Average loss (last 100 batches): 0.5219, lr: 2.85e-04\n",
      "Average loss (last 100 batches): 0.7316, lr: 2.85e-04\n",
      "Average loss (last 100 batches): 0.8444, lr: 2.85e-04\n",
      "Average loss (last 100 batches): 0.7622, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 0.4551, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 0.4809, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 0.5828, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 0.5169, lr: 2.84e-04\n",
      "Average loss (last 100 batches): 0.4910, lr: 2.83e-04\n",
      "Average loss (last 100 batches): 0.5658, lr: 2.83e-04\n",
      "Average loss (last 100 batches): 0.4883, lr: 2.83e-04\n",
      "Average loss (last 100 batches): 0.4706, lr: 2.82e-04\n",
      "Average loss (last 100 batches): 0.5549, lr: 2.82e-04\n",
      "Average loss (last 100 batches): 0.4579, lr: 2.82e-04\n",
      "Average loss (last 100 batches): 0.5663, lr: 2.82e-04\n",
      "Average loss (last 100 batches): 0.5039, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 0.5470, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 0.5661, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 0.5632, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 0.6229, lr: 2.81e-04\n",
      "Average loss (last 100 batches): 0.5683, lr: 2.80e-04\n",
      "Average loss (last 100 batches): 0.4581, lr: 2.80e-04\n",
      "Average loss (last 100 batches): 0.4910, lr: 2.80e-04\n",
      "Average loss (last 100 batches): 0.5090, lr: 2.80e-04\n",
      "Average loss (last 100 batches): 0.4861, lr: 2.79e-04\n",
      "Average loss (last 100 batches): 0.4494, lr: 2.79e-04\n",
      "Average loss (last 100 batches): 0.6332, lr: 2.79e-04\n",
      "Average loss (last 100 batches): 0.5438, lr: 2.79e-04\n",
      "Average loss (last 100 batches): 0.5578, lr: 2.78e-04\n",
      "Average loss (last 100 batches): 0.5530, lr: 2.78e-04\n",
      "Average loss (last 100 batches): 0.5236, lr: 2.78e-04\n",
      "Average loss (last 100 batches): 0.6138, lr: 2.78e-04\n",
      "Average loss (last 100 batches): 0.5348, lr: 2.77e-04\n",
      "Average loss (last 100 batches): 0.6132, lr: 2.77e-04\n",
      "Average loss (last 100 batches): 0.5665, lr: 2.77e-04\n",
      "Average loss (last 100 batches): 0.5289, lr: 2.77e-04\n",
      "Average loss (last 100 batches): 0.4604, lr: 2.76e-04\n",
      "Average loss (last 100 batches): 0.4824, lr: 2.76e-04\n",
      "Average loss (last 100 batches): 0.4892, lr: 2.76e-04\n",
      "Average loss (last 100 batches): 0.4508, lr: 2.76e-04\n",
      "Average loss (last 100 batches): 0.5514, lr: 2.75e-04\n",
      "Average loss (last 100 batches): 0.4795, lr: 2.75e-04\n",
      "Average loss (last 100 batches): 0.5398, lr: 2.75e-04\n",
      "Average loss (last 100 batches): 0.7782, lr: 2.75e-04\n",
      "Average loss (last 100 batches): 0.6469, lr: 2.74e-04\n",
      "Average loss (last 100 batches): 0.5881, lr: 2.74e-04\n",
      "Average loss (last 100 batches): 0.6123, lr: 2.74e-04\n",
      "Average loss (last 100 batches): 0.5223, lr: 2.74e-04\n",
      "Average loss (last 100 batches): 0.5141, lr: 2.73e-04\n",
      "Average loss (last 100 batches): 0.4401, lr: 2.73e-04\n",
      "Average loss (last 100 batches): 0.5849, lr: 2.73e-04\n",
      "Average loss (last 100 batches): 0.4969, lr: 2.73e-04\n",
      "Average loss (last 100 batches): 0.4593, lr: 2.72e-04\n",
      "Average loss (last 100 batches): 0.5526, lr: 2.72e-04\n",
      "Average loss (last 100 batches): 0.4778, lr: 2.72e-04\n",
      "Average loss (last 100 batches): 0.4952, lr: 2.72e-04\n",
      "Average loss (last 100 batches): 0.5086, lr: 2.71e-04\n",
      "Average loss (last 100 batches): 0.5806, lr: 2.71e-04\n",
      "Average loss (last 100 batches): 0.5263, lr: 2.71e-04\n",
      "Average loss (last 100 batches): 0.6192, lr: 2.71e-04\n",
      "Average loss (last 100 batches): 0.4415, lr: 2.70e-04\n",
      "Average loss (last 100 batches): 0.4672, lr: 2.70e-04\n",
      "Average loss (last 100 batches): 0.5304, lr: 2.70e-04\n",
      "Average loss (last 100 batches): 0.4302, lr: 2.70e-04\n",
      "Average loss (last 100 batches): 0.4555, lr: 2.69e-04\n",
      "Average loss (last 100 batches): 0.5314, lr: 2.69e-04\n",
      "Average loss (last 100 batches): 0.6425, lr: 2.69e-04\n",
      "Average loss (last 100 batches): 0.8109, lr: 2.69e-04\n",
      "Average loss (last 100 batches): 0.5477, lr: 2.68e-04\n",
      "Average loss (last 100 batches): 0.4772, lr: 2.68e-04\n",
      "Average loss (last 100 batches): 0.5102, lr: 2.68e-04\n",
      "Average loss (last 100 batches): 0.4623, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 0.6508, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 0.5885, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 0.5017, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 0.5061, lr: 2.67e-04\n",
      "Average loss (last 100 batches): 0.5403, lr: 2.66e-04\n",
      "Average loss (last 100 batches): 0.7461, lr: 2.66e-04\n",
      "Average loss (last 100 batches): 0.5523, lr: 2.66e-04\n",
      "Average loss (last 100 batches): 0.5623, lr: 2.66e-04\n",
      "Average loss (last 100 batches): 0.5145, lr: 2.65e-04\n",
      "Average loss (last 100 batches): 0.4663, lr: 2.65e-04\n",
      "Average loss (last 100 batches): 0.4352, lr: 2.65e-04\n",
      "Average loss (last 100 batches): 0.4210, lr: 2.65e-04\n",
      "Average loss (last 100 batches): 0.5479, lr: 2.64e-04\n",
      "Average loss (last 100 batches): 0.7818, lr: 2.64e-04\n",
      "Average loss (last 100 batches): 0.7590, lr: 2.64e-04\n",
      "Average loss (last 100 batches): 0.7342, lr: 2.64e-04\n",
      "Average loss (last 100 batches): 0.4825, lr: 2.63e-04\n",
      "Average loss (last 100 batches): 0.4775, lr: 2.63e-04\n",
      "Average loss (last 100 batches): 0.4668, lr: 2.63e-04\n",
      "Average loss (last 100 batches): 0.6090, lr: 2.63e-04\n",
      "Average loss (last 100 batches): 0.6229, lr: 2.62e-04\n",
      "Average loss (last 100 batches): 0.4630, lr: 2.62e-04\n",
      "Average loss (last 100 batches): 0.5057, lr: 2.62e-04\n",
      "Average loss (last 100 batches): 0.6065, lr: 2.62e-04\n",
      "Average loss (last 100 batches): 0.5917, lr: 2.61e-04\n",
      "Average loss (last 100 batches): 0.5373, lr: 2.61e-04\n",
      "Average loss (last 100 batches): 0.4879, lr: 2.61e-04\n",
      "Average loss (last 100 batches): 0.4856, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 0.5967, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 0.4905, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 0.5425, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 0.5425, lr: 2.60e-04\n",
      "Average loss (last 100 batches): 0.6462, lr: 2.59e-04\n",
      "Average loss (last 100 batches): 0.4461, lr: 2.59e-04\n",
      "Average loss (last 100 batches): 0.5039, lr: 2.59e-04\n",
      "Average loss (last 100 batches): 0.7822, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 0.5030, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 0.5328, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 0.5141, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 0.5271, lr: 2.58e-04\n",
      "Average loss (last 100 batches): 0.5091, lr: 2.57e-04\n",
      "Average loss (last 100 batches): 0.7206, lr: 2.57e-04\n",
      "Average loss (last 100 batches): 0.4802, lr: 2.57e-04\n",
      "Average loss (last 100 batches): 0.6172, lr: 2.57e-04\n",
      "Average loss (last 100 batches): 0.5358, lr: 2.56e-04\n",
      "Average loss (last 100 batches): 0.4800, lr: 2.56e-04\n",
      "Average loss (last 100 batches): 0.5041, lr: 2.56e-04\n",
      "Average loss (last 100 batches): 0.5674, lr: 2.56e-04\n",
      "Average loss (last 100 batches): 0.4939, lr: 2.55e-04\n",
      "Average loss (last 100 batches): 0.4607, lr: 2.55e-04\n",
      "Average loss (last 100 batches): 0.4578, lr: 2.55e-04\n",
      "Average loss (last 100 batches): 0.5247, lr: 2.55e-04\n",
      "Average loss (last 100 batches): 0.6311, lr: 2.54e-04\n",
      "Average loss (last 100 batches): 0.4451, lr: 2.54e-04\n",
      "Average loss (last 100 batches): 0.5494, lr: 2.54e-04\n",
      "Average loss (last 100 batches): 0.6148, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 0.6146, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 0.5236, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 0.4581, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 0.9147, lr: 2.53e-04\n",
      "Average loss (last 100 batches): 0.4775, lr: 2.52e-04\n",
      "Average loss (last 100 batches): 0.4445, lr: 2.52e-04\n",
      "Average loss (last 100 batches): 0.4974, lr: 2.52e-04\n",
      "Average loss (last 100 batches): 0.5871, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 0.4737, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 0.5304, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 0.5448, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 0.4607, lr: 2.51e-04\n",
      "Average loss (last 100 batches): 0.4979, lr: 2.50e-04\n",
      "Average loss (last 100 batches): 0.4527, lr: 2.50e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e14ba93cb154b26ae15ef78ad328157"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Train Loss: 0.5512 | Test Loss: 61113542007283.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe10cdb8060248ba9aac333ad7ef1fe8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.4431, lr: 2.50e-04\n",
      "Average loss (last 100 batches): 0.5502, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 0.6018, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 0.7237, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 0.4408, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 0.5175, lr: 2.49e-04\n",
      "Average loss (last 100 batches): 0.5516, lr: 2.48e-04\n",
      "Average loss (last 100 batches): 0.4839, lr: 2.48e-04\n",
      "Average loss (last 100 batches): 0.4416, lr: 2.48e-04\n",
      "Average loss (last 100 batches): 0.5433, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 0.4475, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 0.6924, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 0.5220, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 0.5299, lr: 2.47e-04\n",
      "Average loss (last 100 batches): 0.4685, lr: 2.46e-04\n",
      "Average loss (last 100 batches): 0.4145, lr: 2.46e-04\n",
      "Average loss (last 100 batches): 0.4635, lr: 2.46e-04\n",
      "Average loss (last 100 batches): 0.4950, lr: 2.46e-04\n",
      "Average loss (last 100 batches): 0.5135, lr: 2.45e-04\n",
      "Average loss (last 100 batches): 0.5763, lr: 2.45e-04\n",
      "Average loss (last 100 batches): 0.6140, lr: 2.45e-04\n",
      "Average loss (last 100 batches): 0.4274, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 0.5142, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 0.5199, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 0.5596, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 0.6707, lr: 2.44e-04\n",
      "Average loss (last 100 batches): 0.9808, lr: 2.43e-04\n",
      "Average loss (last 100 batches): 0.5378, lr: 2.43e-04\n",
      "Average loss (last 100 batches): 0.5746, lr: 2.43e-04\n",
      "Average loss (last 100 batches): 0.7344, lr: 2.42e-04\n",
      "Average loss (last 100 batches): 0.4905, lr: 2.42e-04\n",
      "Average loss (last 100 batches): 0.4321, lr: 2.42e-04\n",
      "Average loss (last 100 batches): 0.6649, lr: 2.42e-04\n",
      "Average loss (last 100 batches): 0.7580, lr: 2.41e-04\n",
      "Average loss (last 100 batches): 0.6705, lr: 2.41e-04\n",
      "Average loss (last 100 batches): 0.5254, lr: 2.41e-04\n",
      "Average loss (last 100 batches): 0.6731, lr: 2.41e-04\n",
      "Average loss (last 100 batches): 0.4975, lr: 2.40e-04\n",
      "Average loss (last 100 batches): 0.7211, lr: 2.40e-04\n",
      "Average loss (last 100 batches): 0.4512, lr: 2.40e-04\n",
      "Average loss (last 100 batches): 0.5402, lr: 2.40e-04\n",
      "Average loss (last 100 batches): 0.4335, lr: 2.39e-04\n",
      "Average loss (last 100 batches): 0.4288, lr: 2.39e-04\n",
      "Average loss (last 100 batches): 0.4958, lr: 2.39e-04\n",
      "Average loss (last 100 batches): 0.4974, lr: 2.39e-04\n",
      "Average loss (last 100 batches): 0.4399, lr: 2.38e-04\n",
      "Average loss (last 100 batches): 0.5714, lr: 2.38e-04\n",
      "Average loss (last 100 batches): 0.4937, lr: 2.38e-04\n",
      "Average loss (last 100 batches): 0.5288, lr: 2.38e-04\n",
      "Average loss (last 100 batches): 0.4217, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 0.5412, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 0.5158, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 0.5589, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 0.6251, lr: 2.37e-04\n",
      "Average loss (last 100 batches): 0.6181, lr: 2.36e-04\n",
      "Average loss (last 100 batches): 0.4400, lr: 2.36e-04\n",
      "Average loss (last 100 batches): 0.5551, lr: 2.36e-04\n",
      "Average loss (last 100 batches): 0.4585, lr: 2.36e-04\n",
      "Average loss (last 100 batches): 0.5717, lr: 2.35e-04\n",
      "Average loss (last 100 batches): 0.6547, lr: 2.35e-04\n",
      "Average loss (last 100 batches): 0.4461, lr: 2.35e-04\n",
      "Average loss (last 100 batches): 0.4695, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 0.7779, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 0.5753, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 0.5011, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 0.4929, lr: 2.34e-04\n",
      "Average loss (last 100 batches): 0.5893, lr: 2.33e-04\n",
      "Average loss (last 100 batches): 0.4874, lr: 2.33e-04\n",
      "Average loss (last 100 batches): 0.6357, lr: 2.33e-04\n",
      "Average loss (last 100 batches): 0.4308, lr: 2.33e-04\n",
      "Average loss (last 100 batches): 0.5887, lr: 2.32e-04\n",
      "Average loss (last 100 batches): 0.4320, lr: 2.32e-04\n",
      "Average loss (last 100 batches): 0.6308, lr: 2.32e-04\n",
      "Average loss (last 100 batches): 0.5827, lr: 2.32e-04\n",
      "Average loss (last 100 batches): 0.4303, lr: 2.31e-04\n",
      "Average loss (last 100 batches): 0.5538, lr: 2.31e-04\n",
      "Average loss (last 100 batches): 0.4891, lr: 2.31e-04\n",
      "Average loss (last 100 batches): 0.6283, lr: 2.31e-04\n",
      "Average loss (last 100 batches): 0.5060, lr: 2.30e-04\n",
      "Average loss (last 100 batches): 0.4466, lr: 2.30e-04\n",
      "Average loss (last 100 batches): 0.5798, lr: 2.30e-04\n",
      "Average loss (last 100 batches): 0.4917, lr: 2.30e-04\n",
      "Average loss (last 100 batches): 0.6191, lr: 2.29e-04\n",
      "Average loss (last 100 batches): 0.4924, lr: 2.29e-04\n",
      "Average loss (last 100 batches): 0.4466, lr: 2.29e-04\n",
      "Average loss (last 100 batches): 0.5600, lr: 2.29e-04\n",
      "Average loss (last 100 batches): 0.5472, lr: 2.28e-04\n",
      "Average loss (last 100 batches): 0.5365, lr: 2.28e-04\n",
      "Average loss (last 100 batches): 0.5166, lr: 2.28e-04\n",
      "Average loss (last 100 batches): 0.5342, lr: 2.28e-04\n",
      "Average loss (last 100 batches): 0.4763, lr: 2.27e-04\n",
      "Average loss (last 100 batches): 0.4503, lr: 2.27e-04\n",
      "Average loss (last 100 batches): 0.5030, lr: 2.27e-04\n",
      "Average loss (last 100 batches): 0.5869, lr: 2.27e-04\n",
      "Average loss (last 100 batches): 0.4355, lr: 2.26e-04\n",
      "Average loss (last 100 batches): 0.5783, lr: 2.26e-04\n",
      "Average loss (last 100 batches): 0.4774, lr: 2.26e-04\n",
      "Average loss (last 100 batches): 0.4332, lr: 2.26e-04\n",
      "Average loss (last 100 batches): 0.4305, lr: 2.25e-04\n",
      "Average loss (last 100 batches): 0.5367, lr: 2.25e-04\n",
      "Average loss (last 100 batches): 0.7123, lr: 2.25e-04\n",
      "Average loss (last 100 batches): 0.4490, lr: 2.25e-04\n",
      "Average loss (last 100 batches): 0.7617, lr: 2.24e-04\n",
      "Average loss (last 100 batches): 0.6781, lr: 2.24e-04\n",
      "Average loss (last 100 batches): 0.4688, lr: 2.24e-04\n",
      "Average loss (last 100 batches): 0.5883, lr: 2.24e-04\n",
      "Average loss (last 100 batches): 0.4998, lr: 2.23e-04\n",
      "Average loss (last 100 batches): 0.4660, lr: 2.23e-04\n",
      "Average loss (last 100 batches): 0.4836, lr: 2.23e-04\n",
      "Average loss (last 100 batches): 0.4983, lr: 2.23e-04\n",
      "Average loss (last 100 batches): 0.6380, lr: 2.22e-04\n",
      "Average loss (last 100 batches): 0.5405, lr: 2.22e-04\n",
      "Average loss (last 100 batches): 0.4224, lr: 2.22e-04\n",
      "Average loss (last 100 batches): 0.4920, lr: 2.22e-04\n",
      "Average loss (last 100 batches): 0.4758, lr: 2.21e-04\n",
      "Average loss (last 100 batches): 0.5405, lr: 2.21e-04\n",
      "Average loss (last 100 batches): 0.4454, lr: 2.21e-04\n",
      "Average loss (last 100 batches): 0.4023, lr: 2.20e-04\n",
      "Average loss (last 100 batches): 0.5249, lr: 2.20e-04\n",
      "Average loss (last 100 batches): 0.6456, lr: 2.20e-04\n",
      "Average loss (last 100 batches): 0.6662, lr: 2.20e-04\n",
      "Average loss (last 100 batches): 0.4257, lr: 2.19e-04\n",
      "Average loss (last 100 batches): 0.5486, lr: 2.19e-04\n",
      "Average loss (last 100 batches): 0.5254, lr: 2.19e-04\n",
      "Average loss (last 100 batches): 0.5064, lr: 2.19e-04\n",
      "Average loss (last 100 batches): 0.5332, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 0.5082, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 0.5146, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 0.6351, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 0.6084, lr: 2.18e-04\n",
      "Average loss (last 100 batches): 0.4781, lr: 2.17e-04\n",
      "Average loss (last 100 batches): 0.5001, lr: 2.17e-04\n",
      "Average loss (last 100 batches): 0.4313, lr: 2.17e-04\n",
      "Average loss (last 100 batches): 0.5737, lr: 2.17e-04\n",
      "Average loss (last 100 batches): 0.7664, lr: 2.16e-04\n",
      "Average loss (last 100 batches): 0.4561, lr: 2.16e-04\n",
      "Average loss (last 100 batches): 0.4256, lr: 2.16e-04\n",
      "Average loss (last 100 batches): 0.5579, lr: 2.16e-04\n",
      "Average loss (last 100 batches): 0.5108, lr: 2.15e-04\n",
      "Average loss (last 100 batches): 0.4265, lr: 2.15e-04\n",
      "Average loss (last 100 batches): 0.5003, lr: 2.15e-04\n",
      "Average loss (last 100 batches): 0.5795, lr: 2.15e-04\n",
      "Average loss (last 100 batches): 0.4942, lr: 2.14e-04\n",
      "Average loss (last 100 batches): 0.4167, lr: 2.14e-04\n",
      "Average loss (last 100 batches): 0.4401, lr: 2.14e-04\n",
      "Average loss (last 100 batches): 0.6037, lr: 2.14e-04\n",
      "Average loss (last 100 batches): 0.4085, lr: 2.13e-04\n",
      "Average loss (last 100 batches): 0.4371, lr: 2.13e-04\n",
      "Average loss (last 100 batches): 0.5134, lr: 2.13e-04\n",
      "Average loss (last 100 batches): 0.4625, lr: 2.12e-04\n",
      "Average loss (last 100 batches): 0.5505, lr: 2.12e-04\n",
      "Average loss (last 100 batches): 0.5336, lr: 2.12e-04\n",
      "Average loss (last 100 batches): 0.6856, lr: 2.12e-04\n",
      "Average loss (last 100 batches): 0.5550, lr: 2.11e-04\n",
      "Average loss (last 100 batches): 0.4538, lr: 2.11e-04\n",
      "Average loss (last 100 batches): 0.4378, lr: 2.11e-04\n",
      "Average loss (last 100 batches): 0.5377, lr: 2.11e-04\n",
      "Average loss (last 100 batches): 0.4724, lr: 2.10e-04\n",
      "Average loss (last 100 batches): 0.4613, lr: 2.10e-04\n",
      "Average loss (last 100 batches): 0.4656, lr: 2.10e-04\n",
      "Average loss (last 100 batches): 0.4936, lr: 2.10e-04\n",
      "Average loss (last 100 batches): 0.6234, lr: 2.09e-04\n",
      "Average loss (last 100 batches): 0.5838, lr: 2.09e-04\n",
      "Average loss (last 100 batches): 0.5868, lr: 2.09e-04\n",
      "Average loss (last 100 batches): 0.5646, lr: 2.09e-04\n",
      "Average loss (last 100 batches): 0.4414, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 0.4529, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 0.5920, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 0.5633, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 0.4473, lr: 2.08e-04\n",
      "Average loss (last 100 batches): 0.4466, lr: 2.07e-04\n",
      "Average loss (last 100 batches): 0.4348, lr: 2.07e-04\n",
      "Average loss (last 100 batches): 0.4578, lr: 2.07e-04\n",
      "Average loss (last 100 batches): 0.4770, lr: 2.07e-04\n",
      "Average loss (last 100 batches): 0.4591, lr: 2.06e-04\n",
      "Average loss (last 100 batches): 0.4648, lr: 2.06e-04\n",
      "Average loss (last 100 batches): 0.4751, lr: 2.06e-04\n",
      "Average loss (last 100 batches): 0.3902, lr: 2.05e-04\n",
      "Average loss (last 100 batches): 0.5907, lr: 2.05e-04\n",
      "Average loss (last 100 batches): 0.5915, lr: 2.05e-04\n",
      "Average loss (last 100 batches): 0.5181, lr: 2.05e-04\n",
      "Average loss (last 100 batches): 0.5660, lr: 2.04e-04\n",
      "Average loss (last 100 batches): 0.4955, lr: 2.04e-04\n",
      "Average loss (last 100 batches): 0.5118, lr: 2.04e-04\n",
      "Average loss (last 100 batches): 0.4709, lr: 2.04e-04\n",
      "Average loss (last 100 batches): 0.5535, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 0.5063, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 0.5808, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 0.5422, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 1.1677, lr: 2.03e-04\n",
      "Average loss (last 100 batches): 0.4681, lr: 2.02e-04\n",
      "Average loss (last 100 batches): 0.5412, lr: 2.02e-04\n",
      "Average loss (last 100 batches): 0.5136, lr: 2.02e-04\n",
      "Average loss (last 100 batches): 0.4351, lr: 2.02e-04\n",
      "Average loss (last 100 batches): 0.5155, lr: 2.01e-04\n",
      "Average loss (last 100 batches): 0.5237, lr: 2.01e-04\n",
      "Average loss (last 100 batches): 0.5085, lr: 2.01e-04\n",
      "Average loss (last 100 batches): 0.5381, lr: 2.01e-04\n",
      "Average loss (last 100 batches): 0.9433, lr: 2.00e-04\n",
      "Average loss (last 100 batches): 0.4756, lr: 2.00e-04\n",
      "Average loss (last 100 batches): 0.4661, lr: 2.00e-04\n",
      "Average loss (last 100 batches): 0.4729, lr: 2.00e-04\n",
      "Average loss (last 100 batches): 0.5323, lr: 1.99e-04\n",
      "Average loss (last 100 batches): 0.4352, lr: 1.99e-04\n",
      "Average loss (last 100 batches): 0.5545, lr: 1.99e-04\n",
      "Average loss (last 100 batches): 0.6454, lr: 1.99e-04\n",
      "Average loss (last 100 batches): 0.5270, lr: 1.98e-04\n",
      "Average loss (last 100 batches): 0.4388, lr: 1.98e-04\n",
      "Average loss (last 100 batches): 0.4742, lr: 1.98e-04\n",
      "Average loss (last 100 batches): 0.6194, lr: 1.98e-04\n",
      "Average loss (last 100 batches): 0.5489, lr: 1.97e-04\n",
      "Average loss (last 100 batches): 0.4026, lr: 1.97e-04\n",
      "Average loss (last 100 batches): 0.5725, lr: 1.97e-04\n",
      "Average loss (last 100 batches): 0.6189, lr: 1.97e-04\n",
      "Average loss (last 100 batches): 0.4435, lr: 1.96e-04\n",
      "Average loss (last 100 batches): 0.4137, lr: 1.96e-04\n",
      "Average loss (last 100 batches): 0.4330, lr: 1.96e-04\n",
      "Average loss (last 100 batches): 0.4189, lr: 1.96e-04\n",
      "Average loss (last 100 batches): 0.4991, lr: 1.95e-04\n",
      "Average loss (last 100 batches): 0.4372, lr: 1.95e-04\n",
      "Average loss (last 100 batches): 0.4386, lr: 1.95e-04\n",
      "Average loss (last 100 batches): 0.4855, lr: 1.95e-04\n",
      "Average loss (last 100 batches): 0.5885, lr: 1.94e-04\n",
      "Average loss (last 100 batches): 0.4305, lr: 1.94e-04\n",
      "Average loss (last 100 batches): 0.4657, lr: 1.94e-04\n",
      "Average loss (last 100 batches): 0.4422, lr: 1.94e-04\n",
      "Average loss (last 100 batches): 0.4711, lr: 1.93e-04\n",
      "Average loss (last 100 batches): 0.4618, lr: 1.93e-04\n",
      "Average loss (last 100 batches): 0.3963, lr: 1.93e-04\n",
      "Average loss (last 100 batches): 0.5161, lr: 1.93e-04\n",
      "Average loss (last 100 batches): 0.4167, lr: 1.92e-04\n",
      "Average loss (last 100 batches): 0.4614, lr: 1.92e-04\n",
      "Average loss (last 100 batches): 0.6917, lr: 1.92e-04\n",
      "Average loss (last 100 batches): 0.5266, lr: 1.92e-04\n",
      "Average loss (last 100 batches): 0.4752, lr: 1.91e-04\n",
      "Average loss (last 100 batches): 0.4844, lr: 1.91e-04\n",
      "Average loss (last 100 batches): 0.4240, lr: 1.91e-04\n",
      "Average loss (last 100 batches): 0.4181, lr: 1.90e-04\n",
      "Average loss (last 100 batches): 0.5357, lr: 1.90e-04\n",
      "Average loss (last 100 batches): 0.4730, lr: 1.90e-04\n",
      "Average loss (last 100 batches): 0.4466, lr: 1.90e-04\n",
      "Average loss (last 100 batches): 0.5447, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 0.4102, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 0.6654, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 0.5987, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 0.7993, lr: 1.89e-04\n",
      "Average loss (last 100 batches): 0.4395, lr: 1.88e-04\n",
      "Average loss (last 100 batches): 0.6674, lr: 1.88e-04\n",
      "Average loss (last 100 batches): 0.4372, lr: 1.88e-04\n",
      "Average loss (last 100 batches): 0.6237, lr: 1.88e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0863a8905d7446319d606d4f846e703f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Train Loss: 0.5272 | Test Loss: 56558133547421.3281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3478df7f1dbb42d6988c6b6b89c1d5e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.5639, lr: 1.87e-04\n",
      "Average loss (last 100 batches): 0.4635, lr: 1.87e-04\n",
      "Average loss (last 100 batches): 0.4928, lr: 1.87e-04\n",
      "Average loss (last 100 batches): 0.6635, lr: 1.87e-04\n",
      "Average loss (last 100 batches): 0.4518, lr: 1.86e-04\n",
      "Average loss (last 100 batches): 0.4639, lr: 1.86e-04\n",
      "Average loss (last 100 batches): 0.4106, lr: 1.86e-04\n",
      "Average loss (last 100 batches): 0.6901, lr: 1.86e-04\n",
      "Average loss (last 100 batches): 0.4438, lr: 1.85e-04\n",
      "Average loss (last 100 batches): 0.4066, lr: 1.85e-04\n",
      "Average loss (last 100 batches): 0.4366, lr: 1.85e-04\n",
      "Average loss (last 100 batches): 0.4726, lr: 1.85e-04\n",
      "Average loss (last 100 batches): 0.5555, lr: 1.84e-04\n",
      "Average loss (last 100 batches): 0.4374, lr: 1.84e-04\n",
      "Average loss (last 100 batches): 0.3897, lr: 1.84e-04\n",
      "Average loss (last 100 batches): 0.4939, lr: 1.83e-04\n",
      "Average loss (last 100 batches): 0.4222, lr: 1.83e-04\n",
      "Average loss (last 100 batches): 0.4256, lr: 1.83e-04\n",
      "Average loss (last 100 batches): 0.4051, lr: 1.83e-04\n",
      "Average loss (last 100 batches): 0.6100, lr: 1.82e-04\n",
      "Average loss (last 100 batches): 0.4929, lr: 1.82e-04\n",
      "Average loss (last 100 batches): 0.4831, lr: 1.82e-04\n",
      "Average loss (last 100 batches): 0.5762, lr: 1.82e-04\n",
      "Average loss (last 100 batches): 0.5109, lr: 1.81e-04\n",
      "Average loss (last 100 batches): 0.6349, lr: 1.81e-04\n",
      "Average loss (last 100 batches): 0.5014, lr: 1.81e-04\n",
      "Average loss (last 100 batches): 0.4575, lr: 1.81e-04\n",
      "Average loss (last 100 batches): 0.4072, lr: 1.80e-04\n",
      "Average loss (last 100 batches): 0.5847, lr: 1.80e-04\n",
      "Average loss (last 100 batches): 0.5069, lr: 1.80e-04\n",
      "Average loss (last 100 batches): 0.5088, lr: 1.80e-04\n",
      "Average loss (last 100 batches): 0.5143, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 0.4888, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 0.6118, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 0.4187, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 0.6082, lr: 1.79e-04\n",
      "Average loss (last 100 batches): 0.4116, lr: 1.78e-04\n",
      "Average loss (last 100 batches): 0.5277, lr: 1.78e-04\n",
      "Average loss (last 100 batches): 0.5293, lr: 1.78e-04\n",
      "Average loss (last 100 batches): 0.4830, lr: 1.78e-04\n",
      "Average loss (last 100 batches): 0.4204, lr: 1.77e-04\n",
      "Average loss (last 100 batches): 0.4026, lr: 1.77e-04\n",
      "Average loss (last 100 batches): 0.4322, lr: 1.77e-04\n",
      "Average loss (last 100 batches): 0.6658, lr: 1.76e-04\n",
      "Average loss (last 100 batches): 0.5211, lr: 1.76e-04\n",
      "Average loss (last 100 batches): 0.4407, lr: 1.76e-04\n",
      "Average loss (last 100 batches): 0.5177, lr: 1.76e-04\n",
      "Average loss (last 100 batches): 0.4688, lr: 1.75e-04\n",
      "Average loss (last 100 batches): 0.4238, lr: 1.75e-04\n",
      "Average loss (last 100 batches): 0.6227, lr: 1.75e-04\n",
      "Average loss (last 100 batches): 0.5365, lr: 1.75e-04\n",
      "Average loss (last 100 batches): 0.3976, lr: 1.74e-04\n",
      "Average loss (last 100 batches): 0.5552, lr: 1.74e-04\n",
      "Average loss (last 100 batches): 0.4673, lr: 1.74e-04\n",
      "Average loss (last 100 batches): 0.3926, lr: 1.74e-04\n",
      "Average loss (last 100 batches): 0.7086, lr: 1.73e-04\n",
      "Average loss (last 100 batches): 0.4584, lr: 1.73e-04\n",
      "Average loss (last 100 batches): 0.4351, lr: 1.73e-04\n",
      "Average loss (last 100 batches): 0.5339, lr: 1.73e-04\n",
      "Average loss (last 100 batches): 0.4917, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 0.5044, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 0.4245, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 0.4788, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 0.5762, lr: 1.72e-04\n",
      "Average loss (last 100 batches): 0.4578, lr: 1.71e-04\n",
      "Average loss (last 100 batches): 0.4722, lr: 1.71e-04\n",
      "Average loss (last 100 batches): 0.4118, lr: 1.71e-04\n",
      "Average loss (last 100 batches): 0.5803, lr: 1.71e-04\n",
      "Average loss (last 100 batches): 0.4642, lr: 1.70e-04\n",
      "Average loss (last 100 batches): 0.4408, lr: 1.70e-04\n",
      "Average loss (last 100 batches): 0.5753, lr: 1.70e-04\n",
      "Average loss (last 100 batches): 0.3903, lr: 1.70e-04\n",
      "Average loss (last 100 batches): 0.4027, lr: 1.69e-04\n",
      "Average loss (last 100 batches): 0.4445, lr: 1.69e-04\n",
      "Average loss (last 100 batches): 0.5069, lr: 1.69e-04\n",
      "Average loss (last 100 batches): 0.4068, lr: 1.69e-04\n",
      "Average loss (last 100 batches): 0.4621, lr: 1.68e-04\n",
      "Average loss (last 100 batches): 0.5023, lr: 1.68e-04\n",
      "Average loss (last 100 batches): 0.4242, lr: 1.68e-04\n",
      "Average loss (last 100 batches): 0.4541, lr: 1.68e-04\n",
      "Average loss (last 100 batches): 0.4145, lr: 1.67e-04\n",
      "Average loss (last 100 batches): 0.4249, lr: 1.67e-04\n",
      "Average loss (last 100 batches): 0.4090, lr: 1.67e-04\n",
      "Average loss (last 100 batches): 0.4756, lr: 1.67e-04\n",
      "Average loss (last 100 batches): 0.4278, lr: 1.66e-04\n",
      "Average loss (last 100 batches): 0.4940, lr: 1.66e-04\n",
      "Average loss (last 100 batches): 0.4271, lr: 1.66e-04\n",
      "Average loss (last 100 batches): 0.4565, lr: 1.66e-04\n",
      "Average loss (last 100 batches): 0.5811, lr: 1.65e-04\n",
      "Average loss (last 100 batches): 0.4735, lr: 1.65e-04\n",
      "Average loss (last 100 batches): 0.3943, lr: 1.65e-04\n",
      "Average loss (last 100 batches): 0.4079, lr: 1.65e-04\n",
      "Average loss (last 100 batches): 0.5325, lr: 1.64e-04\n",
      "Average loss (last 100 batches): 0.5297, lr: 1.64e-04\n",
      "Average loss (last 100 batches): 0.5639, lr: 1.64e-04\n",
      "Average loss (last 100 batches): 0.5418, lr: 1.64e-04\n",
      "Average loss (last 100 batches): 0.4628, lr: 1.63e-04\n",
      "Average loss (last 100 batches): 0.5321, lr: 1.63e-04\n",
      "Average loss (last 100 batches): 0.7907, lr: 1.63e-04\n",
      "Average loss (last 100 batches): 0.7136, lr: 1.63e-04\n",
      "Average loss (last 100 batches): 0.5994, lr: 1.62e-04\n",
      "Average loss (last 100 batches): 0.6074, lr: 1.62e-04\n",
      "Average loss (last 100 batches): 0.4992, lr: 1.62e-04\n",
      "Average loss (last 100 batches): 0.5296, lr: 1.61e-04\n",
      "Average loss (last 100 batches): 0.4664, lr: 1.61e-04\n",
      "Average loss (last 100 batches): 0.4953, lr: 1.61e-04\n",
      "Average loss (last 100 batches): 0.4988, lr: 1.61e-04\n",
      "Average loss (last 100 batches): 0.5176, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 0.4207, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 0.5008, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 0.5377, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 0.5671, lr: 1.60e-04\n",
      "Average loss (last 100 batches): 0.6378, lr: 1.59e-04\n",
      "Average loss (last 100 batches): 0.5177, lr: 1.59e-04\n",
      "Average loss (last 100 batches): 0.4329, lr: 1.59e-04\n",
      "Average loss (last 100 batches): 0.4984, lr: 1.59e-04\n",
      "Average loss (last 100 batches): 0.4923, lr: 1.58e-04\n",
      "Average loss (last 100 batches): 0.4619, lr: 1.58e-04\n",
      "Average loss (last 100 batches): 0.5254, lr: 1.58e-04\n",
      "Average loss (last 100 batches): 0.4809, lr: 1.58e-04\n",
      "Average loss (last 100 batches): 0.4679, lr: 1.57e-04\n",
      "Average loss (last 100 batches): 0.4439, lr: 1.57e-04\n",
      "Average loss (last 100 batches): 0.4299, lr: 1.57e-04\n",
      "Average loss (last 100 batches): 0.5034, lr: 1.57e-04\n",
      "Average loss (last 100 batches): 0.5014, lr: 1.56e-04\n",
      "Average loss (last 100 batches): 0.5604, lr: 1.56e-04\n",
      "Average loss (last 100 batches): 0.6729, lr: 1.56e-04\n",
      "Average loss (last 100 batches): 0.5640, lr: 1.56e-04\n",
      "Average loss (last 100 batches): 0.4388, lr: 1.55e-04\n",
      "Average loss (last 100 batches): 0.4480, lr: 1.55e-04\n",
      "Average loss (last 100 batches): 0.4815, lr: 1.55e-04\n",
      "Average loss (last 100 batches): 0.4828, lr: 1.55e-04\n",
      "Average loss (last 100 batches): 0.4142, lr: 1.54e-04\n",
      "Average loss (last 100 batches): 0.5568, lr: 1.54e-04\n",
      "Average loss (last 100 batches): 0.5167, lr: 1.54e-04\n",
      "Average loss (last 100 batches): 0.4507, lr: 1.53e-04\n",
      "Average loss (last 100 batches): 0.4171, lr: 1.53e-04\n",
      "Average loss (last 100 batches): 0.4442, lr: 1.53e-04\n",
      "Average loss (last 100 batches): 0.4049, lr: 1.53e-04\n",
      "Average loss (last 100 batches): 0.3939, lr: 1.52e-04\n",
      "Average loss (last 100 batches): 0.5462, lr: 1.52e-04\n",
      "Average loss (last 100 batches): 0.4007, lr: 1.52e-04\n",
      "Average loss (last 100 batches): 0.4285, lr: 1.52e-04\n",
      "Average loss (last 100 batches): 0.7248, lr: 1.51e-04\n",
      "Average loss (last 100 batches): 0.4425, lr: 1.51e-04\n",
      "Average loss (last 100 batches): 0.4098, lr: 1.51e-04\n",
      "Average loss (last 100 batches): 0.4023, lr: 1.51e-04\n",
      "Average loss (last 100 batches): 0.4156, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 0.4140, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 0.6585, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 0.4880, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 0.7538, lr: 1.50e-04\n",
      "Average loss (last 100 batches): 0.6639, lr: 1.49e-04\n",
      "Average loss (last 100 batches): 0.5094, lr: 1.49e-04\n",
      "Average loss (last 100 batches): 0.4459, lr: 1.49e-04\n",
      "Average loss (last 100 batches): 0.4224, lr: 1.49e-04\n",
      "Average loss (last 100 batches): 0.4874, lr: 1.48e-04\n",
      "Average loss (last 100 batches): 0.5345, lr: 1.48e-04\n",
      "Average loss (last 100 batches): 0.4182, lr: 1.48e-04\n",
      "Average loss (last 100 batches): 0.6650, lr: 1.48e-04\n",
      "Average loss (last 100 batches): 0.4584, lr: 1.47e-04\n",
      "Average loss (last 100 batches): 0.4617, lr: 1.47e-04\n",
      "Average loss (last 100 batches): 0.4378, lr: 1.47e-04\n",
      "Average loss (last 100 batches): 0.5480, lr: 1.46e-04\n",
      "Average loss (last 100 batches): 0.6183, lr: 1.46e-04\n",
      "Average loss (last 100 batches): 0.5606, lr: 1.46e-04\n",
      "Average loss (last 100 batches): 0.5086, lr: 1.46e-04\n",
      "Average loss (last 100 batches): 0.4523, lr: 1.45e-04\n",
      "Average loss (last 100 batches): 0.7456, lr: 1.45e-04\n",
      "Average loss (last 100 batches): 0.4671, lr: 1.45e-04\n",
      "Average loss (last 100 batches): 0.4370, lr: 1.45e-04\n",
      "Average loss (last 100 batches): 0.5451, lr: 1.44e-04\n",
      "Average loss (last 100 batches): 0.4009, lr: 1.44e-04\n",
      "Average loss (last 100 batches): 0.4552, lr: 1.44e-04\n",
      "Average loss (last 100 batches): 0.5002, lr: 1.44e-04\n",
      "Average loss (last 100 batches): 0.5159, lr: 1.43e-04\n",
      "Average loss (last 100 batches): 0.5513, lr: 1.43e-04\n",
      "Average loss (last 100 batches): 0.4085, lr: 1.43e-04\n",
      "Average loss (last 100 batches): 0.6471, lr: 1.43e-04\n",
      "Average loss (last 100 batches): 0.4350, lr: 1.42e-04\n",
      "Average loss (last 100 batches): 0.7101, lr: 1.42e-04\n",
      "Average loss (last 100 batches): 0.3874, lr: 1.42e-04\n",
      "Average loss (last 100 batches): 0.4170, lr: 1.42e-04\n",
      "Average loss (last 100 batches): 0.4329, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 0.4628, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 0.5145, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 0.4134, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 0.5924, lr: 1.41e-04\n",
      "Average loss (last 100 batches): 0.4474, lr: 1.40e-04\n",
      "Average loss (last 100 batches): 0.3937, lr: 1.40e-04\n",
      "Average loss (last 100 batches): 0.4689, lr: 1.40e-04\n",
      "Average loss (last 100 batches): 0.5108, lr: 1.40e-04\n",
      "Average loss (last 100 batches): 0.4583, lr: 1.39e-04\n",
      "Average loss (last 100 batches): 0.6484, lr: 1.39e-04\n",
      "Average loss (last 100 batches): 0.4604, lr: 1.39e-04\n",
      "Average loss (last 100 batches): 0.4847, lr: 1.39e-04\n",
      "Average loss (last 100 batches): 0.3942, lr: 1.38e-04\n",
      "Average loss (last 100 batches): 0.4048, lr: 1.38e-04\n",
      "Average loss (last 100 batches): 0.4166, lr: 1.38e-04\n",
      "Average loss (last 100 batches): 0.4298, lr: 1.38e-04\n",
      "Average loss (last 100 batches): 0.6177, lr: 1.37e-04\n",
      "Average loss (last 100 batches): 0.4834, lr: 1.37e-04\n",
      "Average loss (last 100 batches): 0.4426, lr: 1.37e-04\n",
      "Average loss (last 100 batches): 0.5662, lr: 1.37e-04\n",
      "Average loss (last 100 batches): 0.4025, lr: 1.36e-04\n",
      "Average loss (last 100 batches): 0.4126, lr: 1.36e-04\n",
      "Average loss (last 100 batches): 0.6119, lr: 1.36e-04\n",
      "Average loss (last 100 batches): 0.4149, lr: 1.36e-04\n",
      "Average loss (last 100 batches): 0.4043, lr: 1.35e-04\n",
      "Average loss (last 100 batches): 0.4225, lr: 1.35e-04\n",
      "Average loss (last 100 batches): 0.5478, lr: 1.35e-04\n",
      "Average loss (last 100 batches): 0.7738, lr: 1.35e-04\n",
      "Average loss (last 100 batches): 0.5009, lr: 1.34e-04\n",
      "Average loss (last 100 batches): 0.4088, lr: 1.34e-04\n",
      "Average loss (last 100 batches): 0.6070, lr: 1.34e-04\n",
      "Average loss (last 100 batches): 0.5157, lr: 1.34e-04\n",
      "Average loss (last 100 batches): 0.5853, lr: 1.33e-04\n",
      "Average loss (last 100 batches): 0.4284, lr: 1.33e-04\n",
      "Average loss (last 100 batches): 0.4347, lr: 1.33e-04\n",
      "Average loss (last 100 batches): 0.4289, lr: 1.33e-04\n",
      "Average loss (last 100 batches): 0.5453, lr: 1.32e-04\n",
      "Average loss (last 100 batches): 0.4375, lr: 1.32e-04\n",
      "Average loss (last 100 batches): 0.4863, lr: 1.32e-04\n",
      "Average loss (last 100 batches): 0.4431, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 0.4553, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 0.4192, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 0.4000, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 0.4212, lr: 1.31e-04\n",
      "Average loss (last 100 batches): 0.4386, lr: 1.30e-04\n",
      "Average loss (last 100 batches): 0.4553, lr: 1.30e-04\n",
      "Average loss (last 100 batches): 0.3960, lr: 1.30e-04\n",
      "Average loss (last 100 batches): 0.4031, lr: 1.30e-04\n",
      "Average loss (last 100 batches): 0.4611, lr: 1.29e-04\n",
      "Average loss (last 100 batches): 0.4900, lr: 1.29e-04\n",
      "Average loss (last 100 batches): 0.5119, lr: 1.29e-04\n",
      "Average loss (last 100 batches): 0.4953, lr: 1.29e-04\n",
      "Average loss (last 100 batches): 0.4664, lr: 1.28e-04\n",
      "Average loss (last 100 batches): 0.5137, lr: 1.28e-04\n",
      "Average loss (last 100 batches): 0.4750, lr: 1.28e-04\n",
      "Average loss (last 100 batches): 0.5249, lr: 1.28e-04\n",
      "Average loss (last 100 batches): 0.3849, lr: 1.27e-04\n",
      "Average loss (last 100 batches): 0.5081, lr: 1.27e-04\n",
      "Average loss (last 100 batches): 0.4530, lr: 1.27e-04\n",
      "Average loss (last 100 batches): 0.5034, lr: 1.27e-04\n",
      "Average loss (last 100 batches): 0.4668, lr: 1.26e-04\n",
      "Average loss (last 100 batches): 0.3963, lr: 1.26e-04\n",
      "Average loss (last 100 batches): 0.5656, lr: 1.26e-04\n",
      "Average loss (last 100 batches): 0.4985, lr: 1.26e-04\n",
      "Average loss (last 100 batches): 0.3743, lr: 1.25e-04\n",
      "Average loss (last 100 batches): 0.3820, lr: 1.25e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3322ecb249bf4502817efa1d7f588417"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Train Loss: 0.4911 | Test Loss: 53727816099541.6562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b8addab023b49489b0e88243f8fc239"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.4912, lr: 1.25e-04\n",
      "Average loss (last 100 batches): 0.4948, lr: 1.24e-04\n",
      "Average loss (last 100 batches): 0.5184, lr: 1.24e-04\n",
      "Average loss (last 100 batches): 0.4008, lr: 1.24e-04\n",
      "Average loss (last 100 batches): 0.5049, lr: 1.24e-04\n",
      "Average loss (last 100 batches): 0.5571, lr: 1.23e-04\n",
      "Average loss (last 100 batches): 0.4889, lr: 1.23e-04\n",
      "Average loss (last 100 batches): 0.4142, lr: 1.23e-04\n",
      "Average loss (last 100 batches): 0.4339, lr: 1.23e-04\n",
      "Average loss (last 100 batches): 0.3774, lr: 1.22e-04\n",
      "Average loss (last 100 batches): 0.4092, lr: 1.22e-04\n",
      "Average loss (last 100 batches): 0.4790, lr: 1.22e-04\n",
      "Average loss (last 100 batches): 0.4187, lr: 1.22e-04\n",
      "Average loss (last 100 batches): 0.4579, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 0.4248, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 0.3976, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 0.4148, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 0.4143, lr: 1.21e-04\n",
      "Average loss (last 100 batches): 0.4329, lr: 1.20e-04\n",
      "Average loss (last 100 batches): 0.3774, lr: 1.20e-04\n",
      "Average loss (last 100 batches): 0.4672, lr: 1.20e-04\n",
      "Average loss (last 100 batches): 0.4405, lr: 1.19e-04\n",
      "Average loss (last 100 batches): 0.6189, lr: 1.19e-04\n",
      "Average loss (last 100 batches): 0.5313, lr: 1.19e-04\n",
      "Average loss (last 100 batches): 0.4212, lr: 1.19e-04\n",
      "Average loss (last 100 batches): 0.4772, lr: 1.18e-04\n",
      "Average loss (last 100 batches): 0.4780, lr: 1.18e-04\n",
      "Average loss (last 100 batches): 0.4170, lr: 1.18e-04\n",
      "Average loss (last 100 batches): 0.4615, lr: 1.18e-04\n",
      "Average loss (last 100 batches): 0.5040, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 0.5595, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 0.5272, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 0.4392, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 0.4074, lr: 1.17e-04\n",
      "Average loss (last 100 batches): 0.5263, lr: 1.16e-04\n",
      "Average loss (last 100 batches): 0.7088, lr: 1.16e-04\n",
      "Average loss (last 100 batches): 0.4803, lr: 1.16e-04\n",
      "Average loss (last 100 batches): 0.4194, lr: 1.16e-04\n",
      "Average loss (last 100 batches): 0.4786, lr: 1.15e-04\n",
      "Average loss (last 100 batches): 0.4153, lr: 1.15e-04\n",
      "Average loss (last 100 batches): 0.5251, lr: 1.15e-04\n",
      "Average loss (last 100 batches): 0.4517, lr: 1.15e-04\n",
      "Average loss (last 100 batches): 0.4729, lr: 1.14e-04\n",
      "Average loss (last 100 batches): 0.6750, lr: 1.14e-04\n",
      "Average loss (last 100 batches): 0.4075, lr: 1.14e-04\n",
      "Average loss (last 100 batches): 0.4266, lr: 1.14e-04\n",
      "Average loss (last 100 batches): 0.4377, lr: 1.13e-04\n",
      "Average loss (last 100 batches): 0.4073, lr: 1.13e-04\n",
      "Average loss (last 100 batches): 0.4326, lr: 1.13e-04\n",
      "Average loss (last 100 batches): 0.7230, lr: 1.13e-04\n",
      "Average loss (last 100 batches): 0.6439, lr: 1.12e-04\n",
      "Average loss (last 100 batches): 0.5112, lr: 1.12e-04\n",
      "Average loss (last 100 batches): 0.5913, lr: 1.12e-04\n",
      "Average loss (last 100 batches): 0.5217, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 0.4772, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 0.5211, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 0.4838, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 0.4067, lr: 1.11e-04\n",
      "Average loss (last 100 batches): 0.4466, lr: 1.10e-04\n",
      "Average loss (last 100 batches): 0.4175, lr: 1.10e-04\n",
      "Average loss (last 100 batches): 0.6076, lr: 1.10e-04\n",
      "Average loss (last 100 batches): 0.3958, lr: 1.10e-04\n",
      "Average loss (last 100 batches): 0.4682, lr: 1.09e-04\n",
      "Average loss (last 100 batches): 0.4925, lr: 1.09e-04\n",
      "Average loss (last 100 batches): 0.5253, lr: 1.09e-04\n",
      "Average loss (last 100 batches): 0.4394, lr: 1.09e-04\n",
      "Average loss (last 100 batches): 0.3884, lr: 1.08e-04\n",
      "Average loss (last 100 batches): 0.5682, lr: 1.08e-04\n",
      "Average loss (last 100 batches): 0.4235, lr: 1.08e-04\n",
      "Average loss (last 100 batches): 0.4355, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 0.4444, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 0.7580, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 0.4770, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 0.4907, lr: 1.07e-04\n",
      "Average loss (last 100 batches): 0.3901, lr: 1.06e-04\n",
      "Average loss (last 100 batches): 0.4498, lr: 1.06e-04\n",
      "Average loss (last 100 batches): 0.4043, lr: 1.06e-04\n",
      "Average loss (last 100 batches): 0.5054, lr: 1.06e-04\n",
      "Average loss (last 100 batches): 0.4947, lr: 1.05e-04\n",
      "Average loss (last 100 batches): 0.4921, lr: 1.05e-04\n",
      "Average loss (last 100 batches): 0.4493, lr: 1.05e-04\n",
      "Average loss (last 100 batches): 0.4693, lr: 1.04e-04\n",
      "Average loss (last 100 batches): 0.4163, lr: 1.04e-04\n",
      "Average loss (last 100 batches): 0.5260, lr: 1.04e-04\n",
      "Average loss (last 100 batches): 0.3677, lr: 1.04e-04\n",
      "Average loss (last 100 batches): 0.4979, lr: 1.03e-04\n",
      "Average loss (last 100 batches): 0.4505, lr: 1.03e-04\n",
      "Average loss (last 100 batches): 0.4142, lr: 1.03e-04\n",
      "Average loss (last 100 batches): 0.4132, lr: 1.03e-04\n",
      "Average loss (last 100 batches): 0.4072, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 0.4193, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 0.4244, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 0.4276, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 0.4804, lr: 1.02e-04\n",
      "Average loss (last 100 batches): 0.5235, lr: 1.01e-04\n",
      "Average loss (last 100 batches): 0.3901, lr: 1.01e-04\n",
      "Average loss (last 100 batches): 0.4353, lr: 1.01e-04\n",
      "Average loss (last 100 batches): 0.4630, lr: 1.01e-04\n",
      "Average loss (last 100 batches): 0.3867, lr: 1.00e-04\n",
      "Average loss (last 100 batches): 0.4870, lr: 1.00e-04\n",
      "Average loss (last 100 batches): 0.4176, lr: 9.98e-05\n",
      "Average loss (last 100 batches): 0.3747, lr: 9.95e-05\n",
      "Average loss (last 100 batches): 0.6508, lr: 9.93e-05\n",
      "Average loss (last 100 batches): 0.4242, lr: 9.90e-05\n",
      "Average loss (last 100 batches): 0.4530, lr: 9.88e-05\n",
      "Average loss (last 100 batches): 0.4285, lr: 9.85e-05\n",
      "Average loss (last 100 batches): 0.3979, lr: 9.83e-05\n",
      "Average loss (last 100 batches): 0.3680, lr: 9.80e-05\n",
      "Average loss (last 100 batches): 0.4457, lr: 9.78e-05\n",
      "Average loss (last 100 batches): 0.4090, lr: 9.75e-05\n",
      "Average loss (last 100 batches): 0.4391, lr: 9.73e-05\n",
      "Average loss (last 100 batches): 0.5875, lr: 9.70e-05\n",
      "Average loss (last 100 batches): 0.3770, lr: 9.68e-05\n",
      "Average loss (last 100 batches): 0.6988, lr: 9.65e-05\n",
      "Average loss (last 100 batches): 0.7109, lr: 9.63e-05\n",
      "Average loss (last 100 batches): 0.3696, lr: 9.60e-05\n",
      "Average loss (last 100 batches): 0.3797, lr: 9.58e-05\n",
      "Average loss (last 100 batches): 0.4461, lr: 9.55e-05\n",
      "Average loss (last 100 batches): 0.4155, lr: 9.52e-05\n",
      "Average loss (last 100 batches): 0.4197, lr: 9.50e-05\n",
      "Average loss (last 100 batches): 0.4316, lr: 9.47e-05\n",
      "Average loss (last 100 batches): 0.4415, lr: 9.45e-05\n",
      "Average loss (last 100 batches): 0.3708, lr: 9.43e-05\n",
      "Average loss (last 100 batches): 0.4051, lr: 9.40e-05\n",
      "Average loss (last 100 batches): 0.4216, lr: 9.38e-05\n",
      "Average loss (last 100 batches): 0.3919, lr: 9.35e-05\n",
      "Average loss (last 100 batches): 0.4680, lr: 9.33e-05\n",
      "Average loss (last 100 batches): 0.4480, lr: 9.30e-05\n",
      "Average loss (last 100 batches): 0.4318, lr: 9.28e-05\n",
      "Average loss (last 100 batches): 0.5839, lr: 9.25e-05\n",
      "Average loss (last 100 batches): 0.5119, lr: 9.23e-05\n",
      "Average loss (last 100 batches): 0.4195, lr: 9.20e-05\n",
      "Average loss (last 100 batches): 0.4571, lr: 9.17e-05\n",
      "Average loss (last 100 batches): 0.4254, lr: 9.15e-05\n",
      "Average loss (last 100 batches): 0.4145, lr: 9.12e-05\n",
      "Average loss (last 100 batches): 0.5041, lr: 9.10e-05\n",
      "Average loss (last 100 batches): 0.4739, lr: 9.07e-05\n",
      "Average loss (last 100 batches): 0.5378, lr: 9.05e-05\n",
      "Average loss (last 100 batches): 0.4096, lr: 9.02e-05\n",
      "Average loss (last 100 batches): 0.4103, lr: 9.00e-05\n",
      "Average loss (last 100 batches): 0.3902, lr: 8.97e-05\n",
      "Average loss (last 100 batches): 0.4267, lr: 8.95e-05\n",
      "Average loss (last 100 batches): 0.4162, lr: 8.93e-05\n",
      "Average loss (last 100 batches): 0.4887, lr: 8.90e-05\n",
      "Average loss (last 100 batches): 0.3992, lr: 8.88e-05\n",
      "Average loss (last 100 batches): 0.4073, lr: 8.85e-05\n",
      "Average loss (last 100 batches): 0.4688, lr: 8.82e-05\n",
      "Average loss (last 100 batches): 0.6548, lr: 8.80e-05\n",
      "Average loss (last 100 batches): 0.4967, lr: 8.77e-05\n",
      "Average loss (last 100 batches): 0.4622, lr: 8.75e-05\n",
      "Average loss (last 100 batches): 0.3977, lr: 8.72e-05\n",
      "Average loss (last 100 batches): 0.4070, lr: 8.70e-05\n",
      "Average loss (last 100 batches): 0.4746, lr: 8.67e-05\n",
      "Average loss (last 100 batches): 0.4310, lr: 8.65e-05\n",
      "Average loss (last 100 batches): 0.4337, lr: 8.62e-05\n",
      "Average loss (last 100 batches): 0.5160, lr: 8.60e-05\n",
      "Average loss (last 100 batches): 0.4577, lr: 8.58e-05\n",
      "Average loss (last 100 batches): 0.6081, lr: 8.55e-05\n",
      "Average loss (last 100 batches): 0.4618, lr: 8.53e-05\n",
      "Average loss (last 100 batches): 0.4552, lr: 8.50e-05\n",
      "Average loss (last 100 batches): 0.5481, lr: 8.48e-05\n",
      "Average loss (last 100 batches): 0.4564, lr: 8.45e-05\n",
      "Average loss (last 100 batches): 0.5691, lr: 8.43e-05\n",
      "Average loss (last 100 batches): 0.4523, lr: 8.40e-05\n",
      "Average loss (last 100 batches): 0.6483, lr: 8.38e-05\n",
      "Average loss (last 100 batches): 0.4043, lr: 8.35e-05\n",
      "Average loss (last 100 batches): 0.5708, lr: 8.33e-05\n",
      "Average loss (last 100 batches): 0.4827, lr: 8.30e-05\n",
      "Average loss (last 100 batches): 0.4186, lr: 8.28e-05\n",
      "Average loss (last 100 batches): 0.4357, lr: 8.25e-05\n",
      "Average loss (last 100 batches): 0.3956, lr: 8.23e-05\n",
      "Average loss (last 100 batches): 0.3822, lr: 8.20e-05\n",
      "Average loss (last 100 batches): 0.5481, lr: 8.18e-05\n",
      "Average loss (last 100 batches): 0.4100, lr: 8.15e-05\n",
      "Average loss (last 100 batches): 0.5785, lr: 8.13e-05\n",
      "Average loss (last 100 batches): 0.5159, lr: 8.10e-05\n",
      "Average loss (last 100 batches): 0.4649, lr: 8.07e-05\n",
      "Average loss (last 100 batches): 0.4127, lr: 8.05e-05\n",
      "Average loss (last 100 batches): 0.3581, lr: 8.02e-05\n",
      "Average loss (last 100 batches): 0.4259, lr: 8.00e-05\n",
      "Average loss (last 100 batches): 0.3907, lr: 7.98e-05\n",
      "Average loss (last 100 batches): 0.7917, lr: 7.95e-05\n",
      "Average loss (last 100 batches): 0.5947, lr: 7.93e-05\n",
      "Average loss (last 100 batches): 0.4653, lr: 7.90e-05\n",
      "Average loss (last 100 batches): 0.4507, lr: 7.88e-05\n",
      "Average loss (last 100 batches): 0.3833, lr: 7.85e-05\n",
      "Average loss (last 100 batches): 0.4622, lr: 7.83e-05\n",
      "Average loss (last 100 batches): 0.4165, lr: 7.80e-05\n",
      "Average loss (last 100 batches): 0.4708, lr: 7.78e-05\n",
      "Average loss (last 100 batches): 0.4940, lr: 7.75e-05\n",
      "Average loss (last 100 batches): 0.5713, lr: 7.73e-05\n",
      "Average loss (last 100 batches): 0.5257, lr: 7.70e-05\n",
      "Average loss (last 100 batches): 0.5855, lr: 7.67e-05\n",
      "Average loss (last 100 batches): 0.4587, lr: 7.65e-05\n",
      "Average loss (last 100 batches): 0.4016, lr: 7.62e-05\n",
      "Average loss (last 100 batches): 0.4085, lr: 7.60e-05\n",
      "Average loss (last 100 batches): 0.3805, lr: 7.57e-05\n",
      "Average loss (last 100 batches): 0.4160, lr: 7.55e-05\n",
      "Average loss (last 100 batches): 0.3628, lr: 7.52e-05\n",
      "Average loss (last 100 batches): 0.5425, lr: 7.50e-05\n",
      "Average loss (last 100 batches): 0.5661, lr: 7.48e-05\n",
      "Average loss (last 100 batches): 0.5351, lr: 7.45e-05\n",
      "Average loss (last 100 batches): 0.4241, lr: 7.43e-05\n",
      "Average loss (last 100 batches): 0.3871, lr: 7.40e-05\n",
      "Average loss (last 100 batches): 0.4418, lr: 7.38e-05\n",
      "Average loss (last 100 batches): 0.3926, lr: 7.35e-05\n",
      "Average loss (last 100 batches): 0.5688, lr: 7.32e-05\n",
      "Average loss (last 100 batches): 0.5243, lr: 7.30e-05\n",
      "Average loss (last 100 batches): 0.4258, lr: 7.27e-05\n",
      "Average loss (last 100 batches): 0.5056, lr: 7.25e-05\n",
      "Average loss (last 100 batches): 0.4328, lr: 7.22e-05\n",
      "Average loss (last 100 batches): 0.3644, lr: 7.20e-05\n",
      "Average loss (last 100 batches): 0.4545, lr: 7.17e-05\n",
      "Average loss (last 100 batches): 0.4411, lr: 7.15e-05\n",
      "Average loss (last 100 batches): 0.5163, lr: 7.12e-05\n",
      "Average loss (last 100 batches): 0.4437, lr: 7.10e-05\n",
      "Average loss (last 100 batches): 0.4025, lr: 7.07e-05\n",
      "Average loss (last 100 batches): 0.3730, lr: 7.05e-05\n",
      "Average loss (last 100 batches): 0.5280, lr: 7.03e-05\n",
      "Average loss (last 100 batches): 0.4036, lr: 7.00e-05\n",
      "Average loss (last 100 batches): 0.5274, lr: 6.98e-05\n",
      "Average loss (last 100 batches): 0.4737, lr: 6.95e-05\n",
      "Average loss (last 100 batches): 0.4896, lr: 6.93e-05\n",
      "Average loss (last 100 batches): 0.5537, lr: 6.90e-05\n",
      "Average loss (last 100 batches): 0.4440, lr: 6.88e-05\n",
      "Average loss (last 100 batches): 0.4533, lr: 6.85e-05\n",
      "Average loss (last 100 batches): 0.5237, lr: 6.83e-05\n",
      "Average loss (last 100 batches): 0.4489, lr: 6.80e-05\n",
      "Average loss (last 100 batches): 0.3909, lr: 6.78e-05\n",
      "Average loss (last 100 batches): 0.4047, lr: 6.75e-05\n",
      "Average loss (last 100 batches): 0.5554, lr: 6.73e-05\n",
      "Average loss (last 100 batches): 0.4399, lr: 6.70e-05\n",
      "Average loss (last 100 batches): 0.4245, lr: 6.68e-05\n",
      "Average loss (last 100 batches): 0.4565, lr: 6.65e-05\n",
      "Average loss (last 100 batches): 0.3951, lr: 6.63e-05\n",
      "Average loss (last 100 batches): 0.5515, lr: 6.60e-05\n",
      "Average loss (last 100 batches): 0.3657, lr: 6.57e-05\n",
      "Average loss (last 100 batches): 0.5442, lr: 6.55e-05\n",
      "Average loss (last 100 batches): 0.5380, lr: 6.53e-05\n",
      "Average loss (last 100 batches): 0.4361, lr: 6.50e-05\n",
      "Average loss (last 100 batches): 0.4121, lr: 6.48e-05\n",
      "Average loss (last 100 batches): 0.8262, lr: 6.45e-05\n",
      "Average loss (last 100 batches): 0.4774, lr: 6.43e-05\n",
      "Average loss (last 100 batches): 0.4051, lr: 6.40e-05\n",
      "Average loss (last 100 batches): 0.4450, lr: 6.38e-05\n",
      "Average loss (last 100 batches): 0.6498, lr: 6.35e-05\n",
      "Average loss (last 100 batches): 0.6070, lr: 6.33e-05\n",
      "Average loss (last 100 batches): 0.4226, lr: 6.30e-05\n",
      "Average loss (last 100 batches): 0.6289, lr: 6.28e-05\n",
      "Average loss (last 100 batches): 0.5076, lr: 6.25e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1dd51f43d2a14e5284045f8514cf3f8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Train Loss: 0.4703 | Test Loss: 55731426572943.1719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca99b718e4a74ffeaae0a1efb60b995e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss (last 100 batches): 0.4323, lr: 6.22e-05\n",
      "Average loss (last 100 batches): 0.4001, lr: 6.20e-05\n",
      "Average loss (last 100 batches): 0.3826, lr: 6.17e-05\n",
      "Average loss (last 100 batches): 0.3837, lr: 6.15e-05\n",
      "Average loss (last 100 batches): 0.5509, lr: 6.12e-05\n",
      "Average loss (last 100 batches): 0.4141, lr: 6.10e-05\n",
      "Average loss (last 100 batches): 0.5576, lr: 6.07e-05\n",
      "Average loss (last 100 batches): 0.5329, lr: 6.05e-05\n",
      "Average loss (last 100 batches): 0.3910, lr: 6.03e-05\n",
      "Average loss (last 100 batches): 0.5988, lr: 6.00e-05\n",
      "Average loss (last 100 batches): 0.4587, lr: 5.97e-05\n",
      "Average loss (last 100 batches): 0.4321, lr: 5.95e-05\n",
      "Average loss (last 100 batches): 0.5158, lr: 5.92e-05\n",
      "Average loss (last 100 batches): 0.5583, lr: 5.90e-05\n",
      "Average loss (last 100 batches): 0.4594, lr: 5.87e-05\n",
      "Average loss (last 100 batches): 0.3911, lr: 5.85e-05\n",
      "Average loss (last 100 batches): 0.5189, lr: 5.83e-05\n",
      "Average loss (last 100 batches): 0.5244, lr: 5.80e-05\n",
      "Average loss (last 100 batches): 0.6400, lr: 5.78e-05\n",
      "Average loss (last 100 batches): 0.4206, lr: 5.75e-05\n",
      "Average loss (last 100 batches): 0.5058, lr: 5.73e-05\n",
      "Average loss (last 100 batches): 0.7404, lr: 5.70e-05\n",
      "Average loss (last 100 batches): 0.3856, lr: 5.68e-05\n",
      "Average loss (last 100 batches): 0.4304, lr: 5.65e-05\n",
      "Average loss (last 100 batches): 0.4535, lr: 5.63e-05\n",
      "Average loss (last 100 batches): 0.5880, lr: 5.60e-05\n",
      "Average loss (last 100 batches): 0.4252, lr: 5.57e-05\n",
      "Average loss (last 100 batches): 0.5476, lr: 5.55e-05\n",
      "Average loss (last 100 batches): 0.3868, lr: 5.53e-05\n",
      "Average loss (last 100 batches): 0.4617, lr: 5.50e-05\n",
      "Average loss (last 100 batches): 0.3883, lr: 5.48e-05\n",
      "Average loss (last 100 batches): 0.4674, lr: 5.45e-05\n",
      "Average loss (last 100 batches): 0.3977, lr: 5.43e-05\n",
      "Average loss (last 100 batches): 0.4044, lr: 5.40e-05\n",
      "Average loss (last 100 batches): 0.4699, lr: 5.37e-05\n",
      "Average loss (last 100 batches): 0.5469, lr: 5.35e-05\n",
      "Average loss (last 100 batches): 0.4225, lr: 5.33e-05\n",
      "Average loss (last 100 batches): 0.3911, lr: 5.30e-05\n",
      "Average loss (last 100 batches): 0.4905, lr: 5.28e-05\n",
      "Average loss (last 100 batches): 0.4641, lr: 5.25e-05\n",
      "Average loss (last 100 batches): 0.4302, lr: 5.22e-05\n",
      "Average loss (last 100 batches): 0.4511, lr: 5.20e-05\n",
      "Average loss (last 100 batches): 0.5224, lr: 5.17e-05\n",
      "Average loss (last 100 batches): 0.4545, lr: 5.15e-05\n",
      "Average loss (last 100 batches): 0.4523, lr: 5.12e-05\n",
      "Average loss (last 100 batches): 0.4668, lr: 5.10e-05\n",
      "Average loss (last 100 batches): 0.3834, lr: 5.08e-05\n",
      "Average loss (last 100 batches): 0.3966, lr: 5.05e-05\n",
      "Average loss (last 100 batches): 0.3666, lr: 5.03e-05\n",
      "Average loss (last 100 batches): 0.5642, lr: 5.00e-05\n",
      "Average loss (last 100 batches): 0.5524, lr: 4.98e-05\n",
      "Average loss (last 100 batches): 0.4398, lr: 4.95e-05\n",
      "Average loss (last 100 batches): 0.5577, lr: 4.93e-05\n",
      "Average loss (last 100 batches): 0.4136, lr: 4.90e-05\n",
      "Average loss (last 100 batches): 0.3928, lr: 4.88e-05\n",
      "Average loss (last 100 batches): 0.6553, lr: 4.85e-05\n",
      "Average loss (last 100 batches): 0.4129, lr: 4.83e-05\n",
      "Average loss (last 100 batches): 0.4806, lr: 4.80e-05\n",
      "Average loss (last 100 batches): 0.4149, lr: 4.78e-05\n",
      "Average loss (last 100 batches): 0.4905, lr: 4.75e-05\n",
      "Average loss (last 100 batches): 0.4018, lr: 4.73e-05\n",
      "Average loss (last 100 batches): 0.4172, lr: 4.70e-05\n",
      "Average loss (last 100 batches): 0.3994, lr: 4.67e-05\n",
      "Average loss (last 100 batches): 0.5246, lr: 4.65e-05\n",
      "Average loss (last 100 batches): 0.3804, lr: 4.62e-05\n",
      "Average loss (last 100 batches): 0.4009, lr: 4.60e-05\n",
      "Average loss (last 100 batches): 0.4112, lr: 4.58e-05\n",
      "Average loss (last 100 batches): 0.4597, lr: 4.55e-05\n",
      "Average loss (last 100 batches): 0.6444, lr: 4.53e-05\n",
      "Average loss (last 100 batches): 0.4703, lr: 4.50e-05\n",
      "Average loss (last 100 batches): 0.5984, lr: 4.47e-05\n",
      "Average loss (last 100 batches): 0.5948, lr: 4.45e-05\n",
      "Average loss (last 100 batches): 0.4968, lr: 4.42e-05\n",
      "Average loss (last 100 batches): 0.4679, lr: 4.40e-05\n",
      "Average loss (last 100 batches): 0.4524, lr: 4.37e-05\n",
      "Average loss (last 100 batches): 0.5164, lr: 4.35e-05\n",
      "Average loss (last 100 batches): 0.3857, lr: 4.33e-05\n",
      "Average loss (last 100 batches): 0.5441, lr: 4.30e-05\n",
      "Average loss (last 100 batches): 0.6282, lr: 4.28e-05\n",
      "Average loss (last 100 batches): 0.5273, lr: 4.25e-05\n",
      "Average loss (last 100 batches): 0.5161, lr: 4.23e-05\n",
      "Average loss (last 100 batches): 0.4462, lr: 4.20e-05\n",
      "Average loss (last 100 batches): 0.3829, lr: 4.18e-05\n",
      "Average loss (last 100 batches): 0.4730, lr: 4.15e-05\n",
      "Average loss (last 100 batches): 0.4640, lr: 4.12e-05\n",
      "Average loss (last 100 batches): 0.3943, lr: 4.10e-05\n",
      "Average loss (last 100 batches): 0.6369, lr: 4.08e-05\n",
      "Average loss (last 100 batches): 0.4985, lr: 4.05e-05\n",
      "Average loss (last 100 batches): 0.5552, lr: 4.03e-05\n",
      "Average loss (last 100 batches): 0.4085, lr: 4.00e-05\n",
      "Average loss (last 100 batches): 0.5318, lr: 3.98e-05\n",
      "Average loss (last 100 batches): 0.3969, lr: 3.95e-05\n",
      "Average loss (last 100 batches): 0.4306, lr: 3.92e-05\n",
      "Average loss (last 100 batches): 0.4055, lr: 3.90e-05\n",
      "Average loss (last 100 batches): 0.4041, lr: 3.87e-05\n",
      "Average loss (last 100 batches): 0.6863, lr: 3.85e-05\n",
      "Average loss (last 100 batches): 0.5384, lr: 3.83e-05\n",
      "Average loss (last 100 batches): 0.4175, lr: 3.80e-05\n",
      "Average loss (last 100 batches): 0.4945, lr: 3.78e-05\n",
      "Average loss (last 100 batches): 0.3835, lr: 3.75e-05\n",
      "Average loss (last 100 batches): 0.3819, lr: 3.72e-05\n",
      "Average loss (last 100 batches): 0.4191, lr: 3.70e-05\n",
      "Average loss (last 100 batches): 0.4243, lr: 3.67e-05\n",
      "Average loss (last 100 batches): 0.4422, lr: 3.65e-05\n",
      "Average loss (last 100 batches): 0.3890, lr: 3.63e-05\n",
      "Average loss (last 100 batches): 0.4661, lr: 3.60e-05\n",
      "Average loss (last 100 batches): 0.4051, lr: 3.57e-05\n",
      "Average loss (last 100 batches): 0.6235, lr: 3.55e-05\n",
      "Average loss (last 100 batches): 0.3825, lr: 3.52e-05\n",
      "Average loss (last 100 batches): 0.4354, lr: 3.50e-05\n",
      "Average loss (last 100 batches): 0.5330, lr: 3.48e-05\n",
      "Average loss (last 100 batches): 0.6880, lr: 3.45e-05\n",
      "Average loss (last 100 batches): 0.4524, lr: 3.43e-05\n",
      "Average loss (last 100 batches): 0.3872, lr: 3.40e-05\n",
      "Average loss (last 100 batches): 0.4517, lr: 3.38e-05\n",
      "Average loss (last 100 batches): 0.6176, lr: 3.35e-05\n",
      "Average loss (last 100 batches): 0.5251, lr: 3.33e-05\n",
      "Average loss (last 100 batches): 0.5643, lr: 3.30e-05\n",
      "Average loss (last 100 batches): 0.6274, lr: 3.28e-05\n",
      "Average loss (last 100 batches): 0.4327, lr: 3.25e-05\n",
      "Average loss (last 100 batches): 0.4223, lr: 3.23e-05\n",
      "Average loss (last 100 batches): 0.4083, lr: 3.20e-05\n",
      "Average loss (last 100 batches): 0.4505, lr: 3.17e-05\n",
      "Average loss (last 100 batches): 0.4870, lr: 3.15e-05\n",
      "Average loss (last 100 batches): 0.4955, lr: 3.13e-05\n",
      "Average loss (last 100 batches): 0.5130, lr: 3.10e-05\n",
      "Average loss (last 100 batches): 0.3852, lr: 3.08e-05\n",
      "Average loss (last 100 batches): 0.4023, lr: 3.05e-05\n",
      "Average loss (last 100 batches): 0.5023, lr: 3.03e-05\n",
      "Average loss (last 100 batches): 0.3968, lr: 3.00e-05\n",
      "Average loss (last 100 batches): 0.4794, lr: 2.97e-05\n",
      "Average loss (last 100 batches): 0.6652, lr: 2.95e-05\n",
      "Average loss (last 100 batches): 0.4385, lr: 2.93e-05\n",
      "Average loss (last 100 batches): 0.4306, lr: 2.90e-05\n",
      "Average loss (last 100 batches): 0.3629, lr: 2.88e-05\n",
      "Average loss (last 100 batches): 0.4478, lr: 2.85e-05\n",
      "Average loss (last 100 batches): 0.5332, lr: 2.83e-05\n",
      "Average loss (last 100 batches): 0.5047, lr: 2.80e-05\n",
      "Average loss (last 100 batches): 0.4480, lr: 2.78e-05\n",
      "Average loss (last 100 batches): 0.4347, lr: 2.75e-05\n",
      "Average loss (last 100 batches): 0.4643, lr: 2.73e-05\n",
      "Average loss (last 100 batches): 0.6530, lr: 2.70e-05\n",
      "Average loss (last 100 batches): 0.4639, lr: 2.67e-05\n",
      "Average loss (last 100 batches): 0.3899, lr: 2.65e-05\n",
      "Average loss (last 100 batches): 0.5447, lr: 2.63e-05\n",
      "Average loss (last 100 batches): 0.5005, lr: 2.60e-05\n",
      "Average loss (last 100 batches): 0.4499, lr: 2.57e-05\n",
      "Average loss (last 100 batches): 0.5783, lr: 2.55e-05\n",
      "Average loss (last 100 batches): 0.3732, lr: 2.53e-05\n",
      "Average loss (last 100 batches): 0.6032, lr: 2.50e-05\n",
      "Average loss (last 100 batches): 0.3642, lr: 2.48e-05\n",
      "Average loss (last 100 batches): 0.4496, lr: 2.45e-05\n",
      "Average loss (last 100 batches): 0.4140, lr: 2.42e-05\n",
      "Average loss (last 100 batches): 0.4222, lr: 2.40e-05\n",
      "Average loss (last 100 batches): 0.4271, lr: 2.38e-05\n",
      "Average loss (last 100 batches): 0.4196, lr: 2.35e-05\n",
      "Average loss (last 100 batches): 0.4005, lr: 2.32e-05\n",
      "Average loss (last 100 batches): 0.5065, lr: 2.30e-05\n",
      "Average loss (last 100 batches): 0.3754, lr: 2.28e-05\n",
      "Average loss (last 100 batches): 0.6121, lr: 2.25e-05\n",
      "Average loss (last 100 batches): 0.3655, lr: 2.22e-05\n",
      "Average loss (last 100 batches): 0.7432, lr: 2.20e-05\n",
      "Average loss (last 100 batches): 0.6441, lr: 2.18e-05\n",
      "Average loss (last 100 batches): 0.4901, lr: 2.15e-05\n",
      "Average loss (last 100 batches): 0.5021, lr: 2.13e-05\n",
      "Average loss (last 100 batches): 0.4050, lr: 2.10e-05\n",
      "Average loss (last 100 batches): 0.3993, lr: 2.08e-05\n",
      "Average loss (last 100 batches): 0.5323, lr: 2.05e-05\n",
      "Average loss (last 100 batches): 0.4676, lr: 2.03e-05\n",
      "Average loss (last 100 batches): 0.5550, lr: 2.00e-05\n",
      "Average loss (last 100 batches): 0.4236, lr: 1.97e-05\n",
      "Average loss (last 100 batches): 0.4088, lr: 1.95e-05\n",
      "Average loss (last 100 batches): 0.5678, lr: 1.93e-05\n",
      "Average loss (last 100 batches): 0.4211, lr: 1.90e-05\n",
      "Average loss (last 100 batches): 0.4614, lr: 1.87e-05\n",
      "Average loss (last 100 batches): 0.5120, lr: 1.85e-05\n",
      "Average loss (last 100 batches): 0.4613, lr: 1.82e-05\n",
      "Average loss (last 100 batches): 0.5294, lr: 1.80e-05\n",
      "Average loss (last 100 batches): 0.4018, lr: 1.77e-05\n",
      "Average loss (last 100 batches): 0.5486, lr: 1.75e-05\n",
      "Average loss (last 100 batches): 0.4014, lr: 1.73e-05\n",
      "Average loss (last 100 batches): 0.4282, lr: 1.70e-05\n",
      "Average loss (last 100 batches): 0.4436, lr: 1.68e-05\n",
      "Average loss (last 100 batches): 0.3823, lr: 1.65e-05\n",
      "Average loss (last 100 batches): 0.4476, lr: 1.63e-05\n",
      "Average loss (last 100 batches): 0.3835, lr: 1.60e-05\n",
      "Average loss (last 100 batches): 0.4795, lr: 1.57e-05\n",
      "Average loss (last 100 batches): 0.3756, lr: 1.55e-05\n",
      "Average loss (last 100 batches): 0.7852, lr: 1.52e-05\n",
      "Average loss (last 100 batches): 0.4608, lr: 1.50e-05\n",
      "Average loss (last 100 batches): 0.7113, lr: 1.47e-05\n",
      "Average loss (last 100 batches): 0.7126, lr: 1.45e-05\n",
      "Average loss (last 100 batches): 0.4714, lr: 1.43e-05\n",
      "Average loss (last 100 batches): 0.4085, lr: 1.40e-05\n",
      "Average loss (last 100 batches): 0.4211, lr: 1.38e-05\n",
      "Average loss (last 100 batches): 0.5561, lr: 1.35e-05\n",
      "Average loss (last 100 batches): 0.5497, lr: 1.33e-05\n",
      "Average loss (last 100 batches): 0.4170, lr: 1.30e-05\n",
      "Average loss (last 100 batches): 0.5418, lr: 1.27e-05\n",
      "Average loss (last 100 batches): 0.3893, lr: 1.25e-05\n",
      "Average loss (last 100 batches): 0.3717, lr: 1.23e-05\n",
      "Average loss (last 100 batches): 0.7184, lr: 1.20e-05\n",
      "Average loss (last 100 batches): 0.4727, lr: 1.18e-05\n",
      "Average loss (last 100 batches): 0.5730, lr: 1.15e-05\n",
      "Average loss (last 100 batches): 0.5846, lr: 1.12e-05\n",
      "Average loss (last 100 batches): 0.4488, lr: 1.10e-05\n",
      "Average loss (last 100 batches): 0.5682, lr: 1.07e-05\n",
      "Average loss (last 100 batches): 0.3828, lr: 1.05e-05\n",
      "Average loss (last 100 batches): 0.3972, lr: 1.03e-05\n",
      "Average loss (last 100 batches): 0.3826, lr: 1.00e-05\n",
      "Average loss (last 100 batches): 0.4069, lr: 9.75e-06\n",
      "Average loss (last 100 batches): 0.4104, lr: 9.50e-06\n",
      "Average loss (last 100 batches): 0.4611, lr: 9.25e-06\n",
      "Average loss (last 100 batches): 0.4233, lr: 9.00e-06\n",
      "Average loss (last 100 batches): 0.5091, lr: 8.75e-06\n",
      "Average loss (last 100 batches): 0.6793, lr: 8.50e-06\n",
      "Average loss (last 100 batches): 0.3640, lr: 8.25e-06\n",
      "Average loss (last 100 batches): 0.3862, lr: 8.00e-06\n",
      "Average loss (last 100 batches): 0.4462, lr: 7.75e-06\n",
      "Average loss (last 100 batches): 0.3641, lr: 7.50e-06\n",
      "Average loss (last 100 batches): 0.4463, lr: 7.25e-06\n",
      "Average loss (last 100 batches): 0.4068, lr: 7.00e-06\n",
      "Average loss (last 100 batches): 0.4393, lr: 6.75e-06\n",
      "Average loss (last 100 batches): 0.4681, lr: 6.50e-06\n",
      "Average loss (last 100 batches): 0.4931, lr: 6.25e-06\n",
      "Average loss (last 100 batches): 0.4727, lr: 6.00e-06\n",
      "Average loss (last 100 batches): 0.4026, lr: 5.75e-06\n",
      "Average loss (last 100 batches): 0.5417, lr: 5.50e-06\n",
      "Average loss (last 100 batches): 0.4240, lr: 5.25e-06\n",
      "Average loss (last 100 batches): 0.3637, lr: 5.00e-06\n",
      "Average loss (last 100 batches): 0.6404, lr: 4.75e-06\n",
      "Average loss (last 100 batches): 0.5517, lr: 4.50e-06\n",
      "Average loss (last 100 batches): 0.4657, lr: 4.25e-06\n",
      "Average loss (last 100 batches): 0.4085, lr: 4.00e-06\n",
      "Average loss (last 100 batches): 0.5216, lr: 3.75e-06\n",
      "Average loss (last 100 batches): 0.4519, lr: 3.50e-06\n",
      "Average loss (last 100 batches): 0.5813, lr: 3.25e-06\n",
      "Average loss (last 100 batches): 0.6329, lr: 3.00e-06\n",
      "Average loss (last 100 batches): 0.4161, lr: 2.75e-06\n",
      "Average loss (last 100 batches): 0.4638, lr: 2.50e-06\n",
      "Average loss (last 100 batches): 0.3772, lr: 2.25e-06\n",
      "Average loss (last 100 batches): 0.4057, lr: 2.00e-06\n",
      "Average loss (last 100 batches): 0.3725, lr: 1.75e-06\n",
      "Average loss (last 100 batches): 0.3804, lr: 1.50e-06\n",
      "Average loss (last 100 batches): 0.4348, lr: 1.25e-06\n",
      "Average loss (last 100 batches): 0.4058, lr: 1.00e-06\n",
      "Average loss (last 100 batches): 0.4335, lr: 7.50e-07\n",
      "Average loss (last 100 batches): 0.3894, lr: 5.00e-07\n",
      "Average loss (last 100 batches): 0.6545, lr: 2.50e-07\n",
      "Average loss (last 100 batches): 0.4371, lr: 0.00e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c000be9772774f2b812a5a4cba590b09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Train Loss: 0.4741 | Test Loss: 46506442880304.2188\n",
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T10:54:55.757943Z",
     "start_time": "2025-01-18T10:54:55.754673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "def infer(model, dataset, device, column: str = \"CNA-2020-PIB\"):\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=econ_collate_fn)\n",
    "    table_names = list(dataset.table_names)\n",
    "    data = next(iter(dataloader))\n",
    "    for tn in data[\"full_data\"]:\n",
    "        data[\"full_data\"][tn] = data[\"full_data\"][tn].to(device)\n",
    "    data[\"mask\"] = data[\"mask\"].to(device)\n",
    "    data[\"padding_mask\"] = data[\"padding_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data)\n",
    "\n",
    "    targets = {}\n",
    "    valid_masks = {}\n",
    "    losses = []\n",
    "    padding_mask = data[\"padding_mask\"][:, :, 0].unsqueeze(-1)\n",
    "    for tn in table_names:\n",
    "        if tn != column:\n",
    "            continue\n",
    "\n",
    "        pred = outputs[tn]\n",
    "        tgt = data[\"full_data\"][tn][:, :, 0::3]\n",
    "        targets[tn] = tgt\n",
    "        expected_missing_mask = data[\"full_data\"][tn][:, :, 1::3] == 1.0\n",
    "        true_missing_mask = data[\"full_data\"][tn][:, :, 2::3] == 1.0\n",
    "        valid_mask = ~(expected_missing_mask | true_missing_mask | padding_mask)\n",
    "        valid_masks[tn] = valid_mask\n",
    "        losses.append(masked_mse_loss(pred, tgt, valid_mask))\n",
    "\n",
    "    loss_val = torch.stack(losses).mean().item()\n",
    "    print(\"Computed loss:\", loss_val)\n",
    "    return outputs, targets, valid_masks"
   ],
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T11:03:08.088888Z",
     "start_time": "2025-01-18T11:03:07.767068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "test_dataset = create_dataset(table_data_dict, meta_data_dict, monthly_dates, train=False, min_window_length_year=2, max_window_length_year=4, number_of_samples=100, inference_mode=True)\n",
    "outputs, targets, valid_masks = infer(model, test_dataset, device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed loss: 68.79239654541016\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T10:55:24.125281Z",
     "start_time": "2025-01-18T10:55:24.122628Z"
    }
   },
   "cell_type": "code",
   "source": "targets[\"CNA-2020-PIB\"][0, 12, :]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.0836,  1.8250, -1.6541,  2.8923,  2.8842,  0.7365,  0.3575, -1.1170,\n",
       "         1.6394,  0.8702,  0.5023,  1.0544, -1.6651,  2.7071, -4.1691, -3.3951,\n",
       "        -3.9235, -3.3062, -4.0105, -1.4309,  3.0046], device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T10:55:13.507775Z",
     "start_time": "2025-01-18T10:55:13.505420Z"
    }
   },
   "cell_type": "code",
   "source": "valid_masks[\"CNA-2020-PIB\"][0, :, :].cpu().numpy()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True],\n",
       "       [False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T10:55:30.313596Z",
     "start_time": "2025-01-18T10:55:30.310675Z"
    }
   },
   "cell_type": "code",
   "source": "outputs[\"CNA-2020-PIB\"][0, 12, :]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2565,  3.4274, -1.9030,  1.6195,  2.3284, -0.3057, -2.3308, -1.3956,\n",
       "         1.1599,  0.6699,  0.4282,  0.2531,  0.4027,  1.7227, -4.4886, -3.8208,\n",
       "        -4.2485, -3.7883, -4.3450,  0.1779,  0.6506], device='cuda:0')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-18T10:29:27.267730Z",
     "start_time": "2025-01-18T10:29:27.236878Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"model_t.pt\")",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First profiling with N then L"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T13:07:12.296981Z",
     "start_time": "2025-01-17T13:06:44.412328Z"
    }
   },
   "cell_type": "code",
   "source": "print(prof.key_averages().table(sort_by=\"self_cpu_time_total\", row_limit=10))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               backward        25.48%        1.151s        27.41%        1.238s      95.265ms       0.000us         0.00%      10.298ms     792.166us       1.23 Kb        -832 b      -9.40 Gb      -9.43 Gb            13  \n",
      "                                  cudaStreamSynchronize         8.13%     367.582ms         8.13%     367.582ms      11.243us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b         32695  \n",
      "                                             aten::view         6.50%     293.854ms         6.50%     293.854ms      18.679us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b         15732  \n",
      "                                                aten::t         5.46%     246.865ms         5.76%     260.251ms      16.734us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b         15552  \n",
      "                                       cudaLaunchKernel         4.19%     189.534ms         4.19%     189.534ms       1.778us       0.000us         0.00%       0.000us       0.000us           0 b           0 b     -36.50 Kb     -36.50 Kb        106597  \n",
      "                                        cudaMemcpyAsync         4.14%     187.019ms         4.14%     187.019ms       5.186us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b         36065  \n",
      "                                            aten::addmm         3.92%     177.165ms         4.14%     186.877ms      79.454us      26.281ms         4.45%      26.281ms      11.174us           0 b           0 b       1.56 Gb       1.56 Gb          2352  \n",
      "                                              aten::any         2.81%     126.909ms         4.31%     194.611ms       6.425us     101.225ms        17.15%     103.130ms       3.405us           0 b           0 b      14.79 Mb      14.82 Mb         30288  \n",
      "                                               aten::mm         2.58%     116.559ms         3.06%     138.229ms      20.736us      51.865ms         8.79%      51.865ms       7.781us           0 b           0 b       4.29 Gb       4.29 Gb          6666  \n",
      "                                     aten::_unsafe_view         2.05%      92.654ms         2.05%      92.654ms      48.561us       0.000us         0.00%       0.000us       0.000us           0 b           0 b           0 b           0 b          1908  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.519s\n",
      "Self CUDA time total: 590.247ms\n",
      "\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-17T14:25:23.623930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# With compile\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=30))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T19:07:06.417576Z",
     "start_time": "2025-01-10T19:07:00.249108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "key = os.getenv(\"NYT_KEY\")\n",
    "\n",
    "result = requests.request(\"GET\", f\"https://api.nytimes.com/svc/archive/v1/1970/1.json?api-key={key}\")"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T19:23:41.437320Z",
     "start_time": "2025-01-10T19:23:41.307374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(result.json()['response']['docs'][10])\n",
    "for d in result.json()['response']['docs'][:500]:\n",
    "    if 'Front Page 2 -- No Title' in d['headline']['main']:\n",
    "        print(d)\n",
    "        break\n",
    "\n",
    "filtered_articles = [d for d in result.json()['response']['docs'] if 'print_page' in d and int(d['print_page']) < 3]\n",
    "print(len(filtered_articles))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abstract': \"Prosecution of charges involving ousted Water Supply, Gas and Electricity Dept Comr Marcus continues; M Kaufman indicted for '68 perjury concerning attempt to bribe City Planning Comm member to delay bldg application by competitor S Sommer; is charged with denying bribe in testimony before grand jury probing incident and role of Kaufman, Marcus, informer H Itkin, real estate operator R Elyachar 'and others'; Itkin has testified that city official shared $10,000 payoff with him and Marcus; Elyachar pleaded guilty to perjury last Sept, is reptd cooperating with probe; Kaufman pleads not guilty\", 'web_url': 'https://www.nytimes.com/1970/01/01/archives/builder-is-accused-of-perjury-in-cityplanning-bribery-case.html', 'snippet': \"Prosecution of charges involving ousted Water Supply, Gas and Electricity Dept Comr Marcus continues; M Kaufman indicted for '68 perjury concerning attempt to bribe City Planning Comm member to delay bldg application by competitor S Sommer; is cha...\", 'lead_paragraph': 'Melvyn Kaufman, a builder and owner of Manhattan office buildings, was arrested yester day on charges of first‐degree perjury arising from an alleged effort to bribe a member of the City Planning Commission. ', 'print_page': '14', 'source': 'The New York Times', 'multimedia': [], 'headline': {'main': 'Builder Is Accused of Perjury In City‐Planning Bribery Case', 'kicker': None, 'content_kicker': None, 'print_headline': 'Builder Is Accused of Perjury In City‐Planning Bribery Case', 'name': None, 'seo': None, 'sub': None}, 'keywords': [{'name': 'glocations', 'value': 'New York City', 'rank': 1, 'major': 'N'}, {'name': 'glocations', 'value': 'New York City', 'rank': 2, 'major': 'N'}, {'name': 'subject', 'value': 'OFFICE BUILDINGS AND OTHER COMMERCIAL PROPERTIES', 'rank': 3, 'major': 'N'}, {'name': 'subject', 'value': 'EMPLOYES AND OFFICIALS', 'rank': 4, 'major': 'N'}, {'name': 'subject', 'value': 'Ethics', 'rank': 5, 'major': 'N'}, {'name': 'subject', 'value': 'INFLUENCE AND CORRUPTION', 'rank': 6, 'major': 'N'}, {'name': 'subject', 'value': 'MARCUS CASE', 'rank': 7, 'major': 'N'}], 'pub_date': '1970-01-01T05:00:00+0000', 'document_type': 'article', 'news_desk': 'None', 'section_name': 'Archives', 'byline': {'original': 'By Morris Kaplan', 'person': [{'firstname': 'Morris', 'middlename': None, 'lastname': 'Kaplan', 'qualifier': None, 'title': None, 'role': 'reported', 'organization': '', 'rank': 1}], 'organization': None}, 'type_of_material': 'Archives', '_id': 'nyt://article/0ac9126a-9f09-5cf1-b633-67e6ceb94206', 'word_count': 571, 'uri': 'nyt://article/0ac9126a-9f09-5cf1-b633-67e6ceb94206'}\n",
      "508\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T17:51:44.401043Z",
     "start_time": "2025-01-10T17:51:44.364560Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(result.json()['response']['docs']))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6560\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T18:14:30.576083Z",
     "start_time": "2025-01-10T18:14:26.780884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)',\n",
    "        'Referer': 'https://www.google.com/'\n",
    "    }\n",
    "response = requests.get(\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\", headers=headers)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T18:14:30.586663Z",
     "start_time": "2025-01-10T18:14:30.582358Z"
    }
   },
   "cell_type": "code",
   "source": "print(response.text)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\" class=\" story nytapp-vi-article \"  xmlns:og=\"http://opengraphprotocol.org/schema/\">\n",
      "  <head>\n",
      "    \n",
      "    \n",
      "    <meta charset=\"utf-8\" />\n",
      "    <title data-rh=\"true\">Israelis Decide to Continue Talks With Egypt on Treaty - The New York Times</title>\n",
      "    <meta data-rh=\"true\" name=\"robots\" content=\"noarchive, max-image-preview:large\"/><meta data-rh=\"true\" name=\"description\" content=\"Begins says Israel will continue talks with Egypt; illus (M)\"/><meta data-rh=\"true\" property=\"twitter:url\" content=\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><meta data-rh=\"true\" property=\"twitter:title\" content=\"Israelis Decide to Continue Talks With Egypt on Treaty (Published 1979)\"/><meta data-rh=\"true\" property=\"twitter:description\" content=\"Begins says Israel will continue talks with Egypt; illus (M)\"/><meta data-rh=\"true\" property=\"twitter:image\" content=\"https://static01.nyt.com/newsgraphics/images/icons/defaultCrop.png?year=1979\"/><meta data-rh=\"true\" property=\"twitter:image:alt\" content=\"\"/><meta data-rh=\"true\" property=\"twitter:card\" content=\"summary_large_image\"/><meta data-rh=\"true\" property=\"og:url\" content=\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><meta data-rh=\"true\" property=\"og:type\" content=\"article\"/><meta data-rh=\"true\" property=\"og:title\" content=\"Israelis Decide to Continue Talks With Egypt on Treaty (Published 1979)\"/><meta data-rh=\"true\" property=\"og:image\" content=\"https://static01.nyt.com/newsgraphics/images/icons/defaultPromoCrop.png?year=1979\"/><meta data-rh=\"true\" property=\"og:image:alt\" content=\"\"/><meta data-rh=\"true\" property=\"og:description\" content=\"Begins says Israel will continue talks with Egypt; illus (M)\"/> <link data-rh=\"true\" rel=\"canonical\" href=\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><link data-rh=\"true\" rel=\"alternate\" href=\"nyt://article/024d3615-c3f3-5dbe-9572-92f1c4b16f45\"/><link data-rh=\"true\" rel=\"alternate\" type=\"application/json+oembed\" href=\"https://www.nytimes.com/svc/oembed/json/?url=https%3A%2F%2Fwww.nytimes.com%2F1979%2F01%2F01%2Farchives%2Fisraelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\" title=\"Israelis Decide to Continue Talks With Egypt on Treaty\"/> <script data-rh=\"true\" type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"NewsArticle\",\"@id\":\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"description\":\"Begins says Israel will continue talks with Egypt; illus (M)\",\"image\":[{\"@context\":\"https://schema.org\",\"@type\":\"ImageObject\",\"url\":\"https://static01.nyt.com/vi-assets/images/share/1200x675_nameplate.png\",\"height\":675,\"width\":1200,\"contentUrl\":\"https://static01.nyt.com/vi-assets/images/share/1200x675_nameplate.png\",\"creditText\":\"The New York Times\"},{\"@context\":\"https://schema.org\",\"@type\":\"ImageObject\",\"url\":\"https://static01.nyt.com/vi-assets/images/share/1200x900_t.png\",\"height\":900,\"width\":1200,\"contentUrl\":\"https://static01.nyt.com/vi-assets/images/share/1200x900_t.png\",\"creditText\":\"The New York Times\"},{\"@context\":\"https://schema.org\",\"@type\":\"ImageObject\",\"url\":\"https://static01.nyt.com/vi-assets/images/share/1200x1200_t.png\",\"height\":1200,\"width\":1200,\"contentUrl\":\"https://static01.nyt.com/vi-assets/images/share/1200x1200_t.png\",\"creditText\":\"The New York Times\"}],\"mainEntityOfPage\":\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"url\":\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"author\":[{\"@context\":\"https://schema.org\",\"@type\":\"Person\",\"url\":\"\",\"name\":\"Jonathan Kandell\"}],\"dateModified\":\"1979-01-01T05:00:00.000Z\",\"datePublished\":\"1979-01-01T05:00:00.000Z\",\"headline\":\"Israelis Decide to Continue Talks With Egypt on Treaty\",\"publisher\":{\"@id\":\"https://www.nytimes.com/#publisher\",\"name\":\"The New York Times\"},\"hasPart\":{\"@type\":\"WebPageElement\",\"isAccessibleForFree\":false,\"cssSelector\":\".meteredContent\"},\"isPartOf\":{\"@type\":[\"CreativeWork\",\"Product\"],\"name\":\"The New York Times\",\"productID\":\"nytimes.com:basic\"},\"copyrightHolder\":{\"@id\":\"https://www.nytimes.com/#publisher\",\"name\":\"The New York Times\"},\"sourceOrganization\":{\"@id\":\"https://www.nytimes.com/#publisher\",\"name\":\"The New York Times\"},\"copyrightYear\":2025,\"isAccessibleForFree\":false,\"articleSection\":\"Archives\",\"keywords\":[\"Middle East\",\"ISRAELI-ARAB CONFLICT\"]}</script><script data-rh=\"true\" type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"NewsMediaOrganization\",\"name\":\"The New York Times\",\"logo\":{\"@context\":\"https://schema.org\",\"@type\":\"ImageObject\",\"url\":\"https://static01.nyt.com/images/icons/t_logo_291_black.png\",\"height\":291,\"width\":291,\"contentUrl\":\"https://static01.nyt.com/images/icons/t_logo_291_black.png\",\"creditText\":\"The New York Times\"},\"url\":\"https://www.nytimes.com/\",\"@id\":\"https://www.nytimes.com/#publisher\",\"publishingPrinciples\":\"https://www.nytimes.com/editorial-standards/ethical-journalism.html\",\"diversityPolicy\":\"https://www.nytco.com/company/diversity-and-inclusion/\",\"ethicsPolicy\":\"https://www.nytco.com/company/standards-ethics/\",\"masthead\":\"https://www.nytimes.com/interactive/2023/01/28/admin/the-new-york-times-masthead.html\",\"foundingDate\":\"1851-09-18\",\"sameAs\":\"https://en.wikipedia.org/wiki/The_New_York_Times\"}</script>\n",
      "    <meta data-rh=\"true\" property=\"article:published_time\" content=\"1979-01-01T05:00:00.000Z\"/><meta data-rh=\"true\" property=\"article:modified_time\" content=\"1979-01-01T05:00:00.000Z\"/><meta data-rh=\"true\" http-equiv=\"Content-Language\" content=\"en\"/><meta data-rh=\"true\" name=\"articleid\" content=\"1979010100110993241\"/><meta data-rh=\"true\" name=\"nyt_uri\" content=\"nyt://article/024d3615-c3f3-5dbe-9572-92f1c4b16f45\"/><meta data-rh=\"true\" name=\"pubp_event_id\" content=\"pubp://event/d897512268424ffda1a5bb6a28fa53e9\"/><meta data-rh=\"true\" name=\"image\" content=\"https://static01.nyt.com/newsgraphics/images/icons/defaultPromoCrop.png?year=1979\"/><meta data-rh=\"true\" name=\"byl\" content=\"By Jonathan Kandell;Special to The New York Times\"/><meta data-rh=\"true\" name=\"news_keywords\" content=\"Middle East\"/><meta data-rh=\"true\" name=\"pdate\" content=\"19790101\"/><meta data-rh=\"true\" property=\"article:section\" content=\"Archives\"/><meta data-rh=\"true\" property=\"article:tag\" content=\"Middle East\"/><meta data-rh=\"true\" property=\"article:tag\" content=\"ISRAELI-ARAB CONFLICT\"/><meta data-rh=\"true\" property=\"article:opinion\" content=\"false\"/><meta data-rh=\"true\" property=\"article:content_tier\" content=\"metered\"/><meta data-rh=\"true\" name=\"CG\" content=\"archives\"/><meta data-rh=\"true\" name=\"SCG\" content=\"\"/><meta data-rh=\"true\" name=\"CN\" content=\"\"/><meta data-rh=\"true\" name=\"CT\" content=\"\"/><meta data-rh=\"true\" name=\"PT\" content=\"article\"/><meta data-rh=\"true\" name=\"PST\" content=\"Archives\"/><meta data-rh=\"true\" name=\"url\" content=\"https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><meta data-rh=\"true\" name=\"msapplication-starturl\" content=\"https://www.nytimes.com\"/><meta data-rh=\"true\" property=\"al:android:url\" content=\"nyt://article/024d3615-c3f3-5dbe-9572-92f1c4b16f45\"/><meta data-rh=\"true\" property=\"al:android:package\" content=\"com.nytimes.android\"/><meta data-rh=\"true\" property=\"al:android:app_name\" content=\"NYTimes\"/><meta data-rh=\"true\" name=\"twitter:app:name:googleplay\" content=\"NYTimes\"/><meta data-rh=\"true\" name=\"twitter:app:id:googleplay\" content=\"com.nytimes.android\"/><meta data-rh=\"true\" name=\"twitter:app:url:googleplay\" content=\"nyt://article/024d3615-c3f3-5dbe-9572-92f1c4b16f45\"/><meta data-rh=\"true\" property=\"al:iphone:url\" content=\"nytimes://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><meta data-rh=\"true\" property=\"al:iphone:app_store_id\" content=\"284862083\"/><meta data-rh=\"true\" property=\"al:iphone:app_name\" content=\"NYTimes\"/><meta data-rh=\"true\" property=\"al:ipad:url\" content=\"nytimes://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"/><meta data-rh=\"true\" property=\"al:ipad:app_store_id\" content=\"357066198\"/><meta data-rh=\"true\" property=\"al:ipad:app_name\" content=\"NYTimes\"/>\n",
      "    \n",
      "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "<meta property=\"fb:app_id\" content=\"9869919170\" />\n",
      "<meta name=\"twitter:site\" content=\"@nytimes\" />\n",
      "<meta name=\"slack-app-id\" content=\"A0121HXPPTQ\" />\n",
      "    <script>(function Kn(e){if(new URL(window.location).searchParams.get(\"sentryOverride\")||Math.floor(100*Math.random())<=e){var t=['<script src=\"https://js.sentry-cdn.com/7bc8bccf5c254286a99b11c68f6bf4ce.min.js\" crossorigin=\"anonymous\">',\"<\",\"/script>\"].join(\"\");document.write(t)}})(1);</script><script>(function $n(e){var t=e.release,n=e.env,i=e.routeName,a=window.vi&&window.vi.webviewEnvironment||{},o=a.isPreloaded,r=void 0!==o&&o,l=\"IOS\"===a.deviceType;if(window.Sentry){var s=function(){window.Sentry.init({maxBreadcrumbs:c,release:t,environment:n,allowUrls:u,ignoreErrors:d,beforeSend:function(e,t){var n=t.originalException;return n&&n.stack&&n.stack.includes(\"datadog-rum\")?null:e},initialScope:function(e){e.setTags({\"nyt.route\":i});var t=/nyt-a=(.*?)(;|$)/.exec(document.cookie);null!==t&&e.setUser({id:t[1]});try{if(r){var n,a,o=window.asset||{},s=o.eventId,c=void 0===s?\"\":s,d=o.uri,u=void 0===d?\"\":d,f=o.url,p=void 0===f?\"\":f,m=o.sourceType,g=void 0===m?\"\":m,h=o.sourceId,v=void 0===h?\"\":h;c&&e.setTag(\"eventId\",c),u&&e.setTag(\"uri\",u),p&&e.setTag(\"url\",p),g&&e.setTag(\"sourceType\",g),v&&e.setTag(\"sourceId\",v),e.setExtra(\"visibilityState\",document.visibilityState),null!==(n=window)&&void 0!==n&&null!==(a=n.performance)&&void 0!==a&&a.timeOrigin&&e.setExtra(\"timeOrigin\",window.performance.timeOrigin),e.setTag(\"type\",\"preloaded-webview\")}else e.setTag(\"type\",\"browser\");var b=function(){var t=window.config||{},n=t.AppVersion,i=void 0===n?\"\":n,a=t.ConnectionStatus,o=void 0===a?3:a,r=t.LoggedIn,l=void 0!==r&&r,s=t.Subscriber,c=void 0!==s&&s;null==e||e.setTag(\"AppVersion\",i),null==e||e.setTag(\"ConnectionStatus\",o),null==e||e.setTag(\"LoggedIn\",l),null==e||e.setTag(\"Subscriber\",c)};l?window.addEventListener(\"initWebview:ios\",b):b()}catch(e){console.error(e)}return e},replaysSessionSampleRate:0,replaysOnErrorSampleRate:.01,integrations:[window.Sentry.browserTracingIntegration({enableInp:!0,instrumentNavigation:!1,instrumentPageLoad:!1})]});var e=window.Sentry.getClient(),a={};a[window.Sentry.SEMANTIC_ATTRIBUTE_SENTRY_SOURCE]=\"url\",window.Sentry.startBrowserTracingPageLoadSpan(e,{name:i,attributes:a})},c=70,d=[\"2mdn\",\"ads-us\",\"amazon-adsystem\",\"amp4ads\",\"ampproject\",\"bk_addPageCtx\",\"boomerang\",\"BOOMR\",\"cb is not a function\",\"chartbeat\",\"google_tag_manager\",\"gsi\",\"gtm\",\"prebid\",\"pubads\",\"scorecardresearch\",\"setConfig is not a function\",\"webkitExitFullScreen\",\"yimg\",\"reading 'campaign'\",\"Object.fromEntries is not a function\"];r&&(d=d.concat([\"Failed to fetch\",\"Load failed\",\"Something went wrong\",\"Unexpected EOF\",\"The request is not allowed by the user agent\",\"scrollIntoView\",\"No weather-bot homepage data available\",\"UnhandledRejection: Non-Error promise rejection captured with value: false\",\"VHS is currently showing this error message on-screen.\",\"useMessageSelection\",\"messageComponentLibrary\"]));var u=[/^https?:\\/\\/(vi-pr-.*|www|vi|local|alpha|alpha-preview)\\.(stg\\.|dev\\.)?(nytimes\\.com|nyt\\.net)/];window.Sentry.onLoad(s),window.__isUnitTestEnv&&(window.__testSentryOnload=s)}})({\"release\":\"74e0f0702bdea699e5b8f969d4a04ef588eead6b\",\"env\":\"prd\",\"routeName\":\"vi-story\",\"allowUrls\":[{}]});</script>\n",
      "    \n",
      "    <script>\n",
      "      (function Zn(){var e,t,n,i,a;e=window,t=document,n=\"script\",i=\"https://www.datadoghq-browser-agent.com/us1/v5/datadog-rum.js\",e=e[a=\"DD_RUM\"]=e[a]||{q:[],onReady:function(t){e.q.push(t)}},(a=t.createElement(n)).async=1,a.src=i,(i=t.getElementsByTagName(n)[0]).parentNode.insertBefore(a,i)})();\n",
      "      (function Qn(e){var t=e.service,n=e.env,i=e.version,a=e.sessionSampleRate,o=e.deploymentId,r=e.routeName,l=e.tenant;if(window.DD_RUM){var s=function(){var e={clientToken:\"pube5bf68ea68edb54c35106f34e32ff07c\",applicationId:\"7d0602a0-8ef8-4d39-985b-c3188887e5b3\",site:\"datadoghq.com\",service:\"\".concat(t,\"-client\"),env:n,version:i,sessionSampleRate:parseInt(a,10),sessionReplaySampleRate:v,trackUserInteractions:!0,trackResources:!0,trackLongTasks:!0,trackViewsManually:!0,defaultPrivacyLevel:\"mask-user-input\",allowedTracingUrls:m,traceSampleRate:20,useCrossSiteSessionCookie:!0,useSecureSessionCookie:!0};u&&(e=Object.assign(e,h)),window.DD_RUM.init(e);var s={billing:{environment:n,deployment:{id:o}},dvsp:{tenant:l},route:{name:r},webview:p,preloaded:u};u&&(s=Object.assign(s,g)),window.DD_RUM.setGlobalContextProperty(\"nyt\",s),window.DD_RUM.startView({name:r});var c=/nyt-a=(.*?)(;|$)/.exec(document.cookie);if(null!==c&&window.DD_RUM.setUser({id:c[1]}),u){var d=(window.asset||{}).url,f=void 0===d?\"\":d;window.DD_RUM.setGlobalContextProperty(\"url\",f);var b=window.getNativeBridgeCookie(\"nyt-a\");b&&window.DD_RUM.setUser({id:b})}},c=window.vi&&window.vi.webviewEnvironment||{},d=c.isPreloaded,u=void 0!==d&&d,f=c.isInWebview,p=void 0!==f&&f,m=[/https:\\/\\/samizdat-graphql.*\\.nytimes\\.com/],g={},h={},v=100;u&&(m=[/[https|http|nytresource]:\\/\\/.*\\.nytimes\\.com/,/[https|http|nytresource]:\\/\\/.*\\.nyt\\.com/],g={team:\"web-platforms\"},v=0,h={trackFrustrations:!0,allowFallbackToLocalStorage:!0}),window.DD_RUM.onReady(s),window.__isUnitTestEnv&&(window.__testDataDogOnReady=s)}})({\"service\":\"vi\",\"env\":\"prd\",\"version\":\"vi-newsreader@v6404-74e0f07\",\"sessionSampleRate\":\"1\",\"deploymentId\":\"aws-491988406224\",\"routeName\":\"vi-story\",\"tenant\":\"web-platforms\"});\n",
      "    </script>\n",
      "  \n",
      "\n",
      "    <link data-rh=\"true\" rel=\"shortcut icon\" href=\"/vi-assets/static-assets/favicon-d2483f10ef688e6f89e23806b9700298.ico\"/><link data-rh=\"true\" rel=\"apple-touch-icon\" href=\"/vi-assets/static-assets/apple-touch-icon-28865b72953380a40aa43318108876cb.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon-precomposed\" sizes=\"144×144\" href=\"/vi-assets/static-assets/ios-ipad-144x144-28865b72953380a40aa43318108876cb.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon-precomposed\" sizes=\"114×114\" href=\"/vi-assets/static-assets/ios-iphone-114x144-080e7ec6514fdc62bcbb7966d9b257d2.png\"/><link data-rh=\"true\" rel=\"apple-touch-icon-precomposed\" href=\"/vi-assets/static-assets/ios-default-homescreen-57x57-43808a4cd5333b648057a01624d84960.png\"/>\n",
      "    <link href=\"https://g1.nyt.com/fonts/css/web-fonts.a65411eeb1ab091c1b7eaa3047f86dabe8355f0e.css\" rel=\"stylesheet\" type=\"text/css\" crossorigin />\n",
      "    <link rel=\"stylesheet\" href=\"/vi-assets/static-assets/global-75f713f5ef71fb15f77ecbb55c1f03b7.css\" />\n",
      "    <style>[data-timezone] { display: none }</style>\n",
      "    <style data-lights-css=\"k008qs 1dv1kvn qebcue 1pd1msn kgn7zc 1hyfx7x 1jmk4jh 1e1s8k7 1qa4qp6 jq1cx6 79elbk vxcmzt 1baulvz 1eeh360 1yhvmgx 1atjma0 1qy6wq7 1nurhyi 93zicp 12fr9lp 18z7m18 ec8ke8 1hqnpie 10habuo rnl02l tvohiw b4nnp0 1n6z4y 777zgl rfqw0c 19vbshk l9onyx j3uhc5 1iruc8t sg7scw jxzr5i oylsik 1otr2jl 184m8ie qtw155 v0l3hm g4gku8 1rr4qq7 6xhk3s 1onhbft tj0ten ist4u3 1gprdgz 10t7hia e9w26l yk8vb4 z6qatp 1ea6cym 6td9kr 1o03u4n p6m5rf 1r7ky0e ew4tgv s99gbd 53u6y8 1ve50l5 p5jc4e udpjq9 iry6ay 4ejn01 1nq039c 1382yzd 1gus26i 1mweozg 14uxcda 6hi8ev 1s1pakw 1ly73wi 1vkm6nb rq4mmj ktho12 14fe1uy 233int 4anu6l at9mc1 sxwst7 1gqes1i 8qgvsz 1q2w90k 1bymuyk 7s20nv 1f7ibof 10698na ijmohz 1npft71 c5j6tx vfkorq 1bvtpon wqhysl yomkvi 4skfbu 1c5ewvl zd9juy 10d8k1f eap6fy 1vxca1d 1aeqhal 10i3hc jf7ug7 1a5mdf6 1ho5u4o t8x4fj a7htku 1cgskve ccw2r3 1e2jphy 1uc6ajg 11kk65x r25it4 17yegpq xt80pu 1si6tjw name 5j8bii duration delay timing-function\">@-webkit-keyframes animation-5j8bii{from{opacity:0;}to{opacity:1;}}@keyframes animation-5j8bii{from{opacity:0;}to{opacity:1;}}.css-k008qs{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}.css-1dv1kvn{border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;}.css-qebcue{display:none;font-size:10px;margin-left:auto;text-transform:uppercase;}.hasLinks .css-qebcue{display:block;min-height:10px;}@media (min-width:740px){return!e.theme.isIntlHomepage.hasLinks .css-qebcue function(e).hasLinks .css-qebcue function(e)!e.theme.homepage.hasLinks .css-qebcue function(e).hasLinks .css-qebcue function(e){margin:\"none\",position:\"absolute\",right:\"20px\";}}@media (min-width:1024px){.hasLinks .css-qebcue{display:none;min-height:0;}}.css-1pd1msn{display:inline-block;font-size:0.875rem;line-height:1.25rem;-webkit-transition:color 0.6s ease;transition:color 0.6s ease;color:#121212;}.css-1pd1msn:hover{color:#666;}.css-kgn7zc{border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px;border-radius:3px;cursor:pointer;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-transition:ease 0.6s;transition:ease 0.6s;white-space:nowrap;vertical-align:middle;background-color:transparent;color:#000;font-size:11px;line-height:11px;font-weight:700;-webkit-letter-spacing:0.02em;-moz-letter-spacing:0.02em;-ms-letter-spacing:0.02em;letter-spacing:0.02em;padding:11px 12px 8px;background:#fff;display:inline-block;left:44px;text-transform:uppercase;-webkit-transition:none;transition:none;z-index:5;}.css-kgn7zc:active,.css-kgn7zc:focus{-webkit-clip:auto;clip:auto;overflow:visible;width:auto;height:auto;}.css-kgn7zc::-moz-focus-inner{padding:0;border:0;}.css-kgn7zc:-moz-focusring{outline:1px dotted;}.css-kgn7zc:disabled,.css-kgn7zc.disabled{opacity:0.5;cursor:default;}.css-kgn7zc:active,.css-kgn7zc.active{background-color:#f7f7f7;}@media (min-width:740px){.css-kgn7zc:hover{background-color:#f7f7f7;}}.css-kgn7zc:focus{margin-top:3px;padding:8px 8px 6px;}@media (max-width:600px){.css-kgn7zc:focus{margin-top:12px;margin-left:9px;}}@media (min-width:1024px){.css-kgn7zc{left:112px;}}.css-1hyfx7x{display:none;}@media (min-width:1150px){.css-1jmk4jh{margin:0 auto;max-width:1200px;padding:0 3% 9px;}}.NYTApp .css-1jmk4jh{display:none;}@media print{.css-1jmk4jh{display:none;}}.css-1e1s8k7{font-size:11px;text-align:center;padding-bottom:25px;}@media (min-width:1024px){.css-1e1s8k7{padding:0 3% 9px;}}.css-1e1s8k7.dockVisible{padding-bottom:45px;}@media (min-width:1024px){.css-1e1s8k7.dockVisible{padding:0 3% 45px;}}@media (min-width:1150px){.css-1e1s8k7{margin:0 auto;max-width:1200px;}}.NYTApp .css-1e1s8k7{display:none;}@media print{.css-1e1s8k7{display:none;}}.css-1qa4qp6{border-top:1px solid #ebebeb;padding-top:9px;margin:0 0 35px;}.css-jq1cx6{color:#666;font-family:nyt-franklin,helvetica,arial,sans-serif;padding:10px 0;-webkit-text-decoration:none;text-decoration:none;white-space:nowrap;}.css-jq1cx6:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-79elbk{position:relative;}.css-vxcmzt{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;}.css-1baulvz{display:inline-block;}.css-1eeh360{height:auto;width:auto;border-radius:30px;}.css-1eeh360:focus{outline:none;box-shadow:0 0 4px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-1eeh360:focus{box-shadow:none;}.css-1eeh360:focus-visible{box-shadow:0 0 4px 1px rgb(0 95 204);}}.css-1yhvmgx{height:auto;width:auto;border:solid 1px var(--color-stroke-quaternary,#DFDFDF);background-color:var(--color-background-primary,#FFFFFF);border-radius:30px;font-size:0.75rem;font-family:nyt-franklin,helvetica,arial,sans-serif;text-transform:uppercase;}.css-1yhvmgx:hover{background-color:var(--color-background-tertiary,#EBEBEB);border:1px solid var(--color-background-tertiary,#EBEBEB);}.css-1yhvmgx .hiddenClass{display:none;}.css-1yhvmgx[aria-checked='true'] .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-checked='true'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-checked='false'] .saved-fill{fill:none;}.css-1yhvmgx[aria-checked='false'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-1yhvmgx[aria-busy='true']{cursor:default;background-color:var(--color-background-tertiary,#EBEBEB);}.css-1atjma0{padding:0;margin-left:0;margin-right:0;}@media (max-width:424px){.css-1atjma0{margin-left:-9px;margin-right:-20px;}}.css-1qy6wq7{color:#999;display:inline;margin-right:12px;width:100%;}.css-1qy6wq7 > a,.css-1qy6wq7 > button{-webkit-text-decoration:none;text-decoration:none;}.css-1qy6wq7 > a:focus,.css-1qy6wq7 > button:focus{display:inline-block;outline:none;box-shadow:0 0 2px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-1qy6wq7 > a:focus,.css-1qy6wq7 > button:focus{box-shadow:none;}.css-1qy6wq7 > a:focus-visible,.css-1qy6wq7 > button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);}}.css-1qy6wq7 > a:focus{border-radius:100%;}@media (max-width:424px){.css-1qy6wq7{margin-right:6px;}}.css-1qy6wq7:last-of-type{margin-right:0;}.css-1nurhyi{height:auto;width:auto;border-radius:100%;background-color:transparent;}.css-93zicp{display:none;}@media (min-width:375px){.css-93zicp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:16px;height:31px;}}@media (min-width:740px){.css-93zicp{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:16px;height:31px;}}@media (min-width:1024px){.css-93zicp{display:none;}}@media print{.css-93zicp{display:none;}}.css-12fr9lp{height:23px;margin-top:6px;}.css-18z7m18{display:none;}@media (min-width:1024px){.css-18z7m18{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-top:0;}}@media print{.css-18z7m18{display:block;}}.css-ec8ke8{display:none;}@media (min-width:375px){.css-ec8ke8{position:fixed;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;opacity:0;z-index:1;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;width:100%;height:32.063px;background:white;padding:5px 0;top:0;text-align:center;font-family:nyt-cheltenham,cheltenham-fallback-georgia,cheltenham-fallback-noto,georgia,'times new roman',times,serif;box-shadow:rgba(0,0,0,0.08) 0 0 5px 1px;border-bottom:1px solid #e2e2e2;}}@media print{.css-ec8ke8{position:relative;border:none;display:inline-block;opacity:1 !important;visibility:visible !important;}}@media (max-width:739px){.NYTApp .css-ec8ke8{display:none;}}.css-1hqnpie{margin-left:20px;margin-right:20px;max-width:1605px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;position:relative;width:100%;}@media (min-width:1360px){.css-1hqnpie{margin-left:20px;margin-right:20px;}}@media (min-width:1780px){.css-1hqnpie{margin-left:auto;margin-right:auto;}}@media print{.css-1hqnpie{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-10habuo{display:none;}@media (min-width:1024px){.css-10habuo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;max-width:1605px;overflow:hidden;position:absolute;width:50%;margin-left:calc((100% - 50%) / 2);}}@media (min-width:740px){.NYTApp .css-10habuo{width:90%;margin-left:calc((100% - 90%) / 2);}@media (min-width:1024px){.NYTApp .css-10habuo{width:63%;margin-left:calc((100% - 63%) / 2);}}}@media print{.css-10habuo{display:none;}}.css-rnl02l{font-family:nyt-cheltenham-small,georgia,'times new roman';font-weight:400;font-size:13px;-webkit-letter-spacing:0.015em;-moz-letter-spacing:0.015em;-ms-letter-spacing:0.015em;letter-spacing:0.015em;margin-top:10.5px;margin-bottom:10.5px;margin-right:auto;white-space:nowrap;text-overflow:ellipsis;}.css-tvohiw{margin-top:-1px;margin-bottom:auto;margin-left:auto;z-index:50;box-shadow:-14px 2px 7px -2px rgba(255,255,255,0.7);}.css-b4nnp0{margin-top:1px;}@media (min-width:1024px){.css-b4nnp0{margin-top:0;}}.css-1n6z4y{font-family:nyt-franklin,helvetica,arial,sans-serif;color:#ccc !important;border-left:1px solid #ccc;margin-left:10px;padding:10px;display:none;}@media print{.css-1n6z4y{display:inline-block;}}.css-777zgl{position:absolute;width:1px;height:1px;margin:-1px;padding:0;border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);overflow:hidden;text-align:center;}.css-777zgl:focus-visible{background-color:#fff;border-radius:3px;height:auto;width:auto;-webkit-clip:auto;clip:auto;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.6875rem;font-weight:700;left:50%;padding:8px 8px 6px;-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%);transform:translateX(-50%);top:5px;}.css-rfqw0c{text-align:center;height:100%;display:block;}.css-19vbshk{color:#ccc;display:none;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.5625rem;font-weight:300;-webkit-letter-spacing:0.05rem;-moz-letter-spacing:0.05rem;-ms-letter-spacing:0.05rem;letter-spacing:0.05rem;line-height:0.5625rem;margin-left:auto;text-align:center;text-transform:uppercase;}@media (min-width:600px){.css-19vbshk{display:inline-block;}}.css-19vbshk p{margin-bottom:auto;margin-right:7px;margin-top:auto;text-transform:none;}.css-l9onyx{color:#ccc;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.5625rem;font-weight:300;-webkit-letter-spacing:0.05rem;-moz-letter-spacing:0.05rem;-ms-letter-spacing:0.05rem;letter-spacing:0.05rem;line-height:0.5625rem;margin-bottom:9px;text-align:center;text-transform:uppercase;}.css-j3uhc5{width:calc(100% - 40px);max-width:600px;margin-left:20px;margin-right:20px;}@media (min-width:600px){.css-j3uhc5{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-j3uhc5{width:600px;}}@media (min-width:1440px){.css-j3uhc5{width:600px;max-width:600px;}}@media print{.css-j3uhc5{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1iruc8t{list-style:none;margin:0;padding:0;}.css-sg7scw{padding:0 20px;}.css-sg7scw::before{background-color:#fff;border-bottom:1px solid #e2e2e2;border-top:2px solid #e2e2e2;content:'';display:block;height:1px;margin-top:0;}@media (min-width:740px){.css-sg7scw{padding:0 3%;}}@media (min-width:1150px){.css-sg7scw{padding:0;}}.css-jxzr5i{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-flow:row;-ms-flex-flow:row;flex-flow:row;}.css-oylsik{display:block;height:44px;vertical-align:middle;width:184px;}.css-1otr2jl{margin:18px 0 0 auto;}.css-184m8ie{color:#567b95;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:11px;font-style:normal;font-weight:400;line-height:11px;-webkit-text-decoration:none;text-decoration:none;}.css-qtw155{display:block;}@media (min-width:1150px){.css-qtw155{display:none;}}.css-v0l3hm{display:none;}@media (min-width:1150px){.css-v0l3hm{display:block;}}.css-g4gku8{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-top:10px;min-width:600px;}.css-1rr4qq7{-webkit-flex:1;-ms-flex:1;flex:1;}.css-6xhk3s{border-left:1px solid #e2e2e2;-webkit-flex:1;-ms-flex:1;flex:1;padding-left:15px;}.css-1onhbft{color:#333;font-size:13px;font-weight:700;font-family:nyt-franklin,helvetica,arial,sans-serif;height:25px;line-height:15px;margin:0;text-transform:uppercase;width:150px;}.css-tj0ten{margin-bottom:5px;white-space:nowrap;}.css-tj0ten:last-child{margin-bottom:10px;}.css-ist4u3.desktop{display:none;}@media (min-width:740px){.css-ist4u3.desktop{display:block;}.css-ist4u3.smartphone{display:none;}}.css-1gprdgz{list-style:none;margin:0;padding:0;-webkit-columns:2;columns:2;padding:0 0 15px;}.css-10t7hia{height:34px;line-height:34px;list-style-type:none;}.css-10t7hia.desktop{display:none;}@media (min-width:740px){.css-10t7hia.desktop{display:block;}.css-10t7hia.smartphone{display:none;}}.css-e9w26l{color:#333;display:block;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:15px;font-weight:500;height:34px;line-height:34px;-webkit-text-decoration:none;text-decoration:none;text-transform:capitalize;}.css-yk8vb4{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:14px;font-weight:500;height:23px;line-height:16px;}.css-yk8vb4:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-yk8vb4{color:#fff;}.css-z6qatp{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:16px;font-weight:700;height:25px;line-height:15px;padding-bottom:0;}.css-z6qatp:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-z6qatp{color:#fff;}.css-1ea6cym{color:#000;display:inline-block;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-text-decoration:none;text-decoration:none;width:150px;font-size:11px;font-weight:500;height:23px;line-height:21px;}.css-1ea6cym:hover{cursor:pointer;-webkit-text-decoration:underline;text-decoration:underline;}body.dark .css-1ea6cym{color:#fff;}.css-6td9kr{list-style:none;margin:0;padding:0;border-top:1px solid #e2e2e2;margin-top:2px;padding-top:10px;}.css-1o03u4n{display:inline-block;height:13px;width:13px;margin-right:7px;vertical-align:middle;}.css-p6m5rf{margin:1.25rem 0 0;}.css-1r7ky0e .e6idgb70 + .e1h9rw200{margin-top:0;}.css-1r7ky0e .eoo0vm40 + .e1gnsphs0{margin-top:-0.3em;}.css-1r7ky0e .e6idgb70 + .eoo0vm40{margin-top:0;}.css-1r7ky0e .eoo0vm40 + figure{margin-top:1.2rem;}.css-1r7ky0e .e1gnsphs0 + figure{margin-top:1.2rem;}.css-ew4tgv{display:none;}@media (min-width:1024px){.css-ew4tgv{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-right:0;margin-left:auto;width:130px;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}}@media (min-width:1150px){.css-ew4tgv{width:210px;}}@media print{.css-ew4tgv{display:none;}}.css-s99gbd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;margin-bottom:1rem;}@media (min-width:1024px){.css-s99gbd{-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;height:100%;width:945px;margin-left:auto;margin-right:auto;}}@media (min-width:1150px){.css-s99gbd{width:1110px;margin-left:auto;margin-right:auto;}}@media (min-width:1280px){.css-s99gbd{width:1170px;}}@media (min-width:1440px){.css-s99gbd{width:1200px;}}@media print{.css-s99gbd{margin-left:0;margin-right:0;width:100%;max-width:100%;}}@media print{.css-s99gbd{margin-bottom:1em;display:block;}}.css-53u6y8{margin-left:auto;margin-right:auto;width:100%;}@media (min-width:1024px){.css-53u6y8{margin-left:calc((100% - 600px) / 2);margin-right:0;width:600px;}}@media (min-width:1440px){.css-53u6y8{max-width:600px;width:600px;margin-left:calc((100% - 600px) / 2);}}@media print{.css-53u6y8{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1ve50l5{border-top:1px solid #e8e8e8;border-bottom:1px solid #e8e8e8;margin-bottom:1.25rem;padding-top:1.25rem;padding-bottom:0.625rem;}.css-p5jc4e{width:262px;margin:0 auto 1.25rem;}@media (min-width:600px){.css-p5jc4e{margin:0 auto 0 0;}}.css-udpjq9{color:#333;font-weight:500;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.875rem;line-height:1.25rem;text-align:center;margin:0 auto;}.css-iry6ay{position:relative;margin:0 0.5rem;}.css-iry6ay::after{background:#ccc;height:80%;content:'';margin:0 0.3125rem;position:absolute;right:-0.375rem;top:0;width:0.0625rem;}.css-4ejn01{color:#326891;display:inline-block;}.css-4ejn01:hover{-webkit-text-decoration:underline;text-decoration:underline;}.css-1nq039c{display:block;margin:0 auto 0.625rem;text-align:center;max-width:16.875rem;}@media (min-width:600px){.css-1nq039c{max-width:25rem;}}.css-1382yzd{border-radius:3px;cursor:pointer;font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-transition:ease 0.6s;transition:ease 0.6s;white-space:nowrap;vertical-align:middle;background-color:#567b95;border:1px solid #326891;color:#fff;font-size:11px;line-height:11px;font-weight:700;-webkit-letter-spacing:0.05em;-moz-letter-spacing:0.05em;-ms-letter-spacing:0.05em;letter-spacing:0.05em;padding:11px 12px 8px;text-transform:uppercase;display:block;padding:0.8125rem;margin-top:1.25rem;}.css-1382yzd::-moz-focus-inner{padding:0;border:0;}.css-1382yzd:-moz-focusring{outline:1px dotted;}.css-1382yzd:disabled,.css-1382yzd.disabled{opacity:0.5;cursor:default;}@media (min-width:740px){.css-1382yzd:hover{background-color:#326891;}}.css-1gus26i{color:#b3b3b3;font-weight:500;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:0.75rem;line-height:1rem;text-align:center;margin:1.25rem auto;max-width:15.625rem;}@media (min-width:600px){.css-1gus26i{max-width:31.25rem;}}.css-1mweozg{color:#333;font-weight:500;font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:1.0625rem;line-height:1.625rem;font-style:italic;}.css-14uxcda{color:#333;font-weight:500;font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:1.0625rem;line-height:1.625rem;font-style:italic;font-weight:700;margin-top:1.25rem;}.css-6hi8ev{color:#333;font-weight:500;font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:1.0625rem;line-height:1.625rem;font-style:italic;margin-bottom:1.25rem;}.css-6hi8ev a{color:#326891;-webkit-text-decoration:underline;text-decoration:underline;}.css-1s1pakw .css-tqabw5{max-width:12.5rem;}.css-1s1pakw .css-1gus26i{max-width:15.625rem;}.css-1s1pakw .css-z4qjxy{max-width:15.625rem;}.css-1s1pakw .css-1nq039c{max-width:16.875rem;}.css-1ly73wi{position:absolute;width:1px;height:1px;margin:-1px;padding:0;border:0;-webkit-clip:rect(0 0 0 0);clip:rect(0 0 0 0);overflow:hidden;}.css-rq4mmj{height:auto;width:100%;width:100%;vertical-align:top;}.css-rq4mmj img{width:100%;vertical-align:top;}.css-ktho12{color:var(--color-content-quaternary,#727272);font-family:nyt-imperial,georgia,'times new roman',times,serif;margin:10px 20px 0;text-align:left;}.css-ktho12 a{color:var(--color-signal-editorial,#326891);-webkit-text-decoration:none;text-decoration:none;}.css-ktho12 a:hover,.css-ktho12 a:focus{-webkit-text-decoration:underline;text-decoration:underline;}@media (min-width:600px){.css-ktho12{margin-left:0;}}.sizeSmall .css-ktho12{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:calc(50% - 15px);margin:auto 0 15px 15px;}@media (min-width:600px){.sizeSmall .css-ktho12{width:260px;margin-left:15px;}}@media (min-width:740px){.sizeSmall .css-ktho12{margin-left:15px;}}@media (min-width:1440px){.sizeSmall .css-ktho12{width:330px;margin-left:15px;}}@media (max-width:600px){.sizeSmall .css-ktho12{margin:auto 0 0 15px;}}.sizeSmall.sizeSmallNoCaption .css-ktho12{margin-left:auto;margin-right:auto;margin-top:10px;}.sizeMedium .css-ktho12{max-width:900px;}.sizeSmall.layoutVertical.verticalVideo .css-ktho12{margin:0 0 auto 16px;}@media (min-width:740px){.sizeSmall.layoutVertical.verticalVideo .css-ktho12{margin:auto 0 auto 16px;}}.sizeMedium.layoutVertical.verticalVideo .css-ktho12{margin-left:auto;margin-right:auto;width:calc(100% - 40px);}@media (min-width:600px){.sizeMedium.layoutVertical.verticalVideo .css-ktho12{width:100%;}}.sizeLarge .css-ktho12{max-width:none;}@media (min-width:600px){.sizeLarge .css-ktho12{margin-left:20px;}}@media (min-width:740px){.sizeLarge .css-ktho12{margin-left:20px;max-width:900px;}}@media (min-width:1024px){.sizeLarge .css-ktho12{margin-left:0;max-width:720px;}}@media (min-width:1440px){.sizeLarge .css-ktho12{margin-left:0;max-width:900px;}}@media (min-width:740px){.sizeLarge.layoutVertical .css-ktho12{margin-left:0;}}.sizeFull .css-ktho12{margin-left:20px;}@media (min-width:600px){.sizeFull .css-ktho12{max-width:900px;}}@media (min-width:740px){.sizeFull .css-ktho12{max-width:900px;}}@media (min-width:1440px){.sizeFull .css-ktho12{max-width:900px;}}@media print{.css-ktho12{display:none;}}.css-14fe1uy{display:inline;color:var(--color-content-quaternary,#727272);font-family:nyt-franklin,helvetica,arial,sans-serif;-webkit-letter-spacing:0.01em;-moz-letter-spacing:0.01em;-ms-letter-spacing:0.01em;letter-spacing:0.01em;font-size:0.75rem;line-height:1rem;}@media (min-width:740px){.css-14fe1uy{font-size:0.75rem;line-height:1rem;}}@media (min-width:1150px){.css-14fe1uy{font-size:0.8125rem;line-height:1.0625rem;}}.css-233int{display:inline-block;}.css-4anu6l{display:inline-block;margin:0;font-size:0.875rem;line-height:1.125rem;font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:700;color:var(--color-content-secondary,#363636);}@media (min-width:740px){.css-4anu6l{font-size:0.9375rem;line-height:1.25rem;}}.css-at9mc1{margin-bottom:0.78125rem;margin-top:0;overflow-wrap:break-word;color:var(--color-content-secondary,#363636);font-family:nyt-imperial,georgia,'times new roman',times,serif;font-size:1.125rem;line-height:1.5625rem;margin-left:20px;margin-right:20px;width:calc(100% - 40px);max-width:600px;}@media (min-width:740px){.css-at9mc1{margin-bottom:0.9375rem;margin-top:0;}}.css-at9mc1 .css-yywogo{-webkit-text-decoration:underline;text-decoration:underline;-webkit-text-decoration-style:solid;text-decoration-style:solid;-webkit-text-decoration-thickness:1px;text-decoration-thickness:1px;-webkit-text-decoration-color:var(--color-signal-editorial,#326891);text-decoration-color:var(--color-signal-editorial,#326891);}.css-at9mc1 .css-yywogo:hover,.css-at9mc1 .css-yywogo:focus{-webkit-text-decoration:none;text-decoration:none;}@media (min-width:740px){.css-at9mc1{font-size:1.25rem;line-height:1.875rem;}}.css-at9mc1:first-child{margin-top:0;}.css-at9mc1:last-child{margin-bottom:0;}.css-at9mc1.e1h9rw200:last-child{margin-bottom:0.75rem;}.css-at9mc1.eoo0vm40:first-child{margin-top:0.8125rem;}@media (min-width:600px){.css-at9mc1{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-at9mc1{margin-left:0;margin-right:0;width:100%;max-width:100%;}.css-at9mc1.eoo0vm40:first-child{margin-top:1.1875rem;}}@media print{.css-at9mc1{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-sxwst7{background-color:#f7f7f7;border-bottom:1px solid #f3f3f3;border-top:1px solid #f3f3f3;margin:2rem auto;padding-bottom:30px;padding-top:12px;text-align:center;position:relative;margin-top:60px;min-height:280px;}@media (min-width:740px){.css-sxwst7{margin:3rem auto;}}@media print{.css-sxwst7{display:none;}}@media (min-width:740px){.css-sxwst7{margin-bottom:0;margin-top:0;}}.css-1gqes1i{margin-bottom:0.25rem;margin-top:0;}.css-1gqes1i:empty{display:none;}.css-8qgvsz{font-weight:700;}.css-1q2w90k{opacity:1;visibility:visible;-webkit-animation-name:animation-5j8bii;animation-name:animation-5j8bii;-webkit-animation-duration:300ms;animation-duration:300ms;-webkit-animation-delay:0ms;animation-delay:0ms;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}@media print{.css-1q2w90k{display:none;}}@media (min-width:1024px){.css-1q2w90k{position:fixed;width:100%;top:0;left:0;z-index:200;background-color:#fff;border-bottom:none;-webkit-transition:all 0.2s ease-in-out;transition:all 0.2s ease-in-out;}}@media (min-width:1024px){.css-1bymuyk{position:relative;border-bottom:1px solid #e2e2e2;}}.css-7s20nv{background:#fff;border-bottom:1px solid #e2e2e2;height:36px;padding:8px 15px 3px;position:relative;}@media (min-width:740px){.css-7s20nv{background:#fff;padding:8px 15px 3px;}}@media (min-width:1024px){.css-7s20nv{background:transparent;border-bottom:0;padding:4px 15px 2px;}}@media (min-width:1024px){.css-7s20nv{margin:0 auto;max-width:1605px;}}.css-1f7ibof{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;left:10px;position:absolute;}@media print{.css-1f7ibof{display:none;}}.css-10698na{text-align:center;}@media (min-width:740px){.css-10698na{padding-top:0;}}@media print{.css-10698na a[href]::after{content:'';}.css-10698na svg{fill:black;}}.css-ijmohz{display:block;width:189px;height:26px;margin:5px auto 0;}@media (min-width:740px){.css-ijmohz{width:189px;height:26px;margin:5px auto 0;}}@media (min-width:1024px){.css-ijmohz{width:195px;height:26px;margin:6px auto 0;}}.css-1npft71{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;position:absolute;right:10px;top:8px;}@media (min-width:1024px){.css-1npft71{top:4px;}}@media print{.css-1npft71{display:none;}}.css-c5j6tx{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:11px;-webkit-box-pack:space-around;-webkit-justify-content:space-around;-ms-flex-pack:space-around;justify-content:space-around;padding:13px 20px 12px;}@media (min-width:740px){.css-c5j6tx{position:relative;}}@media (min-width:1024px){.css-c5j6tx{-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;border:none;padding:0;height:0;-webkit-transform:translateY(48px);-ms-transform:translateY(48px);transform:translateY(48px);-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;}}@media print{.css-c5j6tx{display:none;}}.css-vfkorq{color:#121212;font-size:0.6875rem;font-family:nyt-franklin,helvetica,arial,sans-serif;display:none;width:auto;font-weight:700;}@media (min-width:740px){.css-vfkorq{text-align:center;width:100%;font-weight:700;}}@media (min-width:1024px){.css-vfkorq{font-size:0.875rem;line-height:1.25rem;width:auto;margin-bottom:4px;font-weight:400;}}.css-1bvtpon{display:none;}.css-wqhysl{top:0;position:-webkit-sticky;position:sticky;background-color:var(--color-background-elevated,#FFFFFF);z-index:902;}@media (min-width:1024px){.css-wqhysl{margin-top:3px;}}@media (min-width:1024px){.css-wqhysl:empty{margin-top:0;}}@media print{.css-wqhysl{display:none;}}.css-yomkvi .actionbar-button{background:var(--color-background-primary,#FFFFFF);border:1px solid var(--color-stroke-quaternary,#DFDFDF);color:var(--color-content-primary,#121212);box-shadow:none;}.css-yomkvi .actionbar-button svg > path{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button:hover{border:1px solid var(--color-stroke-quaternary,#DFDFDF);background:var(--color-background-tertiary,#EBEBEB);color:var(--color-content-primary,#121212);}.css-yomkvi .actionbar-button:hover svg > path{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button:hover svg > g{stroke:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button:active,.css-yomkvi .actionbar-button[aria-expanded='true']{border:1px solid var(--color-stroke-tertiary,#C7C7C7);background:rgba(235,235,235,0.6);}.css-yomkvi .actionbar-button:active svg > path,.css-yomkvi .actionbar-button[aria-expanded='true'] svg > path{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button:active svg > g,.css-yomkvi .actionbar-button[aria-expanded='true'] svg > g{stroke:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true'] .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true']:hover .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true']:hover .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true']:active .saved-fill{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='true']:active .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='false'] .saved-fill{fill:none;}.css-yomkvi .actionbar-button[aria-checked='false'] .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='false']:hover .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button[aria-checked='false']:active .saved-stroke{fill:var(--color-stroke-primary,#121212);}.css-yomkvi .actionbar-button:focus{box-shadow:0 0 2px 1px rgb(0 95 204);outline:3px solid transparent;outline-offset:2px;}@supports selector(:focus-visible){.css-yomkvi .actionbar-button:focus{box-shadow:none;}.css-yomkvi .actionbar-button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);outline:3px solid transparent;outline-offset:2px;}}.css-4skfbu{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;margin-bottom:0;}@media print{.css-4skfbu{display:none;}}.css-1c5ewvl{color:#999;display:inline;margin-right:12px;width:100%;position:relative;}.css-1c5ewvl > a,.css-1c5ewvl > button{-webkit-text-decoration:none;text-decoration:none;}.css-1c5ewvl > a:focus,.css-1c5ewvl > button:focus{display:inline-block;outline:none;box-shadow:0 0 2px 1px rgb(0 95 204);}@supports selector(:focus-visible){.css-1c5ewvl > a:focus,.css-1c5ewvl > button:focus{box-shadow:none;}.css-1c5ewvl > a:focus-visible,.css-1c5ewvl > button:focus-visible{box-shadow:0 0 2px 1px rgb(0 95 204);}}.css-1c5ewvl > a:focus{border-radius:100%;}@media (max-width:424px){.css-1c5ewvl{margin-right:6px;}}.css-1c5ewvl:last-of-type{margin-right:0;}.css-zd9juy{display:inline-block;vertical-align:middle;width:20px;border-radius:100%;padding:6px;overflow:initial;vertical-align:middle;height:20px;}.css-zd9juy path{fill:var(--color-content-primary,#121212);}.css-10d8k1f{direction:ltr;display:inline-block;vertical-align:middle;border-radius:30px;padding:6px 10px 6px;font-size:0.75rem;font-family:nyt-franklin,helvetica,arial,sans-serif;line-height:0.9375rem;text-align:right;font-weight:500;}.css-10d8k1f:hover .gift-count{background-color:#fafafa;}@media (max-width:600px){.css-10d8k1f{padding:6px 7px 5px;}}.css-10d8k1f svg{margin-right:5px;vertical-align:-6px;height:20px;}.css-eap6fy{height:18px;width:18px;padding:7px;overflow:visible;vertical-align:middle;cursor:not-allowed;}.css-eap6fy g{stroke-width:0.1px;}@media (min-width:1150px){.css-eap6fy:hover g,.css-eap6fy:focus g{stroke:var(--color-stroke-secondary,#8B8B8B);opacity:1;}}.css-1vxca1d{position:relative;margin:0 auto;}@media (min-width:600px){.css-1vxca1d{margin:0 auto 20px;}}.css-1vxca1d .relatedcoverage + .recirculation{margin-top:20px;}.css-1vxca1d .wrap + .recirculation{margin-top:20px;}@media (min-width:1024px){.css-1vxca1d{padding-top:40px;}}.css-1aeqhal{display:none;position:relative;min-height:280px;}@media (min-width:765px){.css-1aeqhal{background-color:#f7f7f7;border-bottom:1px solid #f3f3f3;display:block;padding-bottom:15px;padding-top:15px;margin:0;}}@media print{.css-1aeqhal{display:none;}}.css-10i3hc{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;width:calc(100% - 40px);max-width:600px;margin:1.5rem auto 2rem;margin-bottom:1rem;}@media print{.css-10i3hc{display:none;}}@media (min-width:1440px){.css-10i3hc{width:600px;max-width:600px;}}@media (min-width:600px){.css-10i3hc{-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}}.css-10i3hc:empty{display:none;}@media (min-width:600px){.css-10i3hc{margin-bottom:1rem;}}.css-jf7ug7{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;width:calc(100% - 40px);max-width:600px;margin:1.5rem auto 2rem;}@media print{.css-jf7ug7{display:none;}}@media (min-width:1440px){.css-jf7ug7{width:600px;max-width:600px;}}@media (min-width:600px){.css-jf7ug7{-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}}.css-1a5mdf6{cursor:pointer;margin:0;border-top:1px solid #ebebeb;color:#333;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:13px;font-weight:700;height:44px;-webkit-letter-spacing:0.04rem;-moz-letter-spacing:0.04rem;-ms-letter-spacing:0.04rem;letter-spacing:0.04rem;line-height:44px;text-transform:uppercase;}.accordionExpanded .css-1a5mdf6{color:#b3b3b3;}.css-1ho5u4o{list-style:none;margin:0 0 15px;padding:0;}@media (min-width:600px){.css-1ho5u4o{display:inline-block;}}.css-t8x4fj{list-style:none;line-height:8px;padding:0;}.css-t8x4fj:last-child > li{margin:16px 0 0 0;}@media (min-width:600px){.css-t8x4fj{display:inline-block;}}.css-a7htku{display:inline-block;line-height:20px;padding:0 10px;}.css-a7htku:first-child{border-left:none;}.css-a7htku.desktop{display:none;}@media (min-width:740px){.css-a7htku.smartphone{display:none;}.css-a7htku.desktop{display:inline-block;}.css-a7htku.mobileOnly{display:none;}}.css-1cgskve{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;}.css-ccw2r3{-webkit-flex-shrink:1;-ms-flex-negative:1;flex-shrink:1;padding-right:1rem;list-style:none;}.css-1e2jphy{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;width:100%;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:0.25rem;}.css-1e2jphy > img,.css-1e2jphy a > img,.css-1e2jphy div > img{margin-right:10px;}.css-1uc6ajg{font-family:nyt-franklin,helvetica,arial,sans-serif;font-weight:500;color:var(--color-content-secondary,#363636);margin-bottom:1rem;font-size:0.8125rem;line-height:1.125rem;margin-bottom:0;margin-top:0;}.css-11kk65x{margin-top:1.5625rem;}@media (min-width:740px){.css-11kk65x{margin-top:3.75rem;}}.css-11kk65x .e6idgb70{color:var(--color-content-primary,#121212);font-weight:700;line-height:0.75rem;margin-bottom:1.25rem;margin-top:0;}@media print{.css-11kk65x .e6idgb70{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-11kk65x .e1h9rw200{margin-bottom:20px;}@media (min-width:740px){.css-11kk65x .e1h9rw200{position:relative;}}.css-11kk65x .ezdmqqa0{margin-bottom:3px;}@media (min-width:600px){.css-11kk65x .ezdmqqa0{margin-bottom:0;}}.css-11kk65x .e1wiw3jv0{color:var(--color-content-secondary,#363636);}.css-11kk65x .e16638kd0{display:inline-block;}.css-11kk65x .eakwutd0{margin-bottom:20px;color:var(--color-content-primary,#121212);}@media print{.css-11kk65x .eakwutd0{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-r25it4{color:var(--color-content-primary,#121212);font-family:nyt-cheltenham,cheltenham-fallback-georgia,cheltenham-fallback-noto,georgia,'times new roman',times,serif;font-weight:700;font-style:italic;font-size:1.9375rem;line-height:2.25rem;margin:0 20px 20px;position:relative;width:calc(100% - 40px);max-width:600px;margin-left:20px;margin-right:20px;}@media (min-width:740px){.css-r25it4{font-size:2.5rem;line-height:2.875rem;}}@media (min-width:600px){.css-r25it4{margin-left:auto;margin-right:auto;}}@media print{.css-r25it4{margin-left:0;margin-right:0;width:100%;max-width:100%;}}@media (min-width:600px){.css-r25it4{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-r25it4{width:600px;}}@media (min-width:1440px){.css-r25it4{width:600px;max-width:600px;}}@media print{.css-r25it4{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-17yegpq{color:#999;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;font-family:nyt-franklin,helvetica,arial,sans-serif;font-size:17px;margin-bottom:5px;border-top:1px solid #ebebeb;padding-top:20px;margin-bottom:20px;width:calc(100% - 40px);max-width:600px;margin-left:20px;margin-right:20px;}@media print{.css-17yegpq{display:none;}}@media (min-width:740px){.css-17yegpq{margin-bottom:25px;}}@media (min-width:600px){.css-17yegpq{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-17yegpq{width:600px;}}@media (min-width:1440px){.css-17yegpq{width:600px;max-width:600px;}}@media print{.css-17yegpq{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-xt80pu{width:100%;width:calc(100% - 40px);max-width:600px;margin-left:20px;margin-right:20px;}@media (min-width:600px){.css-xt80pu{margin-left:auto;margin-right:auto;}}@media (min-width:1024px){.css-xt80pu{width:600px;}}@media (min-width:1440px){.css-xt80pu{width:600px;max-width:600px;}}@media print{.css-xt80pu{margin-left:0;margin-right:0;width:100%;max-width:100%;}}.css-1si6tjw{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;display:block;margin-bottom:1.875rem;}@media (min-width:600px){.css-1si6tjw{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}</style>\n",
      "    \n",
      "    \n",
      "\n",
      "    <script type=\"text/javascript\">\n",
      "    (function(e,t){function n(){if(!r()&&o()){var n=document.createElement(\"script\");n.id=\"nyt-fides\",n.src=e,t.document.head.appendChild(n)}}var i=new URLSearchParams(t.location.search),a=function(e){return(t.document.cookie.split(\";\").find((function(t){return t.includes(e)}))||\"\").replace(e,\"\").trim().charAt(16)},o=function(){var e,n,o,r=i.get(\"fides-override\"),l=a(\"nyt-purr=\"),s=a(\"override-purr=\");return 0<(null===(e=t.config)||void 0===e||null===(n=e.tc_info)||void 0===n||null===(o=n.fides_string)||void 0===o?void 0:o.length)||\"s\"===s||\"s\"===l||\"true\"===r},r=function(){return null!==t.document.getElementById(\"nyt-fides\")};n(),t.addEventListener(\"initWebview:ios\",n),t.fidesUtils={isFidesEligible:o}})('https://static01.nyt.com/vi-assets/static-assets/fides-8ff3b866ef707d7b05879c1b02bc31aa.js', window);\n",
      "    (function(e){function t(e){var t=e.layerType;return{event:\"impression\",priority:!0,module:{name:t,label:t,region:\"bottom\"}}}function n(t){(e.dataLayer||(e.dataLayer=[])).push(t)}function i(t){var n=e.document.getElementById(\"fides-banner\"),i=e.document.getElementById(\"fides-modal\"),a=e.document.getElementById(\"fides-embed-container\"),o=\"true\"===(null==i?void 0:i.getAttribute(\"aria-hidden\"));if(a)return\"cmp_layer_2\";if(null!==t){if(!n||!i)return\"\";if(n.contains(t))return\"cmp_layer_1\";if(i.contains(t))return\"cmp_layer_2\"}return o?\"cmp_layer_1\":\"cmp_layer_2\"}function a(t){var n=new CustomEvent(\"NYTFidesUpdated\",{detail:t});e.dispatchEvent(n)}var o;!0===(null===(o=e.fidesUtils)||void 0===o?void 0:o.isFidesEligible())&&(e.addEventListener(\"FidesUIShown\",(function(e){var i,a=(null==e||null===(i=e.detail)||void 0===i?void 0:i.extraDetails).servingComponent;\"tcf_banner\"===(void 0===a?\"\":a)&&n(t({layerType:\"cmp_layer_1\"}))})),e.addEventListener(\"click\",(function(e){var t=e.target,o=\"button\"===t.type,r=\"a\"===t.nodeName.toLowerCase();if(o||r){var l=function(e){return{\"accept all\":\"accept_all\",\"reject all\":\"reject_all\",\"manage preferences\":\"manage_prefs\",\"cookie policy\":\"cookie_policy\",\"privacy policy\":\"privacy_policy\",purposes:\"purposes\",features:\"features\",vendors:\"vendors\",save:\"save\"}[e.textContent.toLowerCase()]||\"\"}(t),s=i(t);if(l)n(function(e){var t=e.actionType,n=void 0===t?\"\":t,i=e.layerType,a=void 0===i?\"\":i;return{event:\"moduleInteraction\",eventData:{trigger:\"module\",type:\"click\"},module:{name:a,label:a,element:{name:n,label:n}}}}({actionType:l,layerType:s})),a(function(e){var t=e.actionType,n=void 0===t?\"\":t,i=e.layerType,a=void 0===i?\"\":i;return{subject:\"interaction\",data:{name:a,label:a,element:{name:n,label:n}}}}({actionType:l,layerType:s})),e.stopPropagation()}})),e.addEventListener(\"beforeunload\",(function(){var e=i(null);n(t({layerType:\"\".concat(e,\"_exit\")}))})))})(window);\n",
      "  </script>\n",
      "    \n",
      "    \n",
      "    <script type=\"text/javascript\">\n",
      "      // 41.342kB\n",
      "      window.viHeadScriptSize = 41.342;\n",
      "      window.NYTD = {};\n",
      "      window.vi = window.vi || {};\n",
      "      window.vi.pageType = { type: '', edge: 'vi-story'};\n",
      "      (function () { var userAgent=window.navigator.userAgent||window.navigator.vendor||window.opera||\"\",inNewsreaderApp=userAgent.includes(\"nytios\")||userAgent.includes(\"nyt_android\"),inXWordsApp=userAgent.includes(\"nyt_xwords_ios\")||userAgent.includes(\"Crosswords\"),inAndroid=userAgent.includes(\"nyt_android\")||userAgent.includes(\"Crosswords\"),iniOS=userAgent.includes(\"nytios\")||userAgent.includes(\"nyt_xwords_ios\"),isInWebviewByUserAgent=(inAndroid||iniOS)&&(inNewsreaderApp||inXWordsApp);function appType(){return inNewsreaderApp?\"newsreader\":inXWordsApp?\"crosswords\":\"\"}function deviceType(){return inAndroid?\"ANDROID\":iniOS?\"IOS\":\"\"}var _f=function(e){window.vi.webviewEnvironment={appType:appType(),deviceType:deviceType(),isInWebview:e.webviewEnvironment.isInWebview||isInWebviewByUserAgent,isPreloaded:e.webviewEnvironment.isPreloaded}};;_f.apply(null, [{\"gqlUrlClient\":\"https://samizdat-graphql.nytimes.com/graphql/v2\",\"gqlRequestHeaders\":{\"nyt-app-type\":\"project-vi\",\"nyt-app-version\":\"0.0.5\",\"nyt-token\":\"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+/oUCTBmD/cLdmcecrnBMHiU/pxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB\",\"x-nyt-targeting-dimensions-map\":\"newsTenure=anon_user\"},\"gqlFetchTimeout\":1500,\"disablePersistedQueries\":false,\"initialDeviceType\":\"smartphone\",\"fastlyAbraConfig\":{\".ver\":\"22839.000\",\"AMS_FrictionCircumventionDesktop_cwv\":\"2_low-mid-truncation\",\"AMS_FrictionCircumventionMobile_cwv\":\"2_low-mid-truncation\",\"DFP_TopAd_Anon_0124\":\"0_Control\",\"HOME_cwv_chartbeat\":\"0_Control\",\"STYLN_synth_voice_web\":\"1_synth\"},\"fastlyEntitlements\":[],\"internalPreviewConfig\":{},\"webviewEnvironment\":{\"isInWebview\":false,\"isPreloaded\":false},\"isOptimisticallyTruncated\":false,\"optimisticTruncationDropzone\":6,\"requestPath\":\"/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"isProvisionallyLoggedIn\":false,\"routeName\":\"vi-story\",\"serviceWorkerFile\":\"service-worker-test-1736527629209.js\",\"preloadedServiceWorkerFile\":\"/vi-assets/static-assets/preloaded-service-worker-1736527809396.js\"}]); })();;(function () { var _f=function(i,w){window.vi=window.vi||{},window.vi.env=Object.freeze(i),window.hybrid=w};;_f.apply(null, [{\"JKIDD_PATH\":\"https://a.nytimes.com/svc/nyt/data-layer\",\"ET2_URL\":\"https://a.et.nytimes.com\",\"ALS_URL\":\"https://als-svc.nytimes.com\",\"WEDDINGS_PATH\":\"https://content.api.nytimes.com\",\"GDPR_PATH\":\"https://us-central1-nyt-dsra-prd.cloudfunctions.net/datagov-dsr-formhandler\",\"RECAPTCHA_SITEKEY\":\"6LevSGcUAAAAAF-7fVZF05VTRiXvBDAY4vBSPaTF\",\"ABRA_ET_URL\":\"//et.nytimes.com\",\"NODE_ENV\":\"production\",\"EXPERIMENTAL_ROUTE_PREFIX\":\"\",\"ENVIRONMENT\":\"prd\",\"RELEASE\":\"74e0f0702bdea699e5b8f969d4a04ef588eead6b\",\"RELEASE_TAG\":\"\",\"AUTH_HOST\":\"https://myaccount.nytimes.com\",\"METER_HOST\":\"https://meter-svc.nytimes.com\",\"MESSAGING_LANDING_PAGE_HOST\":\"https://www.nytimes.com\",\"CAPI_HOST\":\"https://mwcm.nytimes.com\",\"SWG_PUBLICATION_ID\":\"nytimes.com\",\"GQL_FETCH_TIMEOUT\":\"1500\",\"GOOGLE_CLIENT_ID\":\"1005640118348-amh5tgkq641oru4fbhr3psm3gt2tcc94.apps.googleusercontent.com\",\"STORY_SURROGATE_CONTROL\":\"max-age=300, stale-if-error=259200, stale-while-revalidate=259200\",\"ONBOARDING_API_KEY\":\"\",\"PURR_ENV\":\"prd\"},false]); })();;(function () { var _f=function(){var e=window;e.initWebview=function(e){var t=document.documentElement;if(e.OS){var i=e.OS.toUpperCase();t.classList.add(i)}if(e.BaseFontSize&&(t.dataset.baseFontSize=e.BaseFontSize),e.trackingSensitive&&(t.dataset.trackingSensitive=!0),e.hasOptedOutOfTracking&&(t.dataset.hasOptedOutOfTracking=!0),e.PurrDirectives){var a=e.PurrDirectives.PURR_AdConfiguration_v3||e.PurrDirectives.PURR_AdConfiguration_v2;a&&(t.dataset.optedOutOfAds=[\"adluce\",\"adluce-socrates\"].includes(a))}e.OS&&\"IOS\"===e.OS.toUpperCase()&&window.dispatchEvent(new CustomEvent(\"initWebview:ios\",{detail:e}))};var t=e.navigator.userAgent.toLowerCase();/iphone|ipod|ipad/.test(t)||void 0===e.config||e.initWebview(e.config)};;_f.apply(null, []); })();;\n",
      "(()=>{var Q=1e3,b=\"pageViewID\",Y=\"getPageViewID\",h=\"contextID\",Z=\"getContextID\",ee=\"NativeBridge unavailable.\";async function X(e){if(!T())return Promise.reject(\"not in webview\");try{await U();let t={};return await Promise.all([L(b,Y,e),L(h,Z,e)]).then(o=>{o.forEach(a=>{a.name==b?t[b]=a.id:t[h]=a.id})}),Promise.resolve(t)}catch(t){return Promise.reject(t)}}function T(){if(window?.vi?.webviewEnvironment!==void 0)return window.vi.webviewEnvironment.isInWebview&&window.vi.webviewEnvironment.deviceType==\"IOS\";if(window?.navigator?.userAgent!==void 0){for(var e=[\"nytios\"],t=0;t<e.length;t++)if(window.navigator.userAgent.includes(e[t]))return!0}return!1}function J(){var e={subject:\"page_update\",assetUrl:(document.querySelector(\"link[rel=canonical]\")||{}).href,assetId:(document.querySelector(\"meta[name=articleid]\")||{}).content,nyt_uri:(document.querySelector(\"meta[name=nyt_uri]\")||{}).content,url:location.href,client_tz_offset:new Date().getTimezoneOffset(),sourceApp:(document.querySelector(\"meta[name=sourceApp]\")||{}).content||\"nytcooking\"};window.nyt_et(\"send\",e)}function te(e,t){window.NativeBridge.addEventListener(e+\"DidChange\",function(o){t(e,o)})}async function L(e,t,o){return window.NativeBridge.callNativeBridgeCommand(t).then(a=>{let _=a.values[e];return te(e,o),Promise.resolve({name:e,id:_})})}async function U(e=0){return window.NativeBridge?Promise.resolve():e>=Q?Promise.reject(ee):new Promise((t,o)=>{setTimeout(function(){return U(e+1).then(t).catch(o)},10)})}function z(e){return!!(Object.keys(e).length==2&&e.hasOwnProperty(\"gtm\")&&e.hasOwnProperty(\"activeTime\")||e.hasOwnProperty(\"eventData\")&&Object.keys(e.eventData).length==2&&e.eventData.hasOwnProperty(\"gtm\")&&e.eventData.hasOwnProperty(\"activeTime\"))}function D(){var e,t,o=window.crypto||window.msCrypto;if(o)t=o.getRandomValues(new Uint8Array(18));else for(t=[];t.length<18;)t.push(Math.random()*256^(e=e||+new Date)&255),e=Math.floor(e/256);return btoa(String.fromCharCode.apply(String,t)).replace(/\\+/g,\"-\").replace(/\\//g,\"_\")}function F(e,t){var o=\"\",a=\"\",_=!1,c=!1,l=!1,g=!1;if(typeof e==\"string\"&&e==\"init\"&&typeof t==\"object\"&&(_=!!t.intranet,c=!!t.force_xhr,l=!!t.store_last_response,g=!!t.use_webview_dedup_logic,typeof t.pv_id_override==\"string\"&&typeof t.ctx_id_override==\"string\"))if(t.pv_id_override.length>=24&&t.ctx_id_override.length>=24)o=t.pv_id_override,a=t.ctx_id_override;else try{console.warn(\"override id(s) must be >= 24 chars long\")}catch{}return{pv_id:o,ctx_id:a,intra:_,store_last_response:l,force_xhr:c,use_webview_dedup_logic:g}}function $(e,t,o,a,_,c,l,g){if(!a&&(l===\"beacon\"||g&&o)){var f=window.navigator.sendBeacon(e,t);return _&&(last_send_response=f),f}else{var s=typeof XMLHttpRequest<\"u\"?new XMLHttpRequest:new ActiveXObject(\"Microsoft.XMLHTTP\");return s.open(\"POST\",e),s.withCredentials=!0,s.setRequestHeader(\"Accept\",\"*/*\"),typeof t==\"string\"?s.setRequestHeader(\"Content-Type\",\"text/plain;charset=UTF-8\"):{}.toString.call(t)===\"[object Blob]\"&&t.type&&s.setRequestHeader(\"Content-Type\",t.type),c&&s.setRequestHeader(\"ETJS-Ignore-Session-Info\",\"true\"),_&&!s.onload&&(s.onload=function(){last_send_response=s.response},s.onerror=function(P){last_send_response=!1}),s.send(t),!0}}(function(e,t){if(e.nyt_et){console.warn(\"et2 snippet should only load once per page\");return}var o,a,_,c,l=0,g,f=[],s,P,p={pv_id:\"\",ctx_id:\"\",intra:!1,force_xhr:!1,store_last_response:!1,use_webview_dedup_logic:!1},B=typeof e.navigator==\"object\"&&typeof e.navigator.userAgent==\"string\"&&/iP(ad|hone|od)/.test(e.navigator.userAgent),O=typeof e.navigator==\"object\"&&e.navigator.sendBeacon,C=O?B?\"xhr_ios\":\"beacon\":\"xhr\",u=T(),d=\"\",m=\"\",S=0;function K(n,i){if(n!==b&&n!==h){console.error(\"syncID got unknown id=\"+n);return}if(!(!i||!i.detail)){var r=i.detail[n]||i.detail.newID;r&&(n===b?d=r:m=r,J())}}function A(n){if(f.length!==0){if(u&&(d===void 0||d===\"\")){console.log(\"ERROR: in webview attempting to transmit() but native_pvid not set. Doing nothing...\");return}$(a,JSON.stringify(f),n,p.force_xhr,p.store_last_response,u,C,O),f.length=0,clearTimeout(s),s=null}}function x(n){var i,r,v,w,R,H,y=n[0];if(typeof y==\"string\"&&/init/.test(y)&&(\"\"+JSON.stringify(n),H=!0,p=F(y,n[3]),c=p.pv_id||D(),l+=1,y==\"init\"&&!_)){if(_=p.ctx_id||D(),typeof n[1]==\"string\"&&/^http/.test(n[1]))o=String(n[1]).replace(/([^\\/])$/,\"$1/\"),a=o+\"track\";else throw new Error(\"init must include an et host url\");if(typeof n[2]==\"string\")g=n[2];else throw new Error(\"init must include a source app name\")}var N=n.length-1;if(n[N]&&typeof n[N]==\"object\"&&(i=n[N]),!i&&!/init/.test(y)?console.warn(\"when invoked without 'init' or 'pageinit', nyt_et() must include a event data\"):i&&!i.subject&&console.warn(\"event data {} must include a subject\"),!o||!(i&&i.subject)){console.log(\"ERROR: data must contain subject and et_base_url must be set\");return}let j=l==1;var V=!1,I=p.use_webview_dedup_logic;if(u&&p.use_webview_dedup_logic&&H&&j&&i.subject==\"page\"&&(i.subject=\"page_update\",V=!0),r=i.subject,delete i.subject,w=r==\"page_exit\"||(i.eventData||{}).type==\"ob_click\",R=r==\"page_update\",I&&u&&w&&(r=\"page_update\",w=!1,R=!0),I&&u&&R&&z(i)){S+=1;return}r==\"page\"||r==\"page_soft\"?v=c:v=D();let W=c,G=_;I&&u&&j&&(W=d,G=m),f.push({context_id:G,pageview_id:W,event_id:v,client_lib:t,sourceApp:g,intranet:p.intra?1:void 0,subject:r,how:w&&B&&O?\"beacon_ios\":C,client_ts:+new Date,data:JSON.parse(JSON.stringify(i))}),y==\"send\"||v==c||w||V?A(w):(y==\"soon\"&&(clearTimeout(s),s=setTimeout(A,200)),s||(s=setTimeout(A,5500)))}e.nyt_et=function(){var n=arguments;if(u&&d===\"\"){e.nyt_et_buffer=e.nyt_et_buffer||[],e.nyt_et_buffer.push(n);return}x(n)};var k=!1;function M(){if(u&&d===\"\"){return}if(k){q(e.nyt_et_buffer);return}let n=e.nyt_et_buffer;e.nyt_et_buffer=e.nyt_et_buffer||[],q(n),e.nyt_et_buffer.push=new Proxy(e.nyt_et_buffer.push,{apply:function(i,r,v){return console.table(\"calling window.nyt_et\",r,v),x(v),i.apply(r,v)}}),k=!0}M();var E=0;function q(n=[]){if(!g){let i=n?.findIndex(r=>typeof r[0]==\"string\"&&r[0]===\"init\");\"\"+i.toString(),i>-1&&x(n[i])}\"\"+E;for(let i=E;i<n.length;i++){let r=n[i];\"\"+E+i,typeof r[0]==\"string\"&&r[0]!==\"init\"&&(console.log(\"non-init event at pos=\"+i.toString()),x(r)),E++}}e.nyt_et.get_pageview_id=function(){return p.use_webview_dedup_logic&&u&&l>=1?d:c},e.nyt_et.get_context_id=function(){return p.use_webview_dedup_logic&&u&&l>=1?m:_},e.nyt_et.get_host=function(){return o},e.nyt_et.is_running_in_webview=function(){return u},e.nyt_et.get_native_pageview_id=function(){return d},e.nyt_et.get_native_context_id=function(){return m},e.nyt_et.get_buffer_len=function(){f.length},e.nyt_et.get_buffer=function(){return f},e.nyt_et.call_is_running_in_webview=function(){return T()},e.nyt_et.get_last_send_response=function(){var n=P;return n&&(P=null),n},e.nyt_et.get_num_blocked_heartbeats=function(){return S},e.nyt_et.reset_blocked_heartbeat_counts=function(){S=0},u&&X(K).then(n=>{m=n[h],d=n[b],M()}).catch(console.error).finally(console.log)})(window,\"v1.4.0\");})();\n",
      "\n",
      ";(function c(e){var t,n=(null===(t=e=e||(\"undefined\"!=typeof window?window:void 0))||void 0===t?void 0:t.UnifiedTracking)||{};return n.context=\"web\",e?(e.UnifiedTracking=n,n.sendAnalytic=function(t,n){return e.dataLayer=e.dataLayer||[],Array.isArray(e.dataLayer)&&(n.event=n.event||t,e.dataLayer.push(n)),Promise.resolve({success:!0})},n):n})(window);!function(r){var n,t;r=r||self,n=r.Abra,(t=r.Abra=function(){\"use strict\";var r=Array.isArray,n=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];if(null==u||\"\"===u)return n;for(var i=String(u).split(\".\"),a=0;a<i.length&&(n=n[i[a]]);a++);return null==n&&(n=o),null!=n?n:null},t=function(r,n,t){return r(t,n).reduce((function(r,n){return parseFloat(r)+parseFloat(n)}),0)},e=function(r,n,t){var e=r(t,n);return e[0]/e[1]},u=function(r,n,t){var e=r(t,n);return e[0]%e[1]},o=function(r,n,t){return r(t,n).reduce((function(r,n){return parseFloat(r)*parseFloat(n)}),1)},i=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];return void 0===o?-u:u-o};function a(n){return!(r(n)&&0===n.length||!n)}var f=function(r,n,t){for(var e,u=0;u<t.length;u++)if(!a(e=r(t[u],n)))return e;return e},c=function(r,n,t){var e;for(e=0;e<t.length-1;e+=2)if(a(r(t[e],n)))return r(t[e+1],n);return t.length===e+1?r(t[e],n):null},l=function(r,n,t){return!a(r(t,n)[0])},v=function(r,n,t){for(var e,u=0;u<t.length;u++)if(a(e=r(t[u],n)))return e;return e},d=function(r,n,t){var e=r(t,n);return e[0]===e[1]},s=function(r,n,t){var e=r(t,n);return e[0]!==e[1]},h=function(r,n,t){var e=r(t,n),u=e[0],o=e[1];return!(!o||void 0===o.indexOf)&&-1!==o.indexOf(u)},g=function(r,n,t){var e=r(t,n);return e[0]>e[1]},p=function(r,n,t){var e=r(t,n);return e[0]>=e[1]},b=function(r,n,t){var e=r(t,n),u=e[0],o=e[1],i=e[2];return void 0===i?u<o:u<o&&o<i},w=function(r,n,t){var e=r(t,n),u=e[0],o=e[1],i=e[2];return void 0===i?u<=o:u<=o&&o<=i},y=function(r,n,t){var e=t[0],u=t[1],o=t.slice(2),i=r(e,n);if(!i)return null;if(0===o.length)return null;if(1===o.length)return r(o[0],n);if(4294967295===o[0])return r(o[1],n);for(var a=function(r){var n,t,e,u,o,i=[],a=[t=1732584193,e=4023233417,~t,~e,3285377520],f=[],c=unescape(encodeURI(r))+\"\\x80\",l=c.length;for(f[r=--l/4+2|15]=8*l;~l;)f[l>>2]|=c.charCodeAt(l)<<8*~l--;for(n=l=0;n<r;n+=16){for(t=a;l<80;t=[t[4]+(i[l]=l<16?~~f[n+l]:2*c|c<0)+1518500249+[e&u|~e&o,c=341275144+(e^u^o),882459459+(e&u|e&o|u&o),c+1535694389][l++/5>>2]+((c=t[0])<<5|c>>>27),c,e<<30|e>>>2,u,o])c=i[l-3]^i[l-8]^i[l-14]^i[l-16],e=t[1],u=t[2],o=t[3];for(l=5;l;)a[--l]+=t[l]}return a[0]>>>0}(i+\" \"+r(u,n));o.length>1;){var f=o.splice(0,2),c=f[0],l=f[1];if(a<=r(c,n))return r(l,n)}return 0===o.length?null:r(o[0],n)},k=function(r,n,t){var e=t[0],u=t[1],o=r(e,n);return null==o?null:new RegExp(u).test(o)};return function(a,m,O,A){void 0===a&&(a={}),void 0===m&&(m={}),void 0===O&&(O={}),void 0===A&&(A=!1);var j=function(){var r={},n=function(n){if(n)for(var t,e=decodeURIComponent(n[1]),u=/(?:^|,)([^,=]+)=([^,]*)/g;t=u.exec(e);){var o=t,i=o[1],a=o[2];r[i]=a||null}};n(document.cookie.match(/(?:^|;) *abra-overrides=([^;]+)/)),n(window.location.search.match(/(?:\\?|&)abra-overrides=([^&]+)/));var t=/(?:^|;) *abra-nuke=true(?:;|$)/.test(document.cookie)||/(?:\\?|&)abra-nuke=true(?:&|$)/.test(window.location.search);return[r,t]}(),x=j[0],E=j[1];Object.keys(O).forEach((function(r){x[r]=O[r]}));var F,C=A||E,R=(F={var:n,if:c,\"===\":d,\"!==\":s,and:f,or:v,\"!\":l,\">\":g,\">=\":p,\"<\":b,\"<=\":w,\"+\":t,\"-\":i,\"*\":o,\"/\":e,\"%\":u,in:h,abtest_partition:y,regex_match:k,ref:function(r,n,t){var e=r(t,n)[0];return U(e)}},function n(t,e){if(e||(e={}),r(t))return t.map((function(r){return n(r,e)}));if(!function(n){return\"object\"==typeof n&&null!==n&&!r(n)&&1===Object.keys(n).length}(t))return t;var u=function(r){return Object.keys(r)[0]}(t),o=t[u];r(o)||(o=[o]);var i=F[u];if(!i)throw new Error(\"Unrecognized operation \"+u);return i(n,e,o)}),U=function(r){if(!r)return null;var n=x[r];if(void 0===n){if(!C){if(Object.prototype.hasOwnProperty.call(x,r))throw new Error(\"circular logic\");x[r]=void 0,n=R(a[r],m)}void 0===n&&(n=null),x[r]=n}return n};return U}}()).noConflict=function(){return r.Abra=n,t}}(this);\n",
      ";(function () { var NYTD=\"undefined\"!=typeof window&&window.NYTD?window.NYTD:{};function setupTimeZone(){var e='[data-timezone][data-timezone~=\"'+(new Date).getHours()+'\"] { display: block }',i=document.createElement(\"style\");i.innerHTML=e,document.head.appendChild(i)}function addNYTAppClass(){var e=window.vi&&window.vi.webviewEnvironment||{};e&&e.isInWebview&&document.documentElement.classList.add(\"NYTApp\"),e&&e.isPreloaded&&document.documentElement.classList.add(\"NYTAppPreloaded\"),e&&e.deviceType&&document.documentElement.classList.add(window.vi.webviewEnvironment.deviceType)}function addNYTPageTypeClass(){var e=window.vi.pageType.edge;e&&document.documentElement.classList.add(\"nytapp-\"+e)}function isIOSNewsreaderWebview(){return void 0!==window.vi&&void 0!==window.vi.webviewEnvironment&&\"IOS\"===window.vi.webviewEnvironment.deviceType&&\"newsreader\"===window.vi.webviewEnvironment.appType}function shouldUseNativePvid(){return void 0!==window.vi&&void 0!==window.vi.webviewEnvironment&&window.vi.webviewEnvironment.isPreloaded||isIOSNewsreaderWebview()}function setNativePageViewId(e){return e?NYTD.PageViewId.current=e:isIOSNewsreaderWebview()?window.NativeBridge.getPageViewID().then(function(e){window.NYTD=window.NYTD||{},window.NYTD.PageViewId=window.NYTD.PageViewId||{},e&&e.values&&e.values.pageViewID?NYTD.PageViewId.current=e.values.pageViewID:NYTD.PageViewId.current=\"native-bridge-pageview_id-undefined\"}).catch(function(){NYTD.PageViewId.current=\"native-bridge-getpageviewid-catch\"}):window.config&&window.config.AdRequirements&&window.config.AdRequirements.page_view_id?NYTD.PageViewId.current=window.config.AdRequirements.page_view_id:NYTD.PageViewId.current=\"native-pageview_id-unavailable\",NYTD.PageViewId.current}function forceNativePageViewIdUpdate(e){setNativePageViewId(e),window.AdSlot4&&window.AdSlot4.updateAdReq&&window.AdSlot4.updateAdReq({page_view_id:e})}function handlePvidDidChange(e){forceNativePageViewIdUpdate(e&&e.detail&&(e.detail.pageViewID||e.detail.newID))}function setupPageViewId(){NYTD.PageViewId={},NYTD.PageViewId.update=function(e){return e?NYTD.PageViewId.current=e:shouldUseNativePvid()?setNativePageViewId():\"undefined\"!=typeof nyt_et&&\"function\"==typeof window.nyt_et.get_pageview_id?(window.nyt_et(\"pageinit\"),NYTD.PageViewId.current=window.nyt_et.get_pageview_id()):NYTD.PageViewId.current=\"no-native-bridge-nor-nyt_et\",NYTD.PageViewId.current},shouldUseNativePvid()&&(isIOSNewsreaderWebview()?window.NativeBridge.addEventListener(\"pageViewIDDidChange\",handlePvidDidChange):window.updatePageViewID=forceNativePageViewIdUpdate)}var _f=function(){try{document.domain=\"nytimes.com\"}catch(e){}window.swgUserInfoXhrObject=new XMLHttpRequest,setupPageViewId(),setupTimeZone(),addNYTAppClass(),addNYTPageTypeClass(),window.nyt_et&&\"function\"==typeof window.nyt_et&&window.nyt_et(\"init\",vi.env.ET2_URL,\"nyt-vi\",{use_webview_dedup_logic:!0},{subject:\"page\",canonicalUrl:(document.querySelector(\"link[rel=canonical]\")||{}).href,articleId:(document.querySelector(\"meta[name=articleid]\")||{}).content,nyt_uri:(document.querySelector(\"meta[name=nyt_uri]\")||{}).content,pubpEventId:(document.querySelector(\"meta[name=pubp_event_id]\")||{}).content,url:location.href,referrer:document.referrer||void 0,client_tz_offset:(new Date).getTimezoneOffset()}),shouldUseNativePvid()?setNativePageViewId():\"undefined\"!=typeof nyt_et&&\"function\"==typeof window.nyt_et.get_pageview_id?NYTD.PageViewId.current=window.nyt_et.get_pageview_id()||\"nyt_et-pageview_id-undefined\":NYTD.PageViewId.update();var e=window.reportError;window.reportError=function(){var i=Array.prototype.slice.call(arguments),n=i[0];(n.message.includes(\"root will switch to client rendering.\")||n.message.includes(\"Minified React error #423\"))&&window.dispatchEvent(new CustomEvent(\"react-hydration-error\")),e.apply(null,i)},window.NYTD=NYTD||{}};;_f.apply(null, []); })();;(function () { var NYTD=\"undefined\"!=typeof window&&window.NYTD?window.NYTD:{};var _f=function(n){var e=window.vi&&window.vi.webviewEnvironment&&window.vi.webviewEnvironment.isPreloaded;function i(){window.Abra&&\"function\"==typeof window.Abra&&(NYTD.Abra=function(){var i=e?window.getNativeBridgeCookie(\"nyt-a\"):(window.document.cookie.match(/(?:^|;) *nyt-a=([^;]*)/)||[])[1],t=[];window.dataLayer=window.dataLayer||[],c.config=n.abraConfig||{},c.reportedAllocations={},c.reportedExposures={};var o=(n.abraURL||\"\").match(/current[/]([a-zA-Z-]+).json/i);c.integration=o&&o.length>1?o[1]:\"\";try{c.version=window.Abra(c.config)(\".ver\")}catch(n){c.version=0}var r=c.config,a={agent_id:i},d=window.Abra(r,a);function c(n){return c.getAbraSync(n).variant}return c.getAbraSync=function(n){var e=c.reportedAllocations[n];if(void 0!==e)return{variant:e,allocated:!0};var i=null,t=!1;try{i=d(n),t=!0}catch(n){}return{variant:i,allocated:t}},c.reportExposure=function(n){var e=c.getAbraSync(n).variant;if(null!=e&&(void 0===c.reportedExposures[n]||e!==c.reportedExposures[n])){c.reportedExposures[n]=e;var i={event:\"ab-expose\",abtest:{test:n,variant:e,config_ver:c.version,integration:c.integration}};window.UnifiedTracking.sendAnalytic(i.event,i)}},c.alloc=function(){Object.keys(c.config).filter(function(n){return!n.includes(\".\")}).forEach(function(n){var e=c.getAbraSync(n);e.allocated&&(c.reportedAllocations[n]=e.variant,t.push({test:n,variant:e.variant}))});var n={event:\"ab-alloc\",abtest:{batch:t}};window.UnifiedTracking.sendAnalytic(n.event,n)},c.alloc(),c}(),window.NYTD=NYTD||{})}e&&!window.nativeBridgeCookies?window.initNativeBridgeCookies(i):i()};;_f.apply(null, [{\"abraConfig\":{\".ver\":23018,\"UPSHOT_wordleStateV2_0306\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"UPSHOT_wordleStateV2_0306\",4294967295,\"0_Control\"]},\"UJ_subx_lire_read_in_app_0824\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"5102aad0-6a61-4c7f-9bf2-7f298c427e7f\",4294967295,\"2_low_friction\"]},\"UJ_ResurfaceRegiOnboarding_0924\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"UJ_ResurfaceRegiOnboarding_0924\",107374181,\"1_ResurfaceRegiOnboarding\",214748364,\"2_ResurfaceRegiOnboarding\",2254857829,\"1_ResurfaceRegiOnboarding\",4294967295,\"2_ResurfaceRegiOnboarding\"]}]},\"UJ_ResurfaceAAOnboarding_0924\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"49c3c84d-7935-4652-80a7-50bfc2aaee45\",2147483647,\"1_ResurfaceAAOnboarding\",4294967295,\"2_ResurfaceAAOnboarding\"]}]},\"UJ_AAOnboardingGamesIntervention_0624\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"UJ_AAOnboardingGamesIntervention_0624\",10737417,\"3_variant_Gamesonb_plusbanner\",21474835,\"3_variant_Gamesonb_plusbanner\",32212254,\"3_variant_Gamesonb_plusbanner\",42949672,\"3_variant_Gamesonb_plusbanner\",53687090,\"3_variant_Gamesonb_plusbanner\",64424508,\"3_variant_Gamesonb_plusbanner\",75161927,\"3_variant_Gamesonb_plusbanner\",85899345,\"3_variant_Gamesonb_plusbanner\",107374181,\"3_variant_Gamesonb_plusbanner\",118111600,\"3_variant_Gamesonb_plusbanner\",128849018,\"3_variant_Gamesonb_plusbanner\",139586436,\"3_variant_Gamesonb_plusbanner\",150323854,\"3_variant_Gamesonb_plusbanner\",161061273,\"3_variant_Gamesonb_plusbanner\",171798691,\"3_variant_Gamesonb_plusbanner\",182536109,\"3_variant_Gamesonb_plusbanner\",193273527,\"3_variant_Gamesonb_plusbanner\",204010946,\"3_variant_Gamesonb_plusbanner\",214748364,\"3_variant_Gamesonb_plusbanner\",225485782,\"3_variant_Gamesonb_plusbanner\",236223200,\"3_variant_Gamesonb_plusbanner\",246960619,\"3_variant_Gamesonb_plusbanner\",257698037,\"3_variant_Gamesonb_plusbanner\",268435455,\"3_variant_Gamesonb_plusbanner\",279172873,\"3_variant_Gamesonb_plusbanner\",289910291,\"3_variant_Gamesonb_plusbanner\",300647710,\"3_variant_Gamesonb_plusbanner\",311385128,\"3_variant_Gamesonb_plusbanner\",322122546,\"3_variant_Gamesonb_plusbanner\",332859964,\"3_variant_Gamesonb_plusbanner\",343597383,\"3_variant_Gamesonb_plusbanner\",354334801,\"3_variant_Gamesonb_plusbanner\",365072219,\"3_variant_Gamesonb_plusbanner\",375809637,\"3_variant_Gamesonb_plusbanner\",386547056,\"3_variant_Gamesonb_plusbanner\",397284474,\"3_variant_Gamesonb_plusbanner\",408021892,\"3_variant_Gamesonb_plusbanner\",418759310,\"3_variant_Gamesonb_plusbanner\",429496729,\"3_variant_Gamesonb_plusbanner\",440234147,\"3_variant_Gamesonb_plusbanner\",450971565,\"3_variant_Gamesonb_plusbanner\",461708983,\"3_variant_Gamesonb_plusbanner\",472446402,\"3_variant_Gamesonb_plusbanner\",483183820,\"3_variant_Gamesonb_plusbanner\",493921238,\"3_variant_Gamesonb_plusbanner\",504658656,\"3_variant_Gamesonb_plusbanner\",515396075,\"3_variant_Gamesonb_plusbanner\",526133493,\"3_variant_Gamesonb_plusbanner\",536870911,\"3_variant_Gamesonb_plusbanner\",547608329,\"3_variant_Gamesonb_plusbanner\",558345747,\"3_variant_Gamesonb_plusbanner\",569083166,\"3_variant_Gamesonb_plusbanner\",579820584,\"3_variant_Gamesonb_plusbanner\",590558002,\"3_variant_Gamesonb_plusbanner\",601295420,\"3_variant_Gamesonb_plusbanner\",612032839,\"3_variant_Gamesonb_plusbanner\",622770257,\"3_variant_Gamesonb_plusbanner\",633507675,\"3_variant_Gamesonb_plusbanner\",644245093,\"3_variant_Gamesonb_plusbanner\",654982512,\"3_variant_Gamesonb_plusbanner\",665719930,\"3_variant_Gamesonb_plusbanner\",676457348,\"3_variant_Gamesonb_plusbanner\",687194766,\"3_variant_Gamesonb_plusbanner\",697932185,\"3_variant_Gamesonb_plusbanner\",708669603,\"3_variant_Gamesonb_plusbanner\",719407021,\"3_variant_Gamesonb_plusbanner\",730144439,\"3_variant_Gamesonb_plusbanner\",740881858,\"3_variant_Gamesonb_plusbanner\",751619276,\"3_variant_Gamesonb_plusbanner\",762356694,\"3_variant_Gamesonb_plusbanner\",773094112,\"3_variant_Gamesonb_plusbanner\",794568949,\"3_variant_Gamesonb_plusbanner\",805306367,\"3_variant_Gamesonb_plusbanner\",837518622,\"3_variant_Gamesonb_plusbanner\",858993458,\"3_variant_Gamesonb_plusbanner\",880468295,\"3_variant_Gamesonb_plusbanner\",923417968,\"3_variant_Gamesonb_plusbanner\",955630222,\"3_variant_Gamesonb_plusbanner\",1009317314,\"3_variant_Gamesonb_plusbanner\",1052266987,\"3_variant_Gamesonb_plusbanner\",4294967295,\"3_variant_Gamesonb_plusbanner\"]}]},\"SUBX_regi_alloc_holdout_2024H1\":{\"abtest_partition\":[{\"var\":\"regi_id\"},\"SUBX_regi_alloc_holdout_2024H1\",214748364,\"1_best_experience\",429496729,\"1_best_experience\",4294967295,\"1_best_experience\"]},\"SUBX_agent_alloc_holdout_2024H1\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SUBX_agent_alloc_holdout_2024H1\",214748364,\"1_best_experience\",429496729,\"1_best_experience\",4294967295,\"1_best_experience\"]},\"SUBCON_RES_AIG_SURVEY_228\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SUBCON_RES_AIG_SURVEY_228\",4080218930,\"0_Control\",4294967295,\"1_Variant\"]},\"STYLN_synth_voice_web\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"STYLN_synth_voice_web2\",42949672,\"1_synth\",408021892,\"1_synth\",450971565,\"1_synth\",472446402,\"1_synth\",536870911,\"1_synth\",558345747,\"1_synth\",622770257,\"1_synth\",644245093,\"1_synth\",751619276,\"1_synth\",773094112,\"1_synth\",816043785,\"1_synth\",880468295,\"1_synth\",923417968,\"1_synth\",966367641,\"1_synth\",1009317314,\"1_synth\",1095216659,\"1_synth\",1138166332,\"1_synth\",1181116005,\"1_synth\",1224065678,\"1_synth\",1288490188,\"1_synth\",1331439861,\"1_synth\",1374389534,\"1_synth\",1417339207,\"1_synth\",1460288880,\"1_synth\",1481763716,\"1_synth\",1503238553,\"1_synth\",1546188226,\"1_synth\",1589137899,\"1_synth\",1610612735,\"1_synth\",1632087571,\"1_synth\",1653562408,\"1_synth\",1675037244,\"1_synth\",1696512081,\"1_synth\",1739461754,\"1_synth\",1760936590,\"1_synth\",1782411427,\"1_synth\",1803886263,\"1_synth\",1825361100,\"1_synth\",1846835936,\"1_synth\",1911260446,\"1_synth\",1954210119,\"1_synth\",1975684955,\"1_synth\",1997159792,\"1_synth\",2018634628,\"1_synth\",2040109465,\"1_synth\",2061584301,\"1_synth\",2083059138,\"1_synth\",2104533974,\"1_synth\",2126008811,\"1_synth\",4294967295,\"1_synth\"]},\"STYLN_synth_voice_app\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"STYLN_synth_voice_app3\",472446402,\"1_synth\",515396075,\"1_synth\",601295420,\"1_synth\",665719930,\"1_synth\",708669603,\"1_synth\",773094112,\"1_synth\",837518622,\"1_synth\",901943131,\"1_synth\",944892804,\"1_synth\",1009317314,\"1_synth\",1052266987,\"1_synth\",1116691496,\"1_synth\",1159641169,\"1_synth\",1202590842,\"1_synth\",1267015351,\"1_synth\",1331439861,\"1_synth\",1417339207,\"1_synth\",1460288880,\"1_synth\",1524713389,\"1_synth\",1567663062,\"1_synth\",1610612735,\"1_synth\",1653562408,\"1_synth\",1696512081,\"1_synth\",1717986917,\"1_synth\",1760936590,\"1_synth\",1803886263,\"1_synth\",1825361100,\"1_synth\",1846835936,\"1_synth\",1868310773,\"1_synth\",1889785609,\"1_synth\",1911260446,\"1_synth\",1932735282,\"1_synth\",1954210119,\"1_synth\",1975684955,\"1_synth\",1997159792,\"1_synth\",2018634628,\"1_synth\",2040109465,\"1_synth\",2061584301,\"1_synth\",2083059138,\"1_synth\",2104533974,\"1_synth\",2126008811,\"1_synth\",4294967295,\"1_synth\"]}]},\"STYLN_LIVE_USER_STATE_API_SWITCH\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"STYLN_LIVE_USER_STATE_API_SWITCH\",4294967295,null]},\"SP_ReqToComRollout_Web\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SP_ReqToComRollout_Web\",4294967295,\"0_Off\"]},\"SP_RepReplyV2_0624\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"ACO_CommentsHoldoutRegi_0624\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"SP_RepReplyV2_0624\",4294967295,\"2_Blue\"]}]},\"SJ_open_in_app_regiwall_0724\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SJ_open_in_app_regiwall_0724\",2147483647,\"1_open_in_app_regiwall\",4294967295,\"1_open_in_app_regiwall\"]},\"SJ_disrupter_V2_increased_cadence\":{\"if\":[{\"and\":[{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"SJ_disrupter_V2_increased_cadence\",4294967295,\"2_high_intensity\"]}]},\"SHA_TooltipWeb_1224\":{\"abtest_partition\":[{\"var\":\"regi_id\"},\"SHA_TooltipWeb_1224\",429496729,\"0_Control\",858993458,\"1_Value\",1288490188,\"2_Awareness\",1717986917,\"3_Connection\"]},\"SHA_LiveNativeShare_1024\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SHA_LiveNativeShare_1024\",4294967295,\"1_Native\"]},\"SHA_ElectionAppPromo_1024\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SHA_ElectionAppPromo_1024\",4294967295,\"1_Download\"]},\"SHA_cardShare_0424\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SHA_cardShare_0424\",4294967295,\"1_Share\"]},\"SEO_spanishSearchTranslation_0824\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SEO_spanishSearchTranslation_0824\",4294967295,null]},\"SEO_langInputSearchBar_0824\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"SEO_langInputSearchBar_0824\",4294967295,\"1_Rollout\"]},\"PERSX_electionNLSignup_0926\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"PERSX_electionNLSignup_0926\",4294967295,\"1_Variant\"]},\"ON_news_upsell_sale\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"ON_news_upsell_sale\",3865470565,\"1_news_upsell\",4294967295,\"1_news_upsell\"]},\"OMA_WEB_LIBRARY_OPS_HARDCODED_FALLBACK\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_WEB_LIBRARY_OPS_HARDCODED_FALLBACK\",1073741823,null]},\"OMA_TIMEOUTROLLOUT_062024\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_TIMEOUTROLLOUT_062024\",4294967295,\"on\"]},\"OMA_TermsOfService_0624\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_TermsOfService_0624\",214748364,\"1_Variant\",429496729,\"1_Variant\",4294967295,\"1_Variant\"]},\"OMA_SAMIZDAT_SELECTION_KILL_SWITCH\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_SAMIZDAT_SELECTION_KILL_SWITCH\"]},\"OMA_SAMIZDAT_OPS_KILL_SWITCH\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_SAMIZDAT_OPS_KILL_SWITCH\"]},\"OMA_SAMIZDAT_KILL_SWITCH\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_SAMIZDAT_KILL_SWITCH\"]},\"OMA_FEDERATED_QUERY\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_FEDERATED_QUERY\",64424508,\"on\",85899345,\"on\",107374181,\"on\",128849018,\"on\",150323854,\"on\",171798691,\"on\",193273527,\"on\",214748364,\"on\",236223200,\"on\",257698037,\"on\",279172873,\"on\",300647710,\"on\",322122546,\"on\",343597383,\"on\",365072219,\"on\",386547056,\"on\",408021892,\"on\",429496729,\"on\",450971565,\"on\",472446402,\"on\",493921238,\"on\",515396075,\"on\",536870911,\"on\",558345747,\"on\",579820584,\"on\",601295420,\"on\",773094112,\"on\",1116691496,\"on\",1503238553,\"on\",1717986917,\"on\",1889785609,\"on\",2126008811,\"on\",4294967295,\"on\"]},\"OMA_FASTLY_ROLLOUT_09_24\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_FASTLY_ROLLOUT_09_24\",214748364,\"1_fastly\",429496729,\"1_fastly\",644245093,\"1_fastly\",858993458,\"1_fastly\",1288490188,\"1_fastly\",1717986917,\"1_fastly\",2576980377,\"1_fastly\",3435973836,\"1_fastly\",3865470565,\"1_fastly\",4294967295,\"1_fastly\"]},\"OMA_DVSP_ROLLOUT\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_DVSP_ROLLOUT\",4294967295,\"on\"]},\"OMA_DISABLE_USER_STATE_HYBRID\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"OMA_DISABLE_USER_STATE_HYBRID\",1073741823,\"enabled\",4294967295,\"enabled\"]},\"MX_Turn_Off_CAPI_0324\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"MX_Turn_Off_CAPI_0324\",4294967295,\"0_no_capi\"]},\"MX_NewArchitecture_gateway\":{\"if\":[{\"and\":[{\"===\":[{\"ref\":\"MX_NewArchitecture_MeterReal\"},\"1_variant\"]}]},{\"abtest_partition\":[{\"var\":\"agent_id\"},\"MX_NewArchitecture_gateway\",21474835,\"1_variant\",107374181,\"1_variant\",1073741823,\"1_variant\",1116691496,\"1_variant\",1159641169,\"1_variant\",1267015351,\"1_variant\",1503238553,\"1_variant\",1717986917,\"1_variant\",1932735282,\"1_variant\",2126008811,\"1_variant\",4294967295,\"1_variant\"]}]},\"MX_FF_WELCOME_AD\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"MX_FF_WELCOME_AD\",4294967295,\"1_Variant\"]},\"GUAC_GROWTH_EXISTING_SUBS_BAR1_SPLIT\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"84bd05a9-a853-4748-90ac-cefc321921e3\",858993458,\"v7\",1288490188,\"v7\",4294967295,\"v7\"]},\"DFP_Prebid_0624\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"DFP_Prebid_0624\",4294967295,\"1_Criteo\"]},\"CONV_TA_PLOPRO\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"eed2c0d2-b7ab-44cd-aeee-fe6ddf49b5e0\",1434519076,\"0_control\",2864743185,\"1_value_list\",4294967295,\"2_value_cards\"]},\"CONV_GUAC_PLOPRO_SLAYER_0224\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_PLOPRO_SLAYER_0224\",4294967295,\"1_slayer\"]},\"CONV_GUAC_NewsPaywall_SLAYER_0324\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_NewsPaywall_SLAYER_0324\",4294967295,\"1_Slayer\"]},\"CONV_GUAC_CKLP_ExpressCheckOut_RollOut_0124\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_CKLP_ExpressCheckOut_RollOut_0124\",4294967295,\"1_expresscheckout\"]},\"CONV_GUAC_CK_AA_Intl_AnnualOffer_0524\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_CK_AA_Intl_AnnualOffer_0524\",4294967295,null]},\"CONV_GUAC_AALP_SLAYER_0224\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_AALP_SLAYER_0224\",4294967295,\"1_slayer\"]},\"CONV_GUAC_AALP_HDAnchor_Test_0424\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"CONV_GUAC_AALP_HDAnchor_Test_0424\",1417339207,\"1_anchor\",4294967295,\"1_anchor\"]},\"CONV_GUAC_AADock_SLAYER_0324\":{\"abtest_partition\":[{\"var\":\"regi_id\"},\"CONV_GUAC_AADock_SLAYER_0324\",4294967295,\"1_slayer\"]},\"CONV_GAMES_GUAC_PRO_REMOVED_TEST\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"70610249-c5a4-4001-9df1-a622b81db68a\",4294967295,\"1_pro_removed\"]},\"CONV_Bar1_Mobile_Redesign\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"8b752cfb-975e-4b44-abf3-b3e86c4c6682\",4294967295,\"1_variant\"]},\"AMS_FrictionCircumventionMobile_cwv\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"AMS_FrictionCircumventionMobile_cwv\",14315125,\"2_low-mid-truncation\",214726889,\"2_low-mid-truncation\",243357141,\"2_low-mid-truncation\",257672267,\"2_low-mid-truncation\",271987393,\"2_low-mid-truncation\",286302519,\"2_low-mid-truncation\",300617645,\"2_low-mid-truncation\",314932771,\"2_low-mid-truncation\",329247897,\"2_low-mid-truncation\",343563023,\"2_low-mid-truncation\",357878149,\"2_low-mid-truncation\",372193275,\"2_low-mid-truncation\",386508401,\"2_low-mid-truncation\",400823527,\"2_low-mid-truncation\",415138653,\"2_low-mid-truncation\",429453779,\"2_low-mid-truncation\",443768905,\"2_low-mid-truncation\",558289913,\"2_low-mid-truncation\",830277307,\"2_low-mid-truncation\",1259731087,\"2_low-mid-truncation\",4294967295,\"2_low-mid-truncation\"]},\"AMS_FrictionCircumventionDesktop_cwv\":{\"abtest_partition\":[{\"var\":\"agent_id\"},\"AMS_FrictionCircumventionDesktop_cwv\",14315125,\"2_low-mid-truncation\",214726889,\"2_low-mid-truncation\",243357141,\"2_low-mid-truncation\",257672267,\"2_low-mid-truncation\",271987393,\"2_low-mid-truncation\",286302519,\"2_low-mid-truncation\",300617645,\"2_low-mid-truncation\",314932771,\"2_low-mid-truncation\",329247897,\"2_low-mid-truncation\",343563023,\"2_low-mid-truncation\",357878149,\"2_low-mid-truncation\",372193275,\"2_low-mid-truncation\",386508401,\"2_low-mid-truncation\",400823527,\"2_low-mid-truncation\",415138653,\"2_low-mid-truncation\",429453779,\"2_low-mid-truncation\",443768905,\"2_low-mid-truncation\",458084031,\"2_low-mid-truncation\",644180669,\"2_low-mid-truncation\",844592433,\"2_low-mid-truncation\",1245415961,\"2_low-mid-truncation\",4294967295,\"2_low-mid-truncation\"]},\"ACCT_TEMPLATIZED_DOCK_1224\":{\"abtest_partition\":[{\"var\":\"regi_id\"},\"ACCT_TEMPLATIZED_DOCK_1224\",2147483647,\"0_Control\",4294967295,\"1_Templatized_Dock\"]},\"AA_OnboardingFlow_MVPFlowAppSequence_WebandApp_V1\":{\"if\":[{\"and\":[{\"regex_match\":[{\"var\":\"user_entitlements\"},\"(^|\\\\W)MM($|\\\\W)\"]},{\"regex_match\":[{\"var\":\"user_entitlements\"},\"(^|\\\\W)CKG($|\\\\W)\"]},{\"regex_match\":[{\"var\":\"user_entitlements\"},\"(^|\\\\W)ATH($|\\\\W)\"]},{\"regex_match\":[{\"var\":\"user_entitlements\"},\"(^|\\\\W)WC($|\\\\W)\"]},{\"regex_match\":[{\"var\":\"user_entitlements\"},\"(^|\\\\W)XWD($|\\\\W)\"]},{\"!\":{\"in\":[{\"ref\":\"SUBX_regi_alloc_holdout_2024H1\"},[\"0_holdout\"]]}},{\"!==\":[{\"var\":\"app_version\"},\"10.44.0\"]}]},{\"abtest_partition\":[{\"var\":\"regi_id\"},\"AA_OnboardingFlow_MVPFlowAppSequence_WebandApp_V1\",773094112,\"2_appLater\",1275605286,\"2_appLater\",1346472246,\"2_appLater\",1360645638,\"2_appLater\",1374819030,\"2_appLater\",1388992423,\"2_appLater\",1403165815,\"2_appLater\",4294967295,\"2_appLater\"]}]}},\"abraURL\":\"https://a1.nyt.com/abra-config/current/vi-prd.json\"}]); })();;(function () { var _f=function(e,r){var t=window.vi&&window.vi.webviewEnvironment&&window.vi.webviewEnvironment.isPreloaded;function n(){var n,s,o=e.url;try{n=JSON.parse(e.body)}catch(e){return void console.error(\"Error parsing body:\",e)}try{var i=window.location.search.slice(1).split(\"&\").reduce(function(e,r){return\"ip-override\"===r.split(\"=\")[0]?\"?\"+r:e},\"\");o+=i}catch(e){console.warn(e)}function a(r,n,s,o){var i=new XMLHttpRequest;for(var a in i.withCredentials=!0,i.open(r,n,!0),i.setRequestHeader(\"Content-Type\",\"application/json\"),i.setRequestHeader(\"Accept\",\"application/json\"),t&&(i.setRequestHeader(\"NYT-User-Token\",window.getNativeBridgeCookie(\"NYT-S\")),i.setRequestHeader(\"NYT-Agent-ID\",window.getNativeBridgeCookie(\"nyt-a\"))),e.headers)i.setRequestHeader(a,e.headers[a]);i.onreadystatechange=function(){i.readyState===XMLHttpRequest.DONE&&o(i)},i.send(s?JSON.stringify(s):null),window.userXhrObject=i}function d(e){var t;if(200===e.status)try{var s=JSON.parse(e.responseText);!s.data&&s.errors&&s.errors.length>0&&\"PersistedQueryNotFound\"===s.errors[0].message&&(console.warn(\"Persisted query not found for GET request.\"),t={operationName:n.operationName,query:n.query,extensions:{persistedQuery:{version:1,sha256Hash:r}},variables:n.variables},a(\"POST\",o,t,function(e){200!==e.status&&console.warn(\"POST request failed:\",e.status,e.statusText)}))}catch(e){console.warn(\"Error processing response:\",e)}else console.warn(\"Request failed:\",e.status,e.statusText)}s=\"extensions=\"+encodeURIComponent(JSON.stringify({persistedQuery:{version:1,sha256Hash:r}}))+\"&operationName=\"+n.operationName+\"&variables=\"+encodeURIComponent(JSON.stringify(n.variables)),a(\"GET\",o+\"?\"+s,null,d)}t&&!window.nativeBridgeCookies?window.initNativeBridgeCookies(function(){n()}):n(),window.userXhrRefresh=function(){return n(),window.userXhrObject}};;_f.apply(null, [{\"url\":\"https://samizdat-graphql.nytimes.com/graphql/v2\",\"body\":\"{\\\"operationName\\\":\\\"UserQuery\\\",\\\"variables\\\":{},\\\"query\\\":\\\"   query UserQuery {     user {       __typename       profile {         displayName         email         givenName       }       newsletterSubscriptions {         newsletters {           productCode           isFreeTrial           freeTrialSignupTime         }       }       userInfo {         regiId         entitlements         demographics {           emailSubscriptions           wat         }       }       subscriptionDetails {         bundleType         cancellationDate         graceStartDate         graceEndDate         isFreeTrial         hasQueuedSub         startDate         endDate         status         hasActiveEntitlements         entitlements         billingSource         promotionTierType         subscriptionName         subscriptionProducts         subscriptionLabels       }     }   } \\\"}\",\"headers\":{\"nyt-app-type\":\"project-vi\",\"nyt-app-version\":\"0.0.5\",\"nyt-token\":\"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+/oUCTBmD/cLdmcecrnBMHiU/pxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB\",\"x-nyt-targeting-dimensions-map\":\"newsTenure=anon_user\"}},\"18b49c689a1a1dda8e2237a503fe06644b44b0f5ca7b1e821a310d9ea9b64bd9\"]); })();;(function () { var registry=window._interactiveRegistry={};function getId(e){for(;(e=e.parentElement)&&!e.matches(\"[data-sourceid].interactive-body\"););return e?e.getAttribute(\"data-sourceid\"):null}window.registerInteractive=function(e){var t={_subs:{cleanup:[],remount:[]},id:e,on:function(e,r){return this._subs[e].push(r),t},errorFound:!1},r=document.getElementById(\"embed-id-\"+e),n=new MutationObserver(function(){(r.textContent.includes(\"500 Internal Error\")||r.textContent.includes(\"200 undefined\"))&&(t.errorFound||(window.dispatchEvent(new CustomEvent(\"trigger-embed-hydration-\"+e)),window.Sentry&&window.Sentry.captureException&&window.Sentry.captureException(new Error(\"Embed load error, triggered manual rehydration: \"+e)),t.errorFound=!0))});r&&n.observe(r,{characterData:!0,attributes:!1,childList:!0,subtree:!0}),registry[e]=t},window.getInteractiveBridge=function(e){var t=\"string\"==typeof e?e:getId(e);return registry[t]}; })();;(function () { var _f=function(){\"function\"!=typeof window.onInitNativeAds&&(window.onInitNativeAds=function(){})};;_f.apply(null, []); })();\n",
      "    </script>\n",
      "    <script>!function(){try{var e=\"undefined\"!=typeof window?window:\"undefined\"!=typeof global?global:\"undefined\"!=typeof self?self:{},n=(new Error).stack;n&&(e._sentryDebugIds=e._sentryDebugIds||{},e._sentryDebugIds[n]=\"e93897a9-f8b4-4749-a2b0-4306f30b7583\",e._sentryDebugIdIdentifier=\"sentry-dbid-e93897a9-f8b4-4749-a2b0-4306f30b7583\")}catch(e){}}();var _global=\"undefined\"!=typeof window?window:\"undefined\"!=typeof global?global:\"undefined\"!=typeof self?self:{};_global.SENTRY_RELEASE={id:\"74e0f0702bdea699e5b8f969d4a04ef588eead6b\"},function(e){function n(n){for(var r,a,u=n[0],l=n[1],i=n[2],s=0,p=[];s<u.length;s++)a=u[s],Object.prototype.hasOwnProperty.call(o,a)&&o[a]&&p.push(o[a][0]),o[a]=0;for(r in l)Object.prototype.hasOwnProperty.call(l,r)&&(e[r]=l[r]);for(d&&d(n);p.length;)p.shift()();return f.push.apply(f,i||[]),t()}function t(){for(var e,n=0;n<f.length;n++){for(var t=f[n],r=!0,u=1;u<t.length;u++){var l=t[u];0!==o[l]&&(r=!1)}r&&(f.splice(n--,1),e=a(a.s=t[0]))}return e}var r={},o={155:0},f=[];function a(n){if(r[n])return r[n].exports;var t=r[n]={i:n,l:!1,exports:{}};return e[n].call(t.exports,t,t.exports,a),t.l=!0,t.exports}a.m=e,a.c=r,a.d=function(e,n,t){a.o(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:t})},a.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},a.t=function(e,n){if(1&n&&(e=a(e)),8&n)return e;if(4&n&&\"object\"==typeof e&&e&&e.__esModule)return e;var t=Object.create(null);if(a.r(t),Object.defineProperty(t,\"default\",{enumerable:!0,value:e}),2&n&&\"string\"!=typeof e)for(var r in e)a.d(t,r,function(n){return e[n]}.bind(null,r));return t},a.n=function(e){var n=e&&e.__esModule?function(){return e.default}:function(){return e};return a.d(n,\"a\",n),n},a.o=function(e,n){return Object.prototype.hasOwnProperty.call(e,n)},a.p=\"/vi-assets/static-assets/\";var u=window.webpackJsonp=window.webpackJsonp||[],l=u.push.bind(u);u.push=n,u=u.slice();for(var i=0;i<u.length;i++)n(u[i]);var d=l;t()}([]);\n",
      "//# sourceMappingURL=runtime~adslot-9b0c6993a5266257a85c.js.map</script>\n",
      "    <script async src=\"/vi-assets/static-assets/adslot-59d16b27033c19666568.js\"></script>\n",
      "    <script data-rh=\"true\" >\n",
      "          (function () { var _f=function(){const n=\"1_block\";function o(n){return window&&window.NYTD&&window.NYTD.Abra?window.NYTD.Abra(n):\"\"}window.adClientUtils={hasActiveToggle:function(r){return o(r)!==n},getAbraVar:o,reportExposure:function(n){window&&window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.reportExposure&&window.NYTD.Abra.reportExposure(n)},getAdsPurrDirective:function(){let n;if(window&&window.config&&window.config.PurrDirectives)n=window.config.PurrDirectives.PURR_AdConfiguration_v3;else{const o={f:\"full\",r:\"rdp\",n:\"npa\",l:\"ltd\",s:\"adluce-socrates\",a:\"no-ads\"},r=function(n){if(\"string\"!=typeof n)return\"\";const o=document.cookie.match(new RegExp(n.concat(\"=([^;]+)\")));return o?o[1]:\"\"}(\"nyt-purr\");n=o[r&&r.substring(14,15)]}return n}}};;_f.apply(null, []); })();\n",
      "          (function () { var _f=function(t){try{if(!(e=t,!!(window&&window.adClientUtils&&window.adClientUtils.hasActiveToggle)&&window.adClientUtils.hasActiveToggle(e)))return;!function(){const t=window&&window.adClientUtils&&window.adClientUtils.getAdsPurrDirective?window.adClientUtils.getAdsPurrDirective():\"\";if(\"adluce-socrates\"!==t&&\"no-ads\"!==t){var e=document.createElement(\"script\");e.async=\"async\",e.src=\"ltd\"===t?\"//pagead2.googlesyndication.com/tag/js/gpt.js\":\"//securepubads.g.doubleclick.net/tag/js/gpt.js\",document.head.appendChild(e)}}()}catch(t){console.log(t)}var e};;_f.apply(null, [\"dfp_story_toggle\"]); })();\n",
      "          (function () { var _f=function(){var t,e,o=50,n=50;function i(t){if(!document.getElementById(\"3pCheckIframeId\")){if(t||(t=1),!document.body){if(t>o)return;return t+=1,setTimeout(i.bind(null,t),n)}var e,a,r;e=\"https://static01.nyt.com/ads/tpc-check.html\",a=document.body,(r=document.createElement(\"iframe\")).src=e,r.id=\"3pCheckIframeId\",r.style=\"display:none;\",r.height=0,r.width=0,a.insertBefore(r,a.firstChild)}}function a(t){if(\"https://static01.nyt.com\"===t.origin)try{\"3PCookieSupported\"===t.data&&googletag.cmd.push(function(){googletag.pubads().setTargeting(\"cookie\",\"true\")}),\"3PCookieNotSupported\"===t.data&&googletag.cmd.push(function(){googletag.pubads().setTargeting(\"cookie\",\"false\")})}catch(t){}}function r(){if(function(){if(Object.prototype.toString.call(window.HTMLElement).indexOf(\"Constructor\")>0)return!0;if(\"[object SafariRemoteNotification]\"===(!window.safari||safari.pushNotification).toString())return!0;try{return window.localStorage&&/Safari/.test(window.navigator.userAgent)}catch(t){return!1}}()){try{window.openDatabase(null,null,null,null)}catch(e){return t(),!0}try{localStorage.length?e():(localStorage.x=1,localStorage.removeItem(\"x\"),e())}catch(o){navigator.cookieEnabled?t():e()}return!0}}!function(){try{googletag.cmd.push(function(){googletag.pubads().setTargeting(\"cookie\",\"unknown\")})}catch(t){}}(),t=function(){try{googletag.cmd.push(function(){googletag.pubads().setTargeting(\"cookie\",\"private\")})}catch(t){}}||function(){},e=function(){window.addEventListener(\"message\",a,!1),i(0)}||function(){},function(){if(window.webkitRequestFileSystem)return window.webkitRequestFileSystem(window.TEMPORARY,1,e,t),!0}()||r()||function(){if(!window.indexedDB&&(window.PointerEvent||window.MSPointerEvent))return t(),!0}()||e()};;_f.apply(null, [\"dfp_story_toggle\"]); })();\n",
      "        </script><script data-rh=\"true\" id=\"als-svc\">(function () { var _f=function(e,t,n,i){function l(e,t=\"impression\"){window.UnifiedTracking&&window.UnifiedTracking.sendAnalytic&&window.UnifiedTracking.sendAnalytic(t,e)}var o;if(!(o=n,!!(window&&window.adClientUtils&&window.adClientUtils.hasActiveToggle)&&window.adClientUtils.hasActiveToggle(o)))return;!function(e){window&&window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.reportExposure(e)}(n);let a=()=>{var e=new Date,t=e.getFullYear();return e.getMonth()<9&&(t+=\"0\"),t+=e.getMonth()+1,e.getDate()<10&&(t+=\"0\"),t+=e.getDate(),e.getHours()<10&&(t+=\"0\"),t+=e.getHours(),e.getMinutes()<10&&(t+=\"0\"),t+=e.getMinutes(),e.getSeconds()<10&&(t+=\"0\"),t+e.getSeconds()};window.googletag=window.googletag||{},googletag.cmd=googletag.cmd||[];let s=new URLSearchParams(location.search).get(\"alice_rules_test\");var r,d=new XMLHttpRequest,g=window.vi.env.ALS_URL,c=document.querySelector('[name=\"nyt_uri\"]');if(t)r=\"uri=\"+(u=t);else if(\"/\"===location.pathname){var u=encodeURIComponent(\"https://www.nytimes.com/pages/index.html\");r=\"uri=\"+u}else if(void 0===c||\"\"===c||null===c){var m=e||location.protocol+\"//\"+location.hostname+location.pathname;r=\"url=\"+encodeURIComponent(m)}else{u=encodeURIComponent(c.content);r=\"uri=\"+u}var w=i;if(!w){var _=document.querySelector('[name=\"template\"]');w=null==_||null==_.content?\"\":_.content}var p=document.querySelector('[name=\"prop\"]'),b=document.querySelector('[name=\"plat\"]'),f=null==p||null==p.content?\"nyt\":p.content,v=null==b||null==b.content?\"web\":b.content;window.innerWidth<740&&(f=\"mnyt\",v=\"mweb\");var U=window.localStorage.getItem(\"als_test_clientside\"),h=null;window.googletag.cmd.push(function(){var e=U&&0!==U.length?U:\"empty_empty_empty_\"+a(),t=h||e;googletag.pubads().setTargeting(\"als_test_clientside\",t)});var T=window.localStorage.getItem(\"mktg\"),S=null;window.googletag.cmd.push(function(){var e=S||T;e&&googletag.pubads().setTargeting(\"mktg\",e)});var C,y=window.localStorage.getItem(\"bt\");window.googletag.cmd.push(function(){var e=null!=C?C:y;null!=e&&googletag.pubads().setTargeting(\"bt\",e)});var x=window.localStorage.getItem(\"sub\"),k=null;window.googletag.cmd.push(function(){var e=k||x;e&&googletag.pubads().setTargeting(\"sub\",e)}),r=null==s?r:r+\"&alice_rules_test=\"+s,d.open(\"GET\",g+\"/als?\"+r+\"&typ=\"+w+\"&prop=\"+f+\"&plat=\"+v,!0),d.withCredentials=!0,d.send(),d.onerror=function(){var e=\"reqfailed_reqfailed_reqfailed_\"+a();h=e,window.googletag.cmd.push(function(){googletag.pubads().setTargeting(\"als_test_clientside\",e)}),l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-reqfail-\"+r}})},d.onreadystatechange=function(){if(4===d.readyState)if(200===d.status){var e=JSON.parse(d.responseText);h=e.als_test_clientside&&0!==e.als_test_clientside.length?e.als_test_clientside:\"bou_bou_bou_\"+a(),void 0!==e.User&&(void 0!==e.User.mktg&&(S=e.User.mktg,window.localStorage.setItem(\"mktg\",e.User.mktg)),void 0!==e.User.bt&&(C=e.User.bt,window.localStorage.setItem(\"bt\",e.User.bt)),void 0!==e.User.sub&&(k=e.User.sub,window.localStorage.setItem(\"sub\",e.User.sub)),void 0!==e.User.aid&&(server_aid=e.User.aid,window.localStorage.setItem(\"aid\",e.User.aid))),window.googletag.cmd.push(function(){if(e.als_test_clientside&&0!==e.als_test_clientside.length)googletag.pubads().setTargeting(\"als_test_clientside\",e.als_test_clientside),window.localStorage.setItem(\"als_test_clientside\",\"ls-\"+e.als_test_clientside);else{var t=void 0===e.als_test_clientside?\"undefined_undefined_undefined_\"+a():\"blank_blank_blank_\"+a();googletag.pubads().setTargeting(\"als_test_clientside\",t),l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-test-client-undefined\"}})}if(void 0!==e.User){if(S)googletag.pubads().setTargeting(\"mktg\",S);else l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-mktg-undefined\"}});if(void 0!==C)googletag.pubads().setTargeting(\"bt\",C);else l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-bt-undefined\"}});if(k)googletag.pubads().setTargeting(\"sub\",k);else l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-sub-undefined\"}});(e.User.lucidC1||e.User.lucidC2||e.User.lucidC3||e.User.lucidC4||e.User.lucidC5)&&l({c1_val:e.User.lucidC1,c2_val:e.User.lucidC2,c3_val:e.User.lucidC3,c4_val:e.User.lucidC4,c5_val:e.User.lucidC5},\"lucidtest\")}else{l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-user-undefined\"}})}if(void 0!==e.Asset)for(var n in e.Asset){var i=e.Asset[n];if(i)googletag.pubads().setTargeting(n,i);else l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-\"+n+\"-undefined\"}})}else l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-asset-undefined\"}})})}else{d.responseText.substring(0,40);var t=\"error_\"+d.status+\"_error_\"+a();window.googletag.cmd.push(function(){googletag.pubads().setTargeting(\"als_test_clientside\",t)}),l({module:{name:\"alice-timing\",context:\"script-load\",label:\"alice-error-ajaxreq-\"+d.status+\"-\"+r}})}}};;_f.apply(null, [null,null,\"als_toggle\",\"art\"]); })();</script><script data-rh=\"true\" id=\"adslot-config\">(function() {\n",
      "            var AdSlot4=function(){\"use strict\";var e=function(){return window.AdSlot4=window.AdSlot4||{},window.AdSlot4.cmd=window.AdSlot4.cmd||[],window.AdSlot4};var t=function(){return t=Object.assign||function(e){for(var t,n=1,i=arguments.length;n<i;n++)for(var o in t=arguments[n])Object.prototype.hasOwnProperty.call(t,o)&&(e[o]=t[o]);return e},t.apply(this,arguments)};\"function\"==typeof SuppressedError&&SuppressedError;var n=[{name:\"PURR_AcceptableTrackers\",valueMapping:{controllers:\"c\",processors:\"p\"}},{name:\"PURR_AdConfiguration\",valueMapping:{full:\"f\",npa:\"n\",\"adluce-socrates\":\"s\"}},{name:\"PURR_DataSaleOptOutUI\",valueMapping:{hide:\"h\",show:\"s\"}},{name:\"PURR_DataProcessingConsentUI\",valueMapping:{hide:\"h\",show:\"s\"}},{name:\"PURR_AcceptableTrackers_v2\",valueMapping:{controllers:\"c\",processors:\"p\",essentials:\"e\"}},{name:\"PURR_AdConfiguration_v2\",valueMapping:{full:\"f\",rdp:\"r\",npa:\"n\",adluce:\"a\",\"adluce-socrates\":\"s\"}},{name:\"PURR_DataProcessingPreferenceUI\",valueMapping:{hide:\"h\",\"allow-opt-out\":\"o\",\"allow-opt-in\":\"i\",\"allow-opt-in-or-out\":\"a\"}},{name:\"PURR_DataSaleOptOutUI_v2\",valueMapping:{hide:\"h\",show:\"s\",\"show-opted-out\":\"o\"}},{name:\"PURR_CaliforniaNoticesUI\",valueMapping:{hide:\"h\",show:\"s\"}},{name:\"PURR_EmailMarketingOptInUI\",valueMapping:{checked:\"c\",unchecked:\"u\"}},{name:\"PURR_DeleteIPAddress\",valueMapping:{delete:\"d\",keep:\"k\"}},{name:\"PURR_AdConfiguration_v3\",valueMapping:{full:\"f\",rdp:\"r\",npa:\"n\",ltd:\"l\",\"adluce-socrates\":\"s\"}},{name:\"PURR_LimitSensitivePI\",valueMapping:{hide:\"h\",show:\"s\"}},{name:\"PURR_EmailMarketingOptInUI_v2\",valueMapping:{checked:\"c\",unchecked:\"u\",\"do-not-display\":\"d\"}},{name:\"PURR_AdConfiguration_v4\",valueMapping:{full:\"f\",rdp:\"r\",npa:\"n\",ltd:\"l\",\"adluce-socrates\":\"s\",\"no-ads\":\"a\"}}],i=function(e){return-1!==document.cookie.indexOf(e)},o=function(e){var t,i,o={PURR_AcceptableTrackers:0,PURR_AdConfiguration:5,PURR_DataSaleOptOutUI:2,PURR_DataProcessingConsentUI:3,PURR_AcceptableTrackers_v2:4,PURR_AdConfiguration_v2:5,PURR_DataProcessingPreferenceUI:6,PURR_DataSaleOptOutUI_v2:7,PURR_CaliforniaNoticesUI:8,PURR_EmailMarketingOptInUI:9,PURR_DeleteIPAddress:10,PURR_AdConfiguration_v3:11,PURR_LimitSensitivePI:12,PURR_EmailMarketingOptInUI_v2:13,PURR_AdConfiguration_v4:14},r=(t=e,2===(i=\"; \".concat(document.cookie).split(\"; \".concat(t,\"=\"))).length?i.pop().split(\";\").shift():null),a={};return Object.keys(o).forEach((function(e){var t,n,i;a[e]=(t=r,n=new RegExp(\"^.{\".concat(o[e],\"}(.)\")),(null==(i=t.match(n))?void 0:i[1])||\"\")})),n.forEach((function(e){Object.keys(e.valueMapping).forEach((function(t){e.valueMapping[t]===a[e.name]&&(a[e.name]=t)}))})),a},r={PURR_DataSaleOptOutUI:\"hide\",PURR_DataSaleOptOutUI_v2:\"hide\",PURR_CaliforniaNoticesUI:\"hide\",PURR_DataProcessingConsentUI:\"hide\",PURR_DataProcessingPreferenceUI:\"hide\",PURR_AcceptableTrackers_v2:\"controllers\",PURR_AcceptableTrackers:\"controllers\",PURR_AdConfiguration_v2:\"full\",PURR_AdConfiguration:\"full\",PURR_EmailMarketingOptInUI:\"unchecked\",PURR_DeleteIPAddress:\"delete\",PURR_AdConfiguration_v3:\"full\",PURR_LimitSensitivePI:\"hide\",PURR_EmailMarketingOptInUI_v2:\"unchecked\",PURR_AdConfiguration_v4:\"full\"},a=function(){var e;try{return function(){if(\"undefined\"!=typeof window){var e=window.navigator.userAgent||window.navigator.vendor,t=-1!==e.indexOf(\"nyt_android\"),n=-1!==e.indexOf(\"nytios\"),i=-1!==e.indexOf(\"nyt_xwords_ios\"),o=-1!==e.indexOf(\"Crosswords\");return t||n||i||o}return!1}()?(null===(e=null===window||void 0===window?void 0:window.config)||void 0===e?void 0:e.PurrDirectives)?window.config.PurrDirectives:i(\"override-purr\")?o(\"override-purr\"):t({},r):i(\"nyt-purr\")?o(\"nyt-purr\"):t({},r)}catch(e){return console.warn(\"can’t get directives from cookie or config\",e),t({},r)}},d=function(){var e={};return\"undefined\"!=typeof window&&window.document&&window.document.createElement&&(e=a().PURR_AdConfiguration_v3||a().PURR_AdConfiguration_v2),e};var s=function(){return\"full\"===d()};function c(e,t,n){var i=document.getElementsByTagName(\"head\")[0],o=document.createElement(\"script\");t&&(o.onload=t),n&&(o.onerror=n),o.src=e,o.async=!0,i.appendChild(o)}var u={32074718:!0,4792640386:!0,21966278:!0,4558311760:!0,4552626466:!0,4400775978:!0,39318518:!0,4874174581:!0,33597638:!0,38636678:!0,38637278:!0,33597998:!0,33613118:!0,30252878:!0,33597758:!0,5154427359:!0},l=\"script_loader_error\",p=function(){e().cmd.push((function(){var t=\"\".concat(\"GeoEdge\",\" failed to load\");e().events.publish({name:l,value:{message:t}})}))},m=function(){return!window.grumi&&(c(\"//rumcdn.geoedge.be/b3960cc6-bfd2-4adc-910c-6e917e8a6a0e/grumi-ip.js\",null,p),window.grumi={key:\"b3960cc6-bfd2-4adc-910c-6e917e8a6a0e\",cfg:{advs:u}},!0)},f=\"A9\",v=[[300,50],[320,50],[300,250],[728,90],[970,90],[970,250]],g=\"large\",w=\"medium\",b=\"small\",_=function(){if(!window.apstag){var e=\"\".concat(f,\" not loading properly\");console.warn(e)}},h=\"BidderError\",R=function(){e().cmd.push((function(){var t=\"\".concat(f,\" failed to load\");e().events.publish({name:h,value:{type:f,message:t}})}))},P=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:window;return e.googletag=e.googletag||{},e.googletag.cmd=e.googletag.cmd||[],e.googletag},y=function(e){return!(!window.apstag||!window.apstag.fetchBids)&&(window.apstag.fetchBids({slots:e},void(window.apstag&&window.apstag.setDisplayBids&&P().cmd.push(window.apstag.setDisplayBids()))),!0)},U=\"AdEmpty\",I=\"AdBlockOn\",A=\"AdDefined\",O=\"AdRefreshed\";function k(e,t,n){return(t=function(e){var t=function(e,t){if(\"object\"!=typeof e||!e)return e;var n=e[Symbol.toPrimitive];if(void 0!==n){var i=n.call(e,t||\"default\");if(\"object\"!=typeof i)return i;throw new TypeError(\"@@toPrimitive must return a primitive value.\")}return(\"string\"===t?String:Number)(e)}(e,\"string\");return\"symbol\"==typeof t?t:t+\"\"}(t))in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function x(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function S(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?x(Object(n),!0).forEach((function(t){k(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):x(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}var D=k(k(k({},g,[[728,90],[970,90],[970,250]]),w,[[728,90],[300,250]]),b,[[300,250]]),j={art:[{id:\"top\",sizes:D},{id:\"mobile_top\",sizes:k({},b,[[300,50],[320,50]])}],hp:[{id:\"dfp-ad-top\",sizes:D}],games:[{id:\"ad-top\",sizes:D},{id:\"intsl\",sizes:D}],default:[{id:\"top\",sizes:D}]},C=function(e,t){var n;return(null==t||null===(n=t.fastFetchSlots)||void 0===n?void 0:n.length)>0?t.fastFetchSlots:j[e]||j.default},z=function(e,t){return e[t]||e[b]},E=function(e,t){var n=[].concat(function(e,t){return[].concat(e).slice().sort((function(e,t){return t[0]-e[0]})).find((function(e){return!Number.isNaN(e[0])&&e[0]<t}))}(e,t)).pop();return n&&n.length?n:null},M=function(e,t,n){return function(){var i=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},o=i.sizes,r=void 0===o?[]:o,a=i.truePosition,d=i.id;if(t&&C(e,n).map((function(e){return e.id})).includes(d))return!1;var s,c=E(r,window.innerWidth),u=(s=c,Array.isArray(s)?v.filter((function(e){return s.some((function(t){return t[0]===e[0]&&t[1]===e[1]}))})):(console.warn(\"filterSizes() did not receive an array\"),[]));if(u.length>0){var l=(null==n?void 0:n.pageName)||e,p=[{slotID:a||d,slotName:\"\".concat(a||d,\"_\").concat(l,\"_web\"),sizes:u}];return y(p),!0}return!1}},T=function(t,n,i){e().cmd.push((function(){var o;t&&y(function(e,t,n){var i=(null==n?void 0:n.pageName)||t;return C(t,n).map((function(t){var o=t.id,r=t.sizes;return{slotID:o,slotName:\"\".concat(o,\"_\").concat(i,\"_web\"),sizes:null!=n&&n.fastFetchSlots?r:z(r,e)}}))}((o=window.innerWidth)>740?g:o>600?w:b,n,i)),e().events.subscribe({name:A,scope:\"all\",callback:M(n,t,i)})}))},N=function(e,t,n,i){var o=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:\"apstag\",t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:window;if(!t[e]){var n=function(n,i){return t[e]._Q.push([n,i])};t[e]={_Q:[],init:function(){n(\"i\",arguments)},fetchBids:function(){n(\"f\",arguments)},setDisplayBids:function(){},targetingKeys:function(){return[]}}}return t[e]}(\"apstag\",window);o.init({pubID:\"3030\",deals:!0,adServer:\"googletag\",params:{si_section:t}}),T(e,n,i)},B={art:{id:[\"mobile_top\",\"top\",\"story-ad-1\",\"story-ad-2\",\"story-ad-3\",\"story-ad-4\",\"story-ad-5\",\"story-ad-6\",\"bottom\"],pos:[\"mobile_top\",\"top\",\"mid1\",\"mid2\",\"mid3\",\"mid4\",\"mid5\",\"mid6\",\"bottom\"]},int:{id:[\"top\",\"mid1\",\"mid2\",\"bottom\"],pos:[\"top\",\"mid1\",\"mid2\",\"bottom\"]},hp:{id:[\"dfp-ad-top\",\"dfp-ad-mid1\",\"dfp-ad-mid2\",\"dfp-ad-mid3\",\"dfp-ad-bottom\"],pos:[\"top\",\"mid1\",\"mid2\",\"mid3\",\"bottom\"]},ss:{id:[\"right-0\",\"right-1\",\"right-2\",\"right-3\"],pos:[\"mid1\",\"mid1\",\"mid1\",\"mid1\"],size:{small:[[300,250]],medium:[[300,250]],large:[[300,250]]}},sf:{id:[\"top\",\"mid1\",\"mid2\"],pos:[\"top\",\"mid1\",\"mid2\"],size:{small:[[300,250]],medium:[[300,250]],large:[[300,250]]}},games:{id:[\"ad-top\",\"ad-mid1\",\"ad-bottom\",\"intsl\"],pos:[\"top\",\"mid1\",\"bottom\",\"intsl\"]},default:{id:[\"top\",\"mid1\",\"mid2\"],pos:[\"top\",\"mid1\",\"mid2\"],size:{small:[[300,250]],medium:[[728,90]],large:[[728,90],[970,90],[970,250]]}}},Y={top:2088370,mid:2088372,bottom:2088374,intsl:3614988,default:2088376},F={top:544112060,mid:544112063,bottom:544112062,intsl:561454180,default:544112065},Q={top:684296214,mid:190706820,bottom:932254072,intsl:868466422,default:153468583},L={top:\"NYTimes_728x90_970_top_PB\",mid:\"NYTimes_728x90_970_mid_PB\",bottom:\"NYTimes_728x90_970_bot_PB\",intsl:\"NYT_mobile_Interstitial_Prebid\",default:\"NYTimes_728x90_970_mid_PB\"},V={top:\"nytimes_top\",mid:\"nytimes_mid\",bottom:\"nytimes_bottom\",intsl:\"6401830\",default:\"nytimes_catchall\"},H={top:\"995821\",mid:\"995822\",bottom:\"995823\",intsl:\"11499610\",default:\"995824\"},K={TOP:\"top\",MID:\"mid\",BOTTOM:\"bottom\",INTSL:\"intsl\"},q={buckets:[{max:3,increment:.05},{max:10,increment:.01},{max:20,increment:.1},{max:50,increment:.5},{max:101,increment:1}]},G=function(e,t){return e[Object.values(K).reduce((function(e,n){return t.includes(n)?n:e}),t)]||e.default},J=function(e,t){var n=arguments.length>2&&void 0!==arguments[2]?arguments[2]:[],i=[{bidder:\"appnexus\",params:{member:3661,invCode:\"nyt_\".concat(e,\"_\").concat(t)}},{bidder:\"criteo\",params:{pubid:\"B7HPLK\",networkId:10470}},{bidder:\"medianet\",params:{cid:\"8CU4WQK98\",crid:G(Q,t)}},{bidder:\"rubicon\",params:{accountId:12330,siteId:\"crosswords\"==e?571306:378266,inventory:{invCode:[\"nyt_\".concat(e,\"_\").concat(t)]},zoneId:G(Y,t),position:\"top\"===t?\"atf\":\"btf\"}},{bidder:\"openx\",params:{unit:G(F,t),delDomain:\"nytimes-d.openx.net\",customParams:{invCode:\"nyt_\".concat(e,\"_\").concat(t)}}},{bidder:\"triplelift\",params:{inventoryCode:G(L,t)}},{bidder:\"pubmatic\",params:{publisherId:\"163427\",adSlot:G(V,t)}},{bidder:\"ix\",params:{siteId:G(H,t)}}],o=i.filter((function(e){return![\"pubmatic\",\"ix\"].includes(e.bidder)}));return n.length?i.filter((function(e){return n.includes(e.bidder)})):o},Z=function(e){var t;switch(e){case\"livebl\":t=\"hp\";break;case\"coll\":t=\"sf\";break;default:t=e}return t in B||(t=\"default\"),t};function W(e,t,n){var i=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},o=i.sizeConfig,r=i.activeBidders,a=i.positionsToFilter,d=void 0===a?[]:a,s=Z(t),c=B[s].size?s:\"default\";return B[s].pos.reduce((function(t,i,a){var u;if(d.includes(i))return t;var l=B[s].id[a],p=S(S({},B[c].size),null==o||null===(u=o[l])||void 0===u?void 0:u.size),m=function(e,t){if(!t||\"\"===t)return{};var n=\"\".concat(t,\"/\").concat(e);return{ortb2Imp:S(S({},\"intsl\"===e&&{instl:1}),{},{ext:{gpid:n,data:{pbadslot:n}}})}}(l,n),f=S(S({code:l},m),{},{mediaTypes:{banner:{sizeConfig:[{minViewPort:[970,0],sizes:p.large},{minViewPort:[728,0],sizes:p.medium},{minViewPort:[0,0],sizes:p.small}]}},bids:J(e,i,r)});return t.push(f),t}),[])}var X=\"PreBid\",$={userSync:{userIds:[{name:\"identityLink\",params:{pid:\"14158\",notUse3P:!0},storage:{type:\"html5\",name:\"idl_env\",expires:15,refreshInSeconds:1800}},{name:\"pairId\",params:{liveramp:{storageKey:\"_lr_pairId\"}}},{name:\"uid2\",params:{serverPublicKey:\"UID2-X-P-MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAEb2nFEsnJ0npRQbsCE7O7IINIMdgu4J29kiA1Hm7GYqfTQAsmqgAQD1YfVkuBR319JpxJYrJzO6Vp73++LTlIwA==\",subscriptionId:\"jCQUsadB4p\"}}],syncDelay:3e3}};var ee=function(t){window.pbjs=window.pbjs||{},window.pbjs.initAdserverSet||(window.pbjs.initAdserverSet=!0,e().cmd.push((function(){e().events.subscribe({name:A,scope:\"all\",callback:function(e){P().cmd.push((function(){var n=function(e){var t=Z(e);return B[t].id}(t);n.includes(e.id)&&window.pbjs.setTargetingForGPTAsync([e.id])}))}})})))},te=function(t,n,i){var o=arguments.length>3&&void 0!==arguments[3]?arguments[3]:{},r=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:window;return e.pbjs=e.pbjs||{},e.pbjs.que=e.pbjs.que||[],e.pbjs}(),a=o.priceGranularity;r.setConfig(S({priceGranularity:a||q},$)),function(t,n,i,o,r){var a=function(e,n){window.pbjs.initAdserverSet=!1,t.requestBids({bidsBackHandler:function(){ee(e)},timeout:n})};e().cmd.push((function(){t.que.push((function(){t.addAdUnits(W(n,i,o,r)),a(i,1e4),e().events.subscribe({name:O,scope:\"all\",callback:function(){a(i,800)}})}))}))}(r,t,n,i,o)},ne=function(){e().cmd.push((function(){var t=\"\".concat(X,\" failed to load\");e().events.publish({name:h,value:{type:X,message:t}})}))},ie=function(e,t,n,i){if(!window.pbjs){return c(\"https://www.nytimes.com/ads/prebid9.26.0.js\",function(e,t,n,i){return function(){window.pbjs||console.log(\"prebid did not load\"),te(e,t,n,i)}}(e,t,n,i),ne),!0}return!1},oe=function(){try{var e=((i=document.createElement(\"div\")).innerHTML=\"&nbsp;\",i.className=\"ad adsbox pub_300x250 pub_300x250m pub_728x90 text-ad textAd text_ad ad-server\",i.style=\"width: 1px !important; height: 1px !important; position: absolute !important; left: -10000px !important; top: -1000px !important;\",document.body.prepend(i),document.getElementsByClassName(\"ad adsbox\")[0]),t=!(!(n=e)||0!==n.offsetHeight&&0!==n.clientHeight)||function(e){if(void 0!==window.getComputedStyle){var t=window.getComputedStyle(e,null);if(t&&(\"none\"===t.getPropertyValue(\"display\")||\"hidden\"===t.getPropertyValue(\"visibility\")))return!0}return!1}(e);return function(e){document.body.removeChild(e)}(e),t}catch(e){console.error(\"ad class check failed\",e)}var n,i;return!1},re=function(){return!(window&&window.AdSlot&&window.AdSlot.AdSlotReady)||(!(window&&window.googletag&&window.googletag.apiReady)||oe())},ae=function(){var e=window&&window.nyt_et&&window.nyt_et.get_host&&window.nyt_et.get_host();return e?fetch(\"\".concat(e,\"/.status\"),{credentials:\"include\",headers:{accept:\"*/*\",\"content-type\":\"text/plain;charset=UTF-8\"},mode:\"no-cors\"}).then((function(){return{success:!0}})).catch((function(e){return console.error(\"et track blocked\",e),{success:!1}})):Promise.resolve({success:!1})};var de,se,ce=function(e,t,n){var i=function(e){if(!document||!document.cookie||!document.cookie.match)return\"\";var t=document.cookie.match(new RegExp(\"\".concat(e,\"=([^;]+)\")));return t?t[1]:\"\"}(\"nyt-a\")||null,o=!!(window&&window.matchMedia&&window.matchMedia(\"(max-width: 739px)\").matches);return\"\".concat(\"https://a-reporting.nytimes.com/report.jpg\",\"?mobile=\").concat(o,\"&block=\").concat(n,\"&aid=\").concat(i,\"&pvid=\").concat(e,\"&et=\").concat(t)},ue=function(e,t,n){return!!(window&&window.NYTD&&window.NYTD.Abra&&\"1_network_detection\"===window.NYTD.Abra(\"DFP_blockDetect_0221\"))&&((new Image).src=ce(e,t,n),!0)},le=function(t,n){n&&e().cmd.push((function(){var t=e();t.events&&t.events.publish({name:U,value:{type:I}})}));var i=!1;return ae().then((function(){i=(arguments.length>0&&void 0!==arguments[0]?arguments[0]:{success:!1}).success})).catch((function(){})).finally((function(){ue(t,i,n)}))},pe=function(e){window.addEventListener(\"load\",function(e){return function(){le(e,re())}}(e))},me=function(){var e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};if(de)return!1;var t,n,i=e.loadAmazon,o=void 0===i||i,r=e.loadPrebid,a=void 0===r||r,d=e.setFastFetch,u=void 0!==d&&d,l=e.loadGeoEdge,p=void 0===l||l,f=e.section,v=void 0===f?\"none\":f,g=e.adUnitPath,w=void 0===g?\"\":g,b=e.pageViewId,h=void 0===b?\"\":b,P=e.pageType,y=void 0===P?\"\":P,U=e.prebidOverrides,I=void 0===U?{}:U,A=e.amazonOverrides,O=void 0===A?{}:A;if(t=document.referrer||\"\",(n=/([a-zA-Z0-9_\\-.]+)(@|%40)([a-zA-Z0-9_\\-.]+).([a-zA-Z]{2,5})/).test(t)||n.test(window.location.href))return!1;if(s()){var k=new RegExp(ar/).test(y)?\"art\":y;p&&m(),o&&function(e,t,n,i){!window.apstag&&(c(\"//c.amazon-adsystem.com/aax2/apstag.js\",_,R),N(e,t,n,i))}(u,v,k,O),a&&ie(v,k,w,I)}return pe(h),de=!0,!0};return(se=e()).loadScripts=se.loadScripts||me,window.AdSlot4=se,se}();\n",
      "            (function () { var _f=function(e={}){const i=window&&window.AdSlot4,t=!!window.adClientUtils.getAbraVar(\"DFP_Prebid_Web_Toggle_0924\"),n=!!window.adClientUtils.getAbraVar(\"DFP_Amzn_Web_Toggle_0924\"),o=window.adClientUtils.getAbraVar(\"DFP_Prebid_0624\"),d=window.vi&&window.vi.webviewEnvironment||{},r=d&&\"IOS\"===d.deviceType&&d.isInWebview;function a(){const e=window.matchMedia(\"(max-width: 739px)\");return e&&e.matches}try{const{adToggleMap:d,pageType:w,prebidOverrides:s,section:c,adUnitPath:l,isSectionThirdPartyEligible:p,setFastFetch:g,headerBidding:b={}}=e,{useAmazon:u,usePrebid:P}=b,T=Object.keys(d).reduce((e,i)=>{const t=d[i]||\"\";return e[i]=function(e){return!!(window&&window.adClientUtils&&window.adClientUtils.hasActiveToggle)&&window.adClientUtils.hasActiveToggle(e)}(t),e},{}),{amazon:A,geoedge:h}=T,v=s&&s.positionsToFilter||[],y=a()?v.concat([\"top\"]):v,_=[\"appnexus\",\"medianet\",\"rubicon\",\"openx\",\"triplelift\",\"ix\",\"pubmatic\"];if(o&&window.adClientUtils.reportExposure(\"DFP_Prebid_0624\"),\"1_Criteo\"===o&&_.push(\"criteo\"),\"function\"==typeof i.loadScripts&&i.loadScripts({loadAmazon:u&&A&&p&&!n,loadPrebid:P&&p&&!t&&!r,setFastFetch:g&&!a(),section:c,adUnitPath:l,prebidOverrides:{...s,positionsToFilter:y,activeBidders:_},pageType:w,pageViewId:window&&window.NYTD&&window.NYTD.PageViewId&&window.NYTD.PageViewId.current?window.NYTD.PageViewId.current:\"\",loadGeoEdge:h}),t&&window.Sentry&&window.Sentry.captureException){const e=new Error(\"Ads are disabled via Abra toggle - Prebid\");window.Sentry.captureException(e)}if(n&&window.Sentry&&window.Sentry.captureException){const e=new Error(\"Ads are disabled via Abra toggle - Amazon\");window.Sentry.captureException(e)}}catch(e){console.error(e)}};;_f.apply(null, [{\"adToggleMap\":{\"amazon\":\"amazon_story_toggle\",\"medianet\":\"medianet_story_toggle\",\"dfp\":\"dfp_story_toggle\",\"geoedge\":\"geoedge_toggle\"},\"pageType\":\"art\",\"section\":\"archives\",\"adUnitPath\":\"/29390238/nyt/archives\",\"isSectionThirdPartyEligible\":true,\"setFastFetch\":true,\"prebidOverrides\":{\"positionsToFilter\":[\"mobile_top\"]},\"headerBidding\":{\"useAmazon\":true,\"usePrebid\":true}}]); })();\n",
      "            (function () { var _f=function(t={},e={},n=\"\"){window.AdSlot4=window.AdSlot4||{},window.AdSlot4.cmd=window.AdSlot4.cmd||[],window.AdSlot4.clientRequirements={mergeObjects:function(t,...e){return e.reduce(function(t,e){return Object.entries(e).reduce(function(t,[e,n]){return t[e]&&null==n?t:Object.assign({},t,{[e]:n})},t)},t)},isFunction:function(t){return\"[object Function]\"===Object.prototype.toString.call(t)},getWebviewEnv:function(){return window.vi&&window.vi.webviewEnvironment||{}},getAbraVariant:function(t){if(!(window.NYTD&&window.NYTD.Abra&&window.NYTD.Abra.getAbraSync&&this.isFunction(window.NYTD.Abra.getAbraSync)))return void console.warn(\"Abra does not exist or is not a function\");const e=window.NYTD.Abra.getAbraSync(t);return e&&e.variant},shouldHaltDFP:function(t){return\"1_block\"===this.getAbraVariant(t)},isAdsDisabled:function(t={}){const{adTargeting:{section:e}={},adsDisabled:n,adUnitPath:i=\"\"}=t,o=i&&i.toLowerCase&&i.toLowerCase().includes(\"tragedy\"),r=!!this.getAbraVariant(\"DFP_GPT_Web_Toggle_0924\");if(r&&window.Sentry&&window.Sentry.captureException){const t=new Error(\"Ads are disabled via Abra toggle\");window.Sentry.captureException(t)}return n||\"learning\"===e||o||r},getSov:function(t={}){return t.sov=t.sov||(Math.floor(4*Math.random())+1).toString(),{sov:t.sov}},getPageViewId:function(t){return{page_view_id:t&&t.current}},getUserData:function(t=\"{}\"){try{const e=JSON.parse(t).data;return e&&e.user}catch(t){console.warn(\"userinfo data unavailable\")}},getEm:function(t){return t&&t.length?{em:t.toString().toLowerCase()}:{}},getWat:function(t){return t?{wat:t.toLowerCase()}:{}},getDemographics:function(t){return this.mergeObjects(this.getEm(t&&t.emailSubscriptions),this.getWat(t&&t.wat))},isValidDfpTest:function(t){return t.toLowerCase().indexOf(\"dfp\")>-1},joinArgumentsForVariant:function(){if(arguments.length)return[].slice.call(arguments).join(\"_\").toLowerCase()},reduceAbraConfigKeysToDfpVariants:function(t=[],e=\"\"){const n=this.getAbraVariant(e),i=this.joinArgumentsForVariant(e,n);return n&&i?t.concat(i):t},reduceFastlyAbraToDfpVariants:function(t=[],[e,n]=[]){const i=this.isValidDfpTest(e)&&n&&this.joinArgumentsForVariant(e,n);return i?t.concat(i):t},getDFPTestNames:function(t={}){if(!t)return[];const e=this.isValidDfpTest;return Object.keys(t).filter(function(t){return e(t)})},getAbraDfpVariants:function(t={},e={}){let n=[],i=[];if(Object.keys(e).length&&(i=Object.entries(e).reduce(this.reduceFastlyAbraToDfpVariants,[])),t.config&&t.getAbraSync){n=this.getDFPTestNames(t.config).reduce(this.reduceAbraConfigKeysToDfpVariants,[])}return{abra_dfp:[...n,...i]}},isMobile:function(t){const e=t.matchMedia(\"(max-width: 739px)\");return e&&e.matches},isManualRefresh:function(t={}){return!(!t.navigation||1!==t.navigation.type)},getAltLangFromPathname:function(t=\"\"){return 0===t.indexOf(\"/es/\")?\"es\":\"\"},getAdTargetingProperty:function(t=!1,e=\"\"){let n=t?\"m\":\"\";return{prop:(n+=e)+\"nyt\"}},getAdTargetingPlatform:function(t=!1){return{plat:(t?\"m\":\"\")+\"web\"}},getAdTargetingEdition:function(t=\"\"){return t.length?{edn:t}:{}},getAdTargetingVersion:function(t=!1){return{ver:(t?\"m\":\"\")+\"vi\"}},getNYTA:function(){var t=window.document.cookie.split(\";\").find(t=>t.includes(\"nyt-a\"))||null;return t&&t.split(\"=\").pop()||null},getHash53:function(t,e){let n=3735928559^e,i=1103547991^e;for(let e,o=0;o<t.length;o++)e=t.charCodeAt(o),n=Math.imul(n^e,2654435761),i=Math.imul(i^e,1597334677);return n=Math.imul(n^n>>>16,2246822507),n^=Math.imul(i^i>>>13,3266489909),i=Math.imul(i^i>>>16,2246822507),4294967296*(2097151&(i^=Math.imul(n^n>>>13,3266489909)))+(n>>>0)},getHashNYTA:function(){var t=this.getNYTA();if(!t)return;let e=this.getHash53(t,64).toString();return e.length<22&&(e=parseInt(e).toString(36)+this.getHash53(t,32).toString(36)+this.getHash53(t,16).toString(36)),e},getPublisherProvidedID:function(){return window.config&&window.config.userInfo&&window.config.userInfo.publisherProvidedID?window.config.userInfo.publisherProvidedID:this.getHashNYTA()},getLazyLoadOffset:function(t){let e=400;if(this.getWebviewEnv().isPreloaded){const n=window.screen&&window.screen.height,i=window.innerHeight,o=\"hp\"===t?8:2;(n||i)&&(e=(n||i)*o)}return e},getAdTargetingHome:function(t,e,n){let i={},o={};return\"hp\"===t&&(i=e?{topRef:e}:{},o=n?{refresh:\"manual\"}:{}),this.mergeObjects(i,o)},getHybridConfigAdTargeting:function(t){let e={};return t&&t.config&&t.config.AdRequirements&&this.getWebviewEnv().isPreloaded&&(e=t.config.AdRequirements,\"hp\"===t.config.AdRequirements.typ&&(delete e.artlen,delete e.ledemedsz)),e},updateAdTargeting:function(t){if(!t)return;let e=t;if(\"string\"==typeof e)try{e=JSON.parse(e)}catch(t){return void console.error(\"[updateAdTargeting - error parsing ad targeting]\",t)}window.AdSlot4&&window.AdSlot4.updateAdReq&&window.AdSlot4.updateAdReq(e)},getAdTargeting:function(t={},n={}){const i=window&&window.NYTD&&window.NYTD.Abra?window.NYTD.Abra:{},o=this.isMobile(window),r=this.getAltLangFromPathname(window.location.pathname),a=this.isManualRefresh(performance);return this.mergeObjects(t,this.getDemographics(n),this.getAdTargetingProperty(o,r),this.getAdTargetingPlatform(o),this.getAdTargetingEdition(r),this.getAdTargetingVersion(o),this.getAdTargetingHome(t.typ,document.referrer,a),this.getAbraDfpVariants(i,e),this.getSov(window),this.getHybridConfigAdTargeting(window),this.getPageViewId(window.NYTD.PageViewId))},testReadyForAds:function(){const t=\"complete\"===document.readyState,e=window.NYTD&&window.NYTD.PageViewId&&window.NYTD.PageViewId.current;return!(!t||!e)},whenReadyForAds:function(t){this.isFunction(t)?this.testReadyForAds()?t():window.addEventListener(\"readyForAds\",t):console.warn(\"whenReadyForAds expects function\")},signalIfReadyForAds:function(){this.testReadyForAds()&&window.dispatchEvent(new CustomEvent(\"readyForAds\",{}))},init:function(t){window.AdSlot4.init&&this.isFunction(window.AdSlot4.init)?window.AdSlot4.init&&window.AdSlot4.init(t):console.warn(\"AdSlot4.init does not exist or is not a function\")},generateConfig:function(t={},e={},n={}){const i=n&&n.userInfo&&n.userInfo.demographics;return this.mergeObjects(t,e,{offset:this.getLazyLoadOffset(e.adTargeting&&e.adTargeting.typ),adTargeting:this.getAdTargeting(e.adTargeting,i),haltDFP:this.shouldHaltDFP(e.dfpToggleName||t.dfpToggleName),adsDisabled:this.isAdsDisabled(e),enablePPID:AdSlot4.clientRequirements.getPublisherProvidedID()})}};for(let t in window.AdSlot4.clientRequirements)window.AdSlot4.clientRequirements[t]=window.AdSlot4.clientRequirements[t].bind(window.AdSlot4.clientRequirements);const i={adUnitPath:\"/29390238/nyt/thisIsNotAPath\",hideTopAd:AdSlot4.clientRequirements.isMobile(window),lockdownAds:!1,sizeMapping:{top:[[970,[\"fluid\",[728,90],[970,90],[970,250],[1605,300]]],[728,[\"fluid\",[728,90],[1605,300]]],[0,[]]],fp1:[[0,[[195,250],[215,270]]]],fp2:[[0,[[195,250],[215,270]]]],fp3:[[0,[[195,250],[215,270]]]],feat1:[[0,[\"fluid\"]]],feat2:[[0,[\"fluid\"]]],feat3:[[0,[\"fluid\"]]],feat4:[[0,[\"fluid\"]]],mktg:[[1020,[300,250]],[0,[]]],pencil:[[728,[[336,46]],[0,[]]]],pp_edpick:[[0,[\"fluid\"]]],pp_morein:[[0,[\"fluid\"],[210,218]]],ribbon:[[0,[\"fluid\"]]],sponsor:[[765,[150,50]],[0,[320,25]]],supplemental:[[1020,[[300,250],[300,600]]],[0,[]]],chat:[[0,[[300,250],[300,420]]]],column:[[0,[[300,250],[300,420]]]],ressint:[[600,[\"fluid\"]],[0,[[300,250]]]],mobile_top:[[0,[[300,50],[320,50]]]],default:[[970,[\"fluid\",[728,90],[970,90],[970,250],[1605,300]]],[728,[\"fluid\",[728,90],[300,250],[1605,300]]],[0,[\"fluid\",[300,250],[300,420]]]]},adTargeting:{},haltDFP:!1,dfpToggleName:t.dfpToggleName,lazyApi:t.lazyApi||{},adsDisabled:!1};window.AdSlot4.cmd.push(function(){const e=window.AdSlot4.clientRequirements,o=e.getUserData(window&&window.userXhrObject&&window.userXhrObject.responseText);if(e.getWebviewEnv().isPreloaded){if(window.updateAdTargeting=e.updateAdTargeting,window.addEventListener(\"load\",e.signalIfReadyForAds),n){window.googletag=window.googletag||{},window.googletag.cmd=window.googletag.cmd||[];const t=\"https://www.nytimes.com\"+n;window.googletag.cmd.push(function(){window.googletag.pubads().set(\"page_url\",t)})}e.whenReadyForAds(function(){const n=e.generateConfig(i,t,o);e.init(n)})}else{const n=e.generateConfig(i,t,o);e.init(n)}})};;_f.apply(null, [{\"adTargeting\":{\"edn\":\"us\",\"test\":\"projectvi\",\"ver\":\"vi\",\"template\":\"article\",\"hasVideo\":\"false\",\"vp\":\"small\",\"typ_materials\":\"#archives#\",\"ledemedsz\":\"none\",\"plat\":\"mweb\",\"typ\":\"art\",\"slug\":\"would\",\"si_section\":\"archives\",\"id\":\"1979010100110993241\",\"bsc\":\"80000200,80222001,80312001,80222008,80312008,80012021,80222006,80312006,80022003,80312022,80222022,80222002,80312002,80022005,80222004,80312004,80222009,80312009,80222010,80312010,80222005,80312005,80222011,80312011,80222014,80312014,80222012,80312012,80122003,80222003,80312003\",\"geo\":\"middleeast\",\"des\":\"israeliarabconflict\",\"artlen\":\"short\",\"section\":\"archives\",\"prop\":\"mnyt\",\"brandsensitive\":\"false\",\"gscat\":\"gs_t\",\"als_test\":\"1736532870245\",\"is_viral_on_social\":\"false\",\"auth\":\"jonathankandell\"},\"adUnitPath\":\"/29390238/nyt/archives\",\"dfpToggleName\":\"dfp_story_toggle\",\"adsDisabled\":false},{\".ver\":\"22839.000\",\"AMS_FrictionCircumventionDesktop_cwv\":\"2_low-mid-truncation\",\"AMS_FrictionCircumventionMobile_cwv\":\"2_low-mid-truncation\",\"DFP_TopAd_Anon_0124\":\"0_Control\",\"HOME_cwv_chartbeat\":\"0_Control\",\"STYLN_synth_voice_web\":\"1_synth\"},\"/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\"]); })();\n",
      "          })();\n",
      "        </script><script data-rh=\"true\" id=\"live-ramp\">(function () { var _f=function(){var e=function(e){var t=document.cookie.match(new RegExp(e+\"=([^;]+)\"));if(t)return t[1]}(\"nyt-purr\"),t=e&&e.substring(14,15)||\"\",a=window.navigator.userAgent.match(/(nyt)[_wd-]*(ios)/i),n=\"atsd\",o=\"_lr_atsDirect\";if(!(e&&\"r\"===t||e&&\"l\"===t||a)){!function(){if(document||document.head){var e=document.createElement(\"link\");e.href=\"https://launchpad.privacymanager.io/latest/launchpad.bundle.js\",e.as=\"script\",document.head.appendChild(e);var t=document.createElement(\"script\");t.async=!1,t.defer=!0,t.src=\"https://launchpad-wrapper.privacymanager.io/9fab0bf6-df63-42ca-acc5-caf4de668f40/launchpad-liveramp.js\",document.head.appendChild(t)}}();var c=function(){var e,t=[];if(-1!==document.cookie.indexOf(o))try{e=(e=(e=document.cookie.split(\";\")).filter(e=>e.includes(o)))[0].split(\"=\")[1],e=atob(decodeURIComponent(e)),t=JSON.parse(e).envelope}catch(e){console.warn(\"Error parsing targeting from cookie.\",e)}return t}();c.length>0&&function(e){window.googletag=window.googletag||{cmd:[]},googletag.cmd.push(()=>{googletag.pubads().setTargeting(n,e)})}(c)}};;_f.apply(null, []); })();</script>\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "  </head>\n",
      "  <body>\n",
      "    <div id=\"app\"><div><div><div class=\"vi-gateway-container\" data-testid=\"vi-gateway-container\"><div><div data-testid=\"masthead-container\" class=\"NYTAppHideMasthead css-1q2w90k e1m0pzr40\"><header class=\"css-1bymuyk e1m0pzr41\"><section class=\"css-7s20nv e1m0pzr42\"><div class=\"css-1f7ibof ea180rp0\"><a class=\"css-kgn7zc\" href=\"#site-content\">Skip to content</a><a class=\"css-kgn7zc\" href=\"#site-index\">Skip to site index</a></div><div class=\"css-10698na ell52qj0\"><a data-testid=\"masthead-mobile-logo\" aria-label=\"New York Times homepage\" class=\"css-ijmohz ell52qj1\" href=\"/\"><svg viewBox=\"0 0 184 25\" fill=\"#000\" aria-hidden=\"true\"><path d=\"M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z\"></path></svg></a></div><div class=\"css-1npft71 e1j3jvdr1\"></div></section><section id=\"masthead-bar-one\" class=\"hasLinks css-c5j6tx e1pjtsj62\"><div><div class=\"css-vfkorq e1pjtsj60\"><span> </span></div><div class=\"css-1bvtpon e1pjtsj61\"><a class=\"css-1pd1msn\" href=\"https://www.nytimes.com/section/todayspaper\">Today’s Paper</a></div></div><div class=\"css-qebcue\"></div></section></header></div></div><div><main id=\"site-content\"><div><div class=\"css-ec8ke8\" style=\"opacity:0.000000001;z-index:-1;visibility:hidden\" id=\"in-story-masthead\"><div class=\"css-1hqnpie\"><div class=\"css-10habuo\"><span class=\"css-rnl02l\">Israelis Decide to Continue Talks With Egypt on Treaty</span></div><div class=\"css-k008qs\"><div class=\"css-b4nnp0\"><a href=\"/\" class=\"css-93zicp\" aria-label=\"New York Times homepage\"><svg viewBox=\"0 0 16 22\"><path d=\"M15.863 13.08c-.687 1.818-1.923 3.147-3.64 3.916v-3.917l2.129-1.958-2.129-1.889V6.505c1.923-.14 3.228-1.609 3.228-3.358C15.45.84 13.32 0 12.086 0c-.275 0-.55 0-.962.14v.14h.481c.824 0 1.51.42 1.51 1.189 0 .63-.48 1.189-1.304 1.189-2.129 0-4.6-1.749-7.279-1.749C2.13.91.481 2.728.481 4.546c0 1.819 1.03 2.448 2.128 2.798v-.14c-.343-.21-.618-.63-.618-1.189 0-.84.756-1.469 1.648-1.469 2.267 0 5.906 1.959 8.172 1.959h.206v2.727l-2.129 1.889 2.13 1.958v3.987c-.894.35-1.786.49-2.748.49-3.502 0-5.768-2.169-5.768-5.806 0-.839.137-1.678.344-2.518l1.785-.769v7.973l3.57-1.608V6.575L3.984 8.953c.55-1.61 1.648-2.728 2.953-3.358v-.07C3.433 6.295 0 9.023 0 13.08c0 4.686 3.914 7.974 8.446 7.974 4.807 0 7.485-3.288 7.554-7.974h-.137z\" fill=\"#000\"></path></svg></a><span class=\"css-18z7m18\"><a href=\"/\" data-testid=\"masthead-logo\" aria-label=\"New York Times homepage\"><svg class=\"css-12fr9lp\" viewBox=\"0 0 184 25\" fill=\"#000\" aria-hidden=\"true\"><path d=\"M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z\"></path></svg></a></span></div><span class=\"css-1n6z4y\">https://www.nytimes.com/1979/01/01/archives/israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html</span><div class=\"css-tvohiw\"><div role=\"toolbar\" data-testid=\"share-tools\" aria-label=\"Social Media Share buttons, Save button, and Comments Panel with current comment count\" class=\"css-yomkvi\"><div></div><div class=\"css-4skfbu\"><ul><li class=\"css-1c5ewvl\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"\" aria-expanded=\"false\" class=\"css-1eeh360 actionbar-button\" data-testid=\"gift-article-button\"><span class=\"css-10d8k1f\"><svg aria-hidden=\"true\" width=\"19\" height=\"19\" viewBox=\"0 0 19 19\"><path d=\"M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z\" fill=\"#121212\" fill-rule=\"nonzero\"></path></svg>Share full article</span></button></div></div></li><li class=\"css-1qy6wq7\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"More sharing options ...\" aria-expanded=\"false\" class=\"css-1nurhyi actionbar-button\"><svg aria-hidden=\"true\" width=\"23\" height=\"18\" viewBox=\"0 0 23 18\" class=\"css-zd9juy\"><path d=\"M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z\" fill=\"#000\" fill-rule=\"nonzero\"></path></svg></button></div></div></li><li class=\"css-1qy6wq7 save-button\"><button type=\"button\" role=\"switch\" class=\"css-1yhvmgx actionbar-button\" data-testid=\"save-article-button\" aria-label=\"Save article for reading later...\" aria-checked=\"false\" disabled=\"\" aria-busy=\"false\" aria-live=\"polite\"><svg width=\"12\" height=\"18\" viewBox=\"0 0 12 18\" class=\"css-eap6fy\"><g fill-rule=\"nonzero\"><path class=\"saved-fill\" d=\"M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z\"></path><path class=\"saved-stroke\" d=\"m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z\"></path></g></svg></button></li></ul></div></div></div></div></div></div><article id=\"story\" class=\"css-1vxca1d e1lmdhsb0\"><div class=\"css-wqhysl\"></div><div id=\"top-wrapper\" class=\"css-1aeqhal\"><div id=\"top-slug\" class=\"css-l9onyx\"><p>Advertisement</p></div><a href=\"#after-top\" class=\"css-777zgl\">SKIP ADVERTISEMENT</a><div class=\"ad top-wrapper css-rfqw0c\"><div id=\"top\" class=\"place-ad\" data-position=\"top\" data-size-key=\"top\" data-lazy-load=\"true\"></div></div><div id=\"after-top\"></div></div><header class=\"css-11kk65x e12qa4dv0\"><div id=\"sponsor-wrapper\" class=\"css-1hyfx7x\"><div id=\"sponsor-slug\" class=\"css-19vbshk\"><p>Supported by</p></div><a href=\"#after-sponsor\" class=\"css-777zgl\">SKIP ADVERTISEMENT</a><div class=\"ad sponsor-wrapper css-rfqw0c\" id=\"sponsor\"></div><div id=\"after-sponsor\"></div></div><div class=\"css-1vkm6nb ehdk2mb0\"><h1 id=\"link-5bf2f917\" class=\"css-r25it4 e1h9rw200\" data-testid=\"headline\">Israelis Decide to Continue Talks With Egypt on Treaty</h1></div><div role=\"toolbar\" data-testid=\"share-tools\" aria-label=\"Social Media Share buttons, Save button, and Comments Panel with current comment count\" class=\"css-yomkvi\"><div></div><div class=\"css-17yegpq\"><ul class=\"css-1atjma0\"><li class=\"css-1c5ewvl\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"\" aria-expanded=\"false\" class=\"css-1eeh360 actionbar-button\" data-testid=\"gift-article-button\"><span class=\"css-10d8k1f\"><svg aria-hidden=\"true\" width=\"19\" height=\"19\" viewBox=\"0 0 19 19\"><path d=\"M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z\" fill=\"#121212\" fill-rule=\"nonzero\"></path></svg>Share full article</span></button></div></div></li><li class=\"css-1qy6wq7\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"More sharing options ...\" aria-expanded=\"false\" class=\"css-1nurhyi actionbar-button\"><svg aria-hidden=\"true\" width=\"23\" height=\"18\" viewBox=\"0 0 23 18\" class=\"css-zd9juy\"><path d=\"M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z\" fill=\"#000\" fill-rule=\"nonzero\"></path></svg></button></div></div></li><li class=\"css-1qy6wq7 save-button\"><button type=\"button\" role=\"switch\" class=\"css-1yhvmgx actionbar-button\" data-testid=\"save-article-button\" aria-label=\"Save article for reading later...\" aria-checked=\"false\" disabled=\"\" aria-busy=\"false\" aria-live=\"polite\"><svg width=\"12\" height=\"18\" viewBox=\"0 0 12 18\" class=\"css-eap6fy\"><g fill-rule=\"nonzero\"><path class=\"saved-fill\" d=\"M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z\"></path><path class=\"saved-stroke\" d=\"m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z\"></path></g></svg></button></li></ul></div></div><div data-testid=\"byline-timestamp\" class=\"css-xt80pu eakwutd0\"><div class=\"css-p6m5rf\"><div class=\"css-1e2jphy epjyd6m2\"><div class=\"css-233int epjyd6m1\"><p class=\"css-4anu6l e1jsehar1\"><span class=\"byline-prefix\">By </span><span class=\"css-1baulvz last-byline\" itemProp=\"name\">Jonathan Kandell;Special to The New York Times</span></p><div class=\"css-1gqes1i epjyd6m0\"></div></div></div><ul class=\"css-1cgskve epjyd6m4\"><li class=\"css-ccw2r3 epjyd6m3\"><time class=\"css-1uc6ajg e16638kd0\" dateTime=\"1979-01-01T00:00:00-05:00\">Jan. 1, 1979</time></li></ul></div></div></header><section name=\"articleBody\" class=\"meteredContent css-1r7ky0e\"><div class=\"css-j3uhc5\"><div class=\"css-1ve50l5\"><div class=\"css-1si6tjw\"><div class=\"css-p5jc4e\"><figure class=\"\" aria-label=\"media\" role=\"group\"><div data-testid=\"imageContainer-children-Image\"><img alt=\"Israelis Decide to Continue Talks With Egypt on Treaty\" class=\"css-rq4mmj\" src=\"https://s1.nyt.com/timesmachine/pages/1/1979/01/01/110993241_360W.png?quality=75&amp;auto=webp&amp;disable=upscale\" srcSet=\"\" decoding=\"async\" width=\"1\" height=\"1\"/></div><figcaption data-testid=\"photoviewer-children-ImageCaption\" class=\"css-ktho12 e3rygrp0\"><span class=\"css-14fe1uy e1z0qqy90\"><span class=\"css-1ly73wi e1tej78p0\">Credit...</span><span><span aria-hidden=\"false\">The New York Times Archives</span></span></span></figcaption></figure></div><div class=\"css-1s1pakw\"><div class=\"css-udpjq9\">See the article in its original context from <br/>January 1, 1979<!-- -->,<!-- --> <!-- --> Page<!-- --> <!-- -->2<span class=\"css-iry6ay\"></span><a class=\"css-4ejn01\" href=\"https://store.nytimes.com/collections/new-york-times-page-reprints?utm_source=nytimes&amp;utm_medium=article-page&amp;utm_campaign=reprints\">Buy Reprints</a></div><div class=\"css-1nq039c\"><a class=\"css-1382yzd\" href=\"https://timesmachine.nytimes.com/timesmachine/1979/01/01/110993241.html\" type=\"button\" rel=\"noopener noreferrer\" target=\"_blank\">View on timesmachine</a></div><div class=\"css-1gus26i\">TimesMachine is an exclusive benefit for home delivery and digital subscribers.</div></div></div><div class=\"css-1mweozg\"><div class=\"css-14uxcda\">About the Archive</div><div class=\"css-6hi8ev\">This is a digitized version of an article from The Times’s print archive, before the start of online publication in 1996. To preserve these articles as they originally appeared, The Times does not alter, edit or update them.</div><div class=\"css-6hi8ev\">Occasionally the digitization process introduces transcription errors or other problems; we are continuing to work to improve these archived versions.</div></div></div></div><div class=\"css-s99gbd StoryBodyCompanionColumn\" data-testid=\"companionColumn-0\"><div class=\"css-53u6y8\"><p class=\"css-at9mc1 evys1bk0\">JERUSALEM, Dec. 31 — The Israeli Government decided today to continue its peace‐treaty talks with Egypt, and Prime Minister Menachem Begin suggested the negotiations could resume “within the week or the next week.”</p><p class=\"css-at9mc1 evys1bk0\">Mr. Begin said no decision had yet been reached on where the new negotiations would take place. He gave no indication whether the talks would be held between himself, President Carter and President Anwar el‐Sadat of Egypt, or would take place at a lower level.</p><p class=\"css-at9mc1 evys1bk0\">The peace negotiations have been stalled for several months; recently, Israel rejected proposals worked out between Egypt and Secretary of State Cyrus R. Vance that would qualify by means of interpretive letters and notes the “framework for peace” arrived at during the Camp David, Md., summit conferente in September.</p><p class=\"css-at9mc1 evys1bk0\">As a result of this disagreement, Israel and Egypt failed to meet a Dec. 17 deadline set at Camp David for the signing of a peace treaty. Mr. Vance&#x27;s trip to the Middle East to resolve the differences was unsuccessful, and created bitterness here because the Israelis felt that Washington had taken Egypt&#x27;s side in the debate.</p></div><aside class=\"css-ew4tgv\" aria-label=\"companion column\"></aside></div><div data-testid=\"Dropzone-1\"></div><div class=\"css-s99gbd StoryBodyCompanionColumn\" data-testid=\"companionColumn-1\"><div class=\"css-53u6y8\"><p class=\"css-at9mc1 evys1bk0\">A low point was reached on Dec. 15 when the Israeli Cabinet, in a unanimous vote, appeared to close the door to further negotiations by rejecting all Egyptian proposals to amend the draft treaty. Since then, Mr. Begin has said that Israel is willing to discuss some but not all the Egyptian demands. The Government decision today and Prime Minister Begin&#x27;s later remarks are part of the gradual movement back to the negotiating table.</p><p class=\"css-at9mc1 evys1bk0\"><strong class=\"css-8qgvsz ebyp5n10\">Israel Would Review Security</strong></p><p class=\"css-at9mc1 evys1bk0\">In announcing agreement to resume the talks, Mr. Begin told reporters that Israel was prepared to discuss with Egypt its demand to review security arrangments in the Sinai Peninsula five years after a peace treaty is signed. Sinai, now under Israeli occupation, would be returned to Egypt under the peace treaty, but Egypt wants to eventually renegotiate the size of the military force it can deploy there.</p><p class=\"css-at9mc1 evys1bk0\">Mr. Begin also said that Israel was prepared to discuss with the Egyptians further arrangements for Palestinian autonomy on the West Bank and Gaza. But the Prime Minister insisted that Israel would continue to resist Egyptian demands for setting a target date for the beginning of Palestinian autonomy.</p><p class=\"css-at9mc1 evys1bk0\">Egypt has tried to establish a connection between a peace treaty with Israel and the achievement of Palestinian selfrule. In recent days, Egyptian officials have also made clear that they expect Palestinian autonomy to lead to a Palestinian state.</p><p class=\"css-at9mc1 evys1bk0\">The Israelis are strongly opposed to the creation of a Palestinian state, which they say would be a base for Soviet penetration of the area and for continued Palestinian terrorist attacks against Israel.</p></div><aside class=\"css-ew4tgv\" aria-label=\"companion column\"></aside></div><div data-testid=\"Dropzone-3\"></div><div class=\"css-s99gbd StoryBodyCompanionColumn\" data-testid=\"companionColumn-2\"><div class=\"css-53u6y8\"><p class=\"css-at9mc1 evys1bk0\">The Israelis resisted linking a peace treaty to Palestinian autonomy because they contend that no one can predict the outcome of talks on autonomy, since such talks would involve Jordan and the Palestinians as well as Israel and Egypt. Until now, Jordan and the Palestinians have rejected any role in such talks.</p><p class=\"css-at9mc1 evys1bk0\"><strong class=\"css-8qgvsz ebyp5n10\">Demands on Article VI Rejected</strong></p><p class=\"css-at9mc1 evys1bk0\">Mr. Begin, in his remarks today, also turned down an Egyptian demand to revise Article VI of the draft treaty, which Egypt contends would make the pact with Israel supersede Egypt&#x27;s defense treaties with other Arab nations. Mr. Begin contends that amending Article VI would render the treaty meaningless because, if another war broke out, Egypt might join other Arab countries against Israel.</p><p class=\"css-at9mc1 evys1bk0\">“Israel will approach the United States Government with a view to insuring the sole and unequivocal meaning of this article of the peace treaty,” Mr. Begin said.</p><p class=\"css-at9mc1 evys1bk0\">While the Cabinet met today to decide on the resumption of peace talks, the Israeli Army blocked an attempt by rightwing extremists to establish an illegal Jewish settlement on the West Bank. The squatters, members of Gush Emunim, or Faith Block, have been attempting to establish new settlements in the occupied areas, which provoke angry reactions from the Egyptian and American Governments.</p><p class=\"css-at9mc1 evys1bk0\">The Gush Emunim settlers justify their actions, by saying that the West Bank is part of Israel because it was inhabited by Jews in biblical times.</p></div><aside class=\"css-ew4tgv\" aria-label=\"companion column\"></aside></div><div data-testid=\"Dropzone-5\"></div><div class=\"css-s99gbd StoryBodyCompanionColumn\" data-testid=\"companionColumn-3\"><div class=\"css-53u6y8\"><p class=\"css-at9mc1 evys1bk0\">In today&#x27;s incident, army troops stopped a convoy of cars and trucks carrying 30 families to an area on the outskirts of Nablus, an Arab town. The squatters then stalled one of their trucks on the highway and piled stones across the road to block access to the Nablus area.</p><p class=\"css-at9mc1 evys1bk0\"><strong class=\"css-8qgvsz ebyp5n10\">Ambivalent Position on Settlements</strong></p><p class=\"css-at9mc1 evys1bk0\">Israel&#x27;s position on the new West Bank settlements has been ambivalent. The Government insists that Jews should have a right to live on the West Bank even after Palestinian autonomy comes, and considers the settlements part of an early‐warning defense system in case of another war. But in order not to interfere with the negotiations with Egypt, the Government froze the establishment of new camps on the West Bank until Dec. 17, when the peace treaty was to be signed.</p><p class=\"css-at9mc1 evys1bk0\">Since then, Government spokesmen have said that the existing 48 settlements there are being expanded and that preparations for new ones are under way. But attempts by Gush Emunim to start new settlements have been resisted on the ground that it is the Government&#x27;s prerogative to decide when and where new camps should be established.</p></div><aside class=\"css-ew4tgv\" aria-label=\"companion column\"></aside></div></section><div class=\"bottom-of-article\"><div role=\"toolbar\" data-testid=\"share-tools\" aria-label=\"Social Media Share buttons, Save button, and Comments Panel with current comment count\" class=\"css-yomkvi\"><div></div><div class=\"css-10i3hc\"></div><div class=\"css-jf7ug7\"><ul class=\"css-1atjma0\"><li class=\"css-1c5ewvl\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"\" aria-expanded=\"false\" class=\"css-1eeh360 actionbar-button\" data-testid=\"gift-article-button\"><span class=\"css-10d8k1f\"><svg aria-hidden=\"true\" width=\"19\" height=\"19\" viewBox=\"0 0 19 19\"><path d=\"M18.04 5.293h-2.725c.286-.34.493-.74.606-1.17a2.875 2.875 0 0 0-.333-2.322A2.906 2.906 0 0 0 13.64.48a3.31 3.31 0 0 0-2.372.464 3.775 3.775 0 0 0-1.534 2.483l-.141.797-.142-.847A3.745 3.745 0 0 0 7.927.923 3.31 3.31 0 0 0 5.555.459 2.907 2.907 0 0 0 3.607 1.78a2.877 2.877 0 0 0-.333 2.321c.117.429.324.828.606 1.171H1.155a.767.767 0 0 0-.757.757v3.674a.767.767 0 0 0 .757.757h.424v7.53A1.01 1.01 0 0 0 2.588 19h14.13a1.01 1.01 0 0 0 1.01-.959v-7.56h.424a.758.758 0 0 0 .757-.757V6.05a.759.759 0 0 0-.868-.757Zm-7.196-1.625a2.665 2.665 0 0 1 1.01-1.736 2.24 2.24 0 0 1 1.574-.313 1.817 1.817 0 0 1 1.211.818 1.857 1.857 0 0 1 .202 1.453 2.2 2.2 0 0 1-.838 1.191h-3.431l.272-1.413ZM4.576 2.386a1.837 1.837 0 0 1 1.221-.817 2.23 2.23 0 0 1 1.565.313 2.624 2.624 0 0 1 1.01 1.736l.242 1.453H5.182a2.2 2.2 0 0 1-.838-1.19 1.857 1.857 0 0 1 .202-1.495h.03ZM1.548 6.424h7.54V9.39h-7.58l.04-2.967Zm1.181 4.128h6.359v7.287H2.729v-7.287Zm13.777 7.287h-6.348v-7.307h6.348v7.307Zm1.181-8.468h-7.53V6.404h7.53V9.37Z\" fill=\"#121212\" fill-rule=\"nonzero\"></path></svg>Share full article</span></button></div></div></li><li class=\"css-1qy6wq7\"><div class=\"css-vxcmzt\"><div class=\"css-79elbk\"><button type=\"button\" aria-label=\"More sharing options ...\" aria-expanded=\"false\" class=\"css-1nurhyi actionbar-button\"><svg aria-hidden=\"true\" width=\"23\" height=\"18\" viewBox=\"0 0 23 18\" class=\"css-zd9juy\"><path d=\"M1.357 17.192a.663.663 0 0 1-.642-.81c1.82-7.955 6.197-12.068 12.331-11.68V1.127a.779.779 0 0 1 .42-.653.726.726 0 0 1 .78.106l8.195 6.986a.81.81 0 0 1 .253.557.82.82 0 0 1-.263.547l-8.196 6.955a.83.83 0 0 1-.779.105.747.747 0 0 1-.42-.663V11.29c-8.418-.905-10.974 5.177-11.08 5.45a.662.662 0 0 1-.6.453Zm10.048-7.26a16.37 16.37 0 0 1 2.314.158.81.81 0 0 1 .642.726v3.02l6.702-5.682-6.702-5.692v2.883a.767.767 0 0 1-.242.536.747.747 0 0 1-.547.18c-4.808-.537-8.364 1.85-10.448 6.922a11.679 11.679 0 0 1 8.28-3.093v.042Z\" fill=\"#000\" fill-rule=\"nonzero\"></path></svg></button></div></div></li><li class=\"css-1qy6wq7 save-button\"><button type=\"button\" role=\"switch\" class=\"css-1yhvmgx actionbar-button\" data-testid=\"save-article-button\" aria-label=\"Save article for reading later...\" aria-checked=\"false\" disabled=\"\" aria-busy=\"false\" aria-live=\"polite\"><svg width=\"12\" height=\"18\" viewBox=\"0 0 12 18\" class=\"css-eap6fy\"><g fill-rule=\"nonzero\"><path class=\"saved-fill\" d=\"M1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268z\"></path><path class=\"saved-stroke\" d=\"m12 18-5.9-4.756L0 17.98V1.014C0 .745.095.487.265.297.435.107.664 0 .904 0h10.192c.24 0 .47.107.64.297.169.19.264.448.264.717V18ZM1.157 1.268v14.288l4.96-3.813 4.753 3.843V1.268H1.158Z\"></path></g></svg></button></li></ul></div></div></div><div data-testid=\"lazy-loader\"></div><div id=\"bottom-sheet-sensor\"><div data-testid=\"lazy-loader\"></div></div><div><div id=\"bottom-wrapper\" class=\"css-sxwst7\"><div id=\"bottom-slug\" class=\"css-l9onyx\"><p>Advertisement</p></div><a href=\"#after-bottom\" class=\"css-777zgl\">SKIP ADVERTISEMENT</a><div class=\"ad bottom-wrapper css-rfqw0c\" id=\"bottom\" style=\"min-height:90px\"></div><div id=\"after-bottom\"></div></div></div></article></div></main><nav class=\"css-1jmk4jh\" id=\"site-index\" aria-labelledby=\"site-index-label\" data-testid=\"site-index\"><h2 class=\"css-1dv1kvn\" id=\"site-index-label\">Site Index</h2><div class=\"css-sg7scw\"><header class=\"css-jxzr5i\"><a aria-label=\"New York Times\" data-testid=\"site-index-header\" href=\"/\"><svg class=\"css-oylsik\" viewBox=\"0 0 184 25\" fill=\"#000\" aria-hidden=\"true\"><path d=\"M14.57,2.57C14.57,.55,12.65-.06,11.04,.01V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.36,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.88-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08C3.31,5.73,.5,8.56,.5,12.06c0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.08c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96M5.8,14.13l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.08-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm19.47-5.76l-.81,.64-2.47-2.2-2.86,2.21V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15-.79,.52-1.08-1.08v-7.12l.74-.54,1.7,1.48v6.19c0,3.92-.87,4.73-2.63,5.37v.1c2.93,.12,5.57-.87,5.57-5.89v-6.75l.88-.72-.12-.15h0Zm5.22,10.8l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h-.01Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6ZM53.65,1.61c0-.32-.08-.59-.2-.96h-.07c-.32,.87-.67,1.33-1.68,1.33-.88,0-1.58-.54-1.95-.94,0,.03-2.96,3.42-2.96,3.42l.15,.12,.84-.96c.64,.49,1.21,1.06,2.63,1.08V13.34l-6.06-10.5c-.47-.79-1.28-1.97-2.66-1.97-1.63,0-2.86,1.4-2.66,3.77h.1c.12-.59,.47-1.33,1.18-1.33,.57,0,1.03,.54,1.3,1.03v3.38c-1.87,0-2.93,.87-2.93,2.34,0,.61,.45,1.94,1.72,2.17v-.07c-.17-.17-.34-.32-.34-.67,0-.57,.42-.88,1.18-.88,.12,0,.3,.03,.37,.05v4.38c-2.2,.03-3.89,1.23-3.89,3.31s1.7,2.88,3.47,2.78v-.07c-1.11-.12-1.68-.69-1.68-1.5,0-.88,.64-1.36,1.45-1.36s1.43,.52,1.95,1.11l2.96-3.33-.12-.12-.76,.87c-1.14-1.01-1.87-1.48-3.18-1.68V4.67l8.36,14.57h.45V4.72c1.6-.1,3.03-1.3,3.03-3.11m2.81,17.54l4.51-3.62-.12-.17-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.8l-1.01,.79,.12,.15,.96-.76,3.5,2.54h0Zm-.69-5.67v-5.15l2.27,3.55-2.27,1.6Zm21.22-5.52l-.69,.52-1.97-1.68-2.29,2.07,.94,.88v7.72l-2.34-1.6v-6.26l.81-.57-2.41-2.24-2.24,2.07,.94,.88v7.46l-.15,.1-2.2-1.6v-6.13c0-1.43-.72-1.85-1.63-2.41-.76-.47-1.16-.91-1.16-1.63,0-.79,.69-1.11,.91-1.23-.79-.03-2.98,.76-3.03,2.76-.03,1.03,.47,1.48,.99,1.97,.52,.49,1.01,.96,1.01,1.83v6.01l-1.06,.84,.12,.12,1.01-.79,2.63,2.14,2.51-1.75,2.76,1.75,5.42-3.2v-6.95l1.21-.94-.1-.15h0Zm18.15-5.84l-1.03,.94-2.32-2.02-3.13,2.51V1.19h-.19V18.12c-.34-.05-1.06-.25-1.85-.37V3.58c0-1.03-.74-2.47-2.59-2.47s-3.01,1.56-3.01,2.91h.08c.1-.61,.52-1.16,1.13-1.16s1.18,.39,1.18,1.78v4.04c-1.75,.07-2.81,1.16-2.81,2.34,0,.67,.42,1.92,1.75,1.97v-.1c-.45-.19-.54-.42-.54-.67,0-.59,.57-.79,1.36-.79h.19v6.51c-1.5,.52-2.2,1.53-2.2,2.78,0,1.72,1.38,3.05,3.4,3.05,1.43,0,2.44-.25,3.75-.54,1.06-.22,2.21-.47,2.83-.47,.79,0,1.14,.35,1.14,.91,0,.72-.27,1.08-.69,1.21v.1c1.7-.32,2.69-1.3,2.69-2.83s-1.5-2.54-3.18-2.54c-.87,0-2.44,.27-3.72,.57-1.43,.32-2.66,.47-3.11,.47-.72,0-1.6-.32-1.6-1.28,0-.87,.72-1.56,2.49-1.56,.96,0,1.9,.15,3.08,.42,1.26,.27,2.12,.64,3.2,.64,1.5,0,2.71-.54,2.71-2.74V3.29l1.11-1.01-.12-.15h0Zm-4.24,6.78c-.27,.3-.59,.54-1.11,.54-.57,0-.87-.3-1.14-.54V3.81l.74-.59,1.5,1.28v4.41h0Zm0,2.41c-.25-.25-.57-.47-1.11-.47s-.91,.27-1.14,.47v-2.17c.22,.19,.59,.49,1.14,.49s.87-.25,1.11-.49v2.17Zm0,5.1c0,.84-.42,1.78-1.5,1.78-.17,0-.57-.03-.74-.05v-6.58c.25-.22,.57-.52,1.14-.52,.52,0,.81,.25,1.11,.52v4.86h0Zm8.78,2.74l5.03-3.13v-6.85l-3.25-2.39-5.03,2.88v6.78l-.99,.79,.1,.15,.81-.67,3.33,2.44h0Zm-.37-3.55v-7.3l2.51,1.87v7.3l-2.51-1.87Zm15.01-8.65c-.39,.27-.74,.42-1.11,.42-.39,0-.88-.25-1.14-.57,0,.03-1.87,2.02-1.87,2.02l-1.87-2.02-3.05,2.12,.1,.17,.81-.54,1.11,1.21v6.63l-1.33,1.01,.12,.12,.67-.46,2.49,2.12,3.15-2.09-.1-.15-.81,.49-1.28-1.16v-7.28c.52,.57,1.11,1.06,1.82,1.06,1.28,0,2.14-1.53,2.29-3.11m11.88,9.81l-.94,.59-5.2-7.76,.27-.37c.57,.34,1.08,.81,2.17,.81s2.47-1.14,2.59-3.23c-.27,.37-.81,.81-1.7,.81-.64,0-1.28-.42-1.67-.81l-3.55,5.22,4.71,7.17,3.42-2.27-.1-.17h0Zm-6.31,.19l-.79,.52-1.08-1.08V.48l-3.89,2.69c.45,.15,.99,.39,.99,1.43v11.81l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm22.89-14.39c0-2.02-1.92-2.63-3.53-2.56V.19c.96,.07,1.7,.46,1.7,1.11,0,.45-.32,1.01-1.28,1.01-.76,0-2.02-.45-3.2-.84-1.3-.45-2.54-.87-3.57-.87-2.02,0-3.55,1.5-3.55,3.35,0,1.5,1.16,2.02,1.63,2.21l.03-.07c-.3-.2-.49-.42-.49-1.06,0-.54,.39-1.26,1.43-1.26,.94,0,2.17,.42,3.8,.88,1.4,.39,2.91,.76,3.75,.87v3.28l-1.58,1.3,1.58,1.36v4.49c-.81,.46-1.75,.61-2.56,.61-1.5,0-2.89-.42-4.02-1.68l4.26-2.07V5.73l-5.2,2.32c.54-1.38,1.55-2.41,2.66-3.08l-.03-.08c-3.08,.84-5.89,3.67-5.89,7.17,0,4.19,3.35,7.3,7.22,7.3,4.19,0,6.65-3.28,6.61-6.75h-.07c-.61,1.33-1.63,2.59-2.78,3.25v-4.38l1.65-1.33-1.65-1.33v-3.28c1.53,0,3.11-1.01,3.11-2.96m-8.78,11.56l-1.21,.61c-.74-.96-1.23-2.32-1.23-4.07,0-.72,.07-1.7,.32-2.39l2.14-.96-.03,6.8h0Zm11.93-12.31l-2.17,1.82,1.85,2.09,2.17-1.82-1.85-2.09Zm3.3,15.15l-.79,.52-1.08-1.08v-7.17l.91-.72-.12-.15-.76,.59-1.8-2.14-2.96,2.07,.1,.17,.74-.49,.99,1.23v6.61l-1.33,1.01,.12,.12,.67-.46,2.32,2.12,3.11-2.07-.1-.15h0Zm16.63-.1l-.74,.49-1.16-1.11v-7.03l.94-.72-.12-.15-.84,.64-2.47-2.2-2.78,2.17-2.44-2.17-2.74,2.14-1.85-2.14-2.96,2.07,.1,.17,.74-.49,1.06,1.21v6.61l-.81,.81,2.36,2,2.29-2.07-.94-.88v-7.04l.61-.45,1.7,1.48v6.16l-.79,.81,2.39,2,2.24-2.07-.94-.88v-7.04l.59-.47,1.72,1.5v6.06l-.69,.72,2.41,2.2,3.18-2.17-.1-.15h.02Zm8.6-1.5l-2.36,1.87-2.71-2.14v-1.33l4.68-3.3-2.36-3.67-5.2,2.86v6.93l3.57,2.59,4.51-3.62-.12-.17h0Zm-5.08-1.88v-5.15l2.27,3.55-2.27,1.6Zm14.12-.97l-2-1.53c1.33-1.16,1.8-2.63,1.8-3.69,0-.15-.03-.42-.05-.67h-.08c-.19,.54-.72,1.01-1.53,1.01s-1.26-.45-1.75-.99l-4.58,2.54v3.72l1.75,1.38c-1.75,1.55-2.09,2.51-2.09,3.4s.52,1.67,1.41,2.02l.07-.12c-.22-.19-.42-.32-.42-.79,0-.34,.35-.88,1.14-.88,1.01,0,1.63,.69,1.95,1.06,0-.03,4.38-2.69,4.38-2.69v-3.77h0Zm-1.03-3.05c-.69,1.23-2.21,2.44-3.11,3.13l-1.11-.94v-3.62c.45,.99,1.36,1.82,2.54,1.82,.69,0,1.14-.12,1.67-.39m-1.9,8.13c-.52-1.16-1.63-2-2.86-2-.3,0-1.21-.03-2,.46,.47-.79,1.87-2.21,3.65-3.28l1.21,1.01v3.8Z\"></path></svg></a><div class=\"css-1otr2jl\"><a class=\"css-184m8ie\" data-testid=\"go-to-homepage\" href=\"/\">Go to Home Page »</a></div></header><div class=\"css-qtw155\" data-testid=\"site-index-accordion\"><div class=\" \" role=\"tablist\" aria-multiselectable=\"true\" data-testid=\"accordion\"><div class=\"\" data-testid=\"accordion-item\"><header aria-controls=\"body-siteindex-0\" id=\"item-siteindex-0\" class=\"css-1a5mdf6\" role=\"tab\" tabindex=\"0\" aria-expanded=\"false\" data-testid=\"accordion-item-header\">News</header><div class=\"css-1hyfx7x\" id=\"body-siteindex-0\" aria-labelledby=\"item-siteindex-0\" role=\"tabpanel\" data-testid=\"accordion-item-body\"><ul class=\"css-1gprdgz\" data-testid=\"site-index-accordion-list\"><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/\" data-testid=\"accordion-item-list-link\">Home Page</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/us\" data-testid=\"accordion-item-list-link\">U.S.</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/world\" data-testid=\"accordion-item-list-link\">World</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/politics\" data-testid=\"accordion-item-list-link\">Politics</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/nyregion\" data-testid=\"accordion-item-list-link\">New York</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/education\" data-testid=\"accordion-item-list-link\">Education</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/sports\" data-testid=\"accordion-item-list-link\">Sports</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/business\" data-testid=\"accordion-item-list-link\">Business</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/technology\" data-testid=\"accordion-item-list-link\">Tech</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/science\" data-testid=\"accordion-item-list-link\">Science</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/news-event/weather-climate\" data-testid=\"accordion-item-list-link\">Weather</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/the-great-read\" data-testid=\"accordion-item-list-link\">The Great Read</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/obituaries\" data-testid=\"accordion-item-list-link\">Obituaries</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/headway\" data-testid=\"accordion-item-list-link\">Headway</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/visual-investigations\" data-testid=\"accordion-item-list-link\">Visual Investigations</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/magazine\" data-testid=\"accordion-item-list-link\">The Magazine</a></li></ul></div></div><div class=\"\" data-testid=\"accordion-item\"><header aria-controls=\"body-siteindex-1\" id=\"item-siteindex-1\" class=\"css-1a5mdf6\" role=\"tab\" tabindex=\"0\" aria-expanded=\"false\" data-testid=\"accordion-item-header\">Arts</header><div class=\"css-1hyfx7x\" id=\"body-siteindex-1\" aria-labelledby=\"item-siteindex-1\" role=\"tabpanel\" data-testid=\"accordion-item-body\"><ul class=\"css-1gprdgz\" data-testid=\"site-index-accordion-list\"><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/books/review\" data-testid=\"accordion-item-list-link\">Book Review</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/books/best-sellers/\" data-testid=\"accordion-item-list-link\">Best Sellers Book List</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/arts/dance\" data-testid=\"accordion-item-list-link\">Dance</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/movies\" data-testid=\"accordion-item-list-link\">Movies</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/arts/music\" data-testid=\"accordion-item-list-link\">Music</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/pop-culture\" data-testid=\"accordion-item-list-link\">Pop Culture</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/arts/television\" data-testid=\"accordion-item-list-link\">Television</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/theater\" data-testid=\"accordion-item-list-link\">Theater</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/arts/design\" data-testid=\"accordion-item-list-link\">Visual Arts</a></li></ul></div></div><div class=\"\" data-testid=\"accordion-item\"><header aria-controls=\"body-siteindex-2\" id=\"item-siteindex-2\" class=\"css-1a5mdf6\" role=\"tab\" tabindex=\"0\" aria-expanded=\"false\" data-testid=\"accordion-item-header\">Lifestyle</header><div class=\"css-1hyfx7x\" id=\"body-siteindex-2\" aria-labelledby=\"item-siteindex-2\" role=\"tabpanel\" data-testid=\"accordion-item-body\"><ul class=\"css-1gprdgz\" data-testid=\"site-index-accordion-list\"><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/health\" data-testid=\"accordion-item-list-link\">Health</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/well\" data-testid=\"accordion-item-list-link\">Well</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/food\" data-testid=\"accordion-item-list-link\">Food</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/reviews/dining\" data-testid=\"accordion-item-list-link\">Restaurant Reviews</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/fashion/weddings\" data-testid=\"accordion-item-list-link\">Love</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/travel\" data-testid=\"accordion-item-list-link\">Travel</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/style\" data-testid=\"accordion-item-list-link\">Style</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/fashion\" data-testid=\"accordion-item-list-link\">Fashion</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/realestate\" data-testid=\"accordion-item-list-link\">Real Estate</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/t-magazine\" data-testid=\"accordion-item-list-link\">T Magazine</a></li></ul></div></div><div class=\"\" data-testid=\"accordion-item\"><header aria-controls=\"body-siteindex-3\" id=\"item-siteindex-3\" class=\"css-1a5mdf6\" role=\"tab\" tabindex=\"0\" aria-expanded=\"false\" data-testid=\"accordion-item-header\">Opinion</header><div class=\"css-1hyfx7x\" id=\"body-siteindex-3\" aria-labelledby=\"item-siteindex-3\" role=\"tabpanel\" data-testid=\"accordion-item-body\"><ul class=\"css-1gprdgz\" data-testid=\"site-index-accordion-list\"><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion\" data-testid=\"accordion-item-list-link\">Today&#x27;s Opinion</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion/columnists\" data-testid=\"accordion-item-list-link\">Columnists</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion/editorials\" data-testid=\"accordion-item-list-link\">Editorials</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion/contributors\" data-testid=\"accordion-item-list-link\">Guest Essays</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/column/op-docs\" data-testid=\"accordion-item-list-link\">Op-Docs</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion/letters\" data-testid=\"accordion-item-list-link\">Letters</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/opinion/sunday\" data-testid=\"accordion-item-list-link\">Sunday Opinion</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/opinion-video\" data-testid=\"accordion-item-list-link\">Opinion Video</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/series/opinion-audio\" data-testid=\"accordion-item-list-link\">Opinion Audio</a></li></ul></div></div><div class=\"\" data-testid=\"accordion-item\"><header aria-controls=\"body-siteindex-4\" id=\"item-siteindex-4\" class=\"css-1a5mdf6\" role=\"tab\" tabindex=\"0\" aria-expanded=\"false\" data-testid=\"accordion-item-header\">More</header><div class=\"css-1hyfx7x\" id=\"body-siteindex-4\" aria-labelledby=\"item-siteindex-4\" role=\"tabpanel\" data-testid=\"accordion-item-body\"><ul class=\"css-1gprdgz\" data-testid=\"site-index-accordion-list\"><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/podcasts\" data-testid=\"accordion-item-list-link\">Audio</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://www.nytimes.com/crosswords\" data-testid=\"accordion-item-list-link\">Games</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://cooking.nytimes.com\" data-testid=\"accordion-item-list-link\">Cooking</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://www.nytimes.com/wirecutter/\" data-testid=\"accordion-item-list-link\">Wirecutter</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://www.nytimes.com/athletic/\" data-testid=\"accordion-item-list-link\">The Athletic</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/jobs\" data-testid=\"accordion-item-list-link\">Jobs</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/video\" data-testid=\"accordion-item-list-link\">Video</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/graphics\" data-testid=\"accordion-item-list-link\">Graphics</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/trending/\" data-testid=\"accordion-item-list-link\">Trending</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/nyt-events\" data-testid=\"accordion-item-list-link\">Live Events</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/corrections\" data-testid=\"accordion-item-list-link\">Corrections</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/reader-center\" data-testid=\"accordion-item-list-link\">Reader Center</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://timesmachine.nytimes.com/browser\" data-testid=\"accordion-item-list-link\">TimesMachine</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/section/learning\" data-testid=\"accordion-item-list-link\">The Learning Network</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"https://nytedu.com/\" data-testid=\"accordion-item-list-link\">School of The NYT</a></li><li class=\"css-10t7hia\"><a class=\"css-e9w26l\" href=\"/spotlight/nytimesineducation\" data-testid=\"accordion-item-list-link\">inEducation</a></li></ul></div></div></div></div><div class=\"css-v0l3hm\" data-testid=\"site-index-sections\"><div class=\"css-g4gku8\" data-testid=\"site-index-section\"><section class=\"css-1rr4qq7\" aria-labelledby=\"site-index-section-label-0\"><h3 class=\"css-1onhbft\" id=\"site-index-section-label-0\">News</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-section-list\"><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/\" data-testid=\"site-index-section-list-link\">Home Page</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/us\" data-testid=\"site-index-section-list-link\">U.S.</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/world\" data-testid=\"site-index-section-list-link\">World</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/politics\" data-testid=\"site-index-section-list-link\">Politics</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/nyregion\" data-testid=\"site-index-section-list-link\">New York</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/education\" data-testid=\"site-index-section-list-link\">Education</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/sports\" data-testid=\"site-index-section-list-link\">Sports</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/business\" data-testid=\"site-index-section-list-link\">Business</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/technology\" data-testid=\"site-index-section-list-link\">Tech</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/science\" data-testid=\"site-index-section-list-link\">Science</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/news-event/weather-climate\" data-testid=\"site-index-section-list-link\">Weather</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/the-great-read\" data-testid=\"site-index-section-list-link\">The Great Read</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/obituaries\" data-testid=\"site-index-section-list-link\">Obituaries</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/headway\" data-testid=\"site-index-section-list-link\">Headway</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/visual-investigations\" data-testid=\"site-index-section-list-link\">Visual Investigations</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/magazine\" data-testid=\"site-index-section-list-link\">The Magazine</a></li></ul></section><section class=\"css-1rr4qq7\" aria-labelledby=\"site-index-section-label-1\"><h3 class=\"css-1onhbft\" id=\"site-index-section-label-1\">Arts</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-section-list\"><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/books/review\" data-testid=\"site-index-section-list-link\">Book Review</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/books/best-sellers/\" data-testid=\"site-index-section-list-link\">Best Sellers Book List</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/arts/dance\" data-testid=\"site-index-section-list-link\">Dance</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/movies\" data-testid=\"site-index-section-list-link\">Movies</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/arts/music\" data-testid=\"site-index-section-list-link\">Music</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/pop-culture\" data-testid=\"site-index-section-list-link\">Pop Culture</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/arts/television\" data-testid=\"site-index-section-list-link\">Television</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/theater\" data-testid=\"site-index-section-list-link\">Theater</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/arts/design\" data-testid=\"site-index-section-list-link\">Visual Arts</a></li></ul></section><section class=\"css-1rr4qq7\" aria-labelledby=\"site-index-section-label-2\"><h3 class=\"css-1onhbft\" id=\"site-index-section-label-2\">Lifestyle</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-section-list\"><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/health\" data-testid=\"site-index-section-list-link\">Health</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/well\" data-testid=\"site-index-section-list-link\">Well</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/food\" data-testid=\"site-index-section-list-link\">Food</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/reviews/dining\" data-testid=\"site-index-section-list-link\">Restaurant Reviews</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/fashion/weddings\" data-testid=\"site-index-section-list-link\">Love</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/travel\" data-testid=\"site-index-section-list-link\">Travel</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/style\" data-testid=\"site-index-section-list-link\">Style</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/fashion\" data-testid=\"site-index-section-list-link\">Fashion</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/realestate\" data-testid=\"site-index-section-list-link\">Real Estate</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/t-magazine\" data-testid=\"site-index-section-list-link\">T Magazine</a></li></ul></section><section class=\"css-1rr4qq7\" aria-labelledby=\"site-index-section-label-3\"><h3 class=\"css-1onhbft\" id=\"site-index-section-label-3\">Opinion</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-section-list\"><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion\" data-testid=\"site-index-section-list-link\">Today&#x27;s Opinion</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion/columnists\" data-testid=\"site-index-section-list-link\">Columnists</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion/editorials\" data-testid=\"site-index-section-list-link\">Editorials</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion/contributors\" data-testid=\"site-index-section-list-link\">Guest Essays</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/column/op-docs\" data-testid=\"site-index-section-list-link\">Op-Docs</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion/letters\" data-testid=\"site-index-section-list-link\">Letters</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/opinion/sunday\" data-testid=\"site-index-section-list-link\">Sunday Opinion</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/opinion-video\" data-testid=\"site-index-section-list-link\">Opinion Video</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/series/opinion-audio\" data-testid=\"site-index-section-list-link\">Opinion Audio</a></li></ul></section><section class=\"css-1rr4qq7\" aria-labelledby=\"site-index-section-label-4\"><h3 class=\"css-1onhbft\" id=\"site-index-section-label-4\">More</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-section-list\"><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/podcasts\" data-testid=\"site-index-section-list-link\">Audio</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://www.nytimes.com/crosswords\" data-testid=\"site-index-section-list-link\">Games</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://cooking.nytimes.com\" data-testid=\"site-index-section-list-link\">Cooking</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://www.nytimes.com/wirecutter/\" data-testid=\"site-index-section-list-link\">Wirecutter</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://www.nytimes.com/athletic/\" data-testid=\"site-index-section-list-link\">The Athletic</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/jobs\" data-testid=\"site-index-section-list-link\">Jobs</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/video\" data-testid=\"site-index-section-list-link\">Video</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/graphics\" data-testid=\"site-index-section-list-link\">Graphics</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/trending/\" data-testid=\"site-index-section-list-link\">Trending</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/nyt-events\" data-testid=\"site-index-section-list-link\">Live Events</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/corrections\" data-testid=\"site-index-section-list-link\">Corrections</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/reader-center\" data-testid=\"site-index-section-list-link\">Reader Center</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://timesmachine.nytimes.com/browser\" data-testid=\"site-index-section-list-link\">TimesMachine</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/section/learning\" data-testid=\"site-index-section-list-link\">The Learning Network</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"https://nytedu.com/\" data-testid=\"site-index-section-list-link\">School of The NYT</a></li><li class=\"css-ist4u3\"><a class=\"css-yk8vb4\" href=\"/spotlight/nytimesineducation\" data-testid=\"site-index-section-list-link\">inEducation</a></li></ul></section><div class=\"css-6xhk3s\" aria-labelledby=\"site-index-subscribe-label\"><h3 class=\"css-1onhbft\" id=\"site-index-subscribe-label\">Account</h3><ul class=\"css-1iruc8t\" data-testid=\"site-index-subscribe-list\"><li class=\"css-tj0ten\"><a class=\"css-z6qatp\" href=\"/subscription\" data-testid=\"site-index-subscribe-list-link\"><svg class=\"css-1o03u4n\" viewBox=\"0 0 10 13\"><path fill=\"#000\" d=\"M9.9,8c-0.4,1.1-1.2,1.9-2.3,2.4V8l1.3-1.2L7.6,5.7V4c1.2-0.1,2-1,2-2c0-1.4-1.3-1.9-2.1-1.9c-0.2,0-0.3,0-0.6,0.1v0.1c0.1,0,0.2,0,0.3,0c0.5,0,0.9,0.2,0.9,0.7c0,0.4-0.3,0.7-0.8,0.7C6,1.7,4.5,0.6,2.8,0.6c-1.5,0-2.5,1.1-2.5,2.2C0.3,4,1,4.3,1.6,4.6l0-0.1C1.4,4.4,1.3,4.1,1.3,3.8c0-0.5,0.5-0.9,1-0.9C3.7,2.9,6,4,7.4,4h0.1v1.7L6.2,6.8L7.5,8v2.4c-0.5,0.2-1.1,0.3-1.7,0.3c-2.2,0-3.6-1.3-3.6-3.5c0-0.5,0.1-1,0.2-1.5l1.1-0.5V10l2.2-1v-5L2.5,5.5c0.3-1,1-1.7,1.8-2l0,0C2.2,3.9,0.1,5.6,0.1,8c0,2.9,2.4,4.8,5.2,4.8C8.2,12.9,9.9,10.9,9.9,8L9.9,8z\"></path></svg>Subscribe</a></li><li class=\"css-tj0ten\"><a class=\"css-z6qatp\" href=\"/account\" data-testid=\"site-index-subscribe-list-link\"><svg class=\"css-1o03u4n\" viewBox=\"0 0 20 20\" fill=\"#333\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M14.2379 6C14.2379 8.20914 12.4471 10 10.2379 10C8.02878 10 6.23792 8.20914 6.23792 6C6.23792 3.79086 8.02878 2 10.2379 2C12.4471 2 14.2379 3.79086 14.2379 6Z\" fill=\"#333\"></path><path d=\"M16.2355 14.5714C16.2371 14.5477 16.2379 14.5239 16.2379 14.5C16.2379 13.1193 13.5516 12 10.2379 12C6.92421 12 4.23792 13.1193 4.23792 14.5C4.23792 14.5239 4.23872 14.5477 4.24032 14.5714H4.23792V18H16.2379V14.5714H16.2355Z\" fill=\"#333\"></path></svg>Manage My Account</a></li><li class=\"css-tj0ten\"><a class=\"css-z6qatp\" href=\"https://www.nytimes.com/subscription/home-delivery\" data-testid=\"site-index-subscribe-list-link\"><svg class=\"css-1o03u4n\" viewBox=\"0 0 14 13\" fill=\"#000\"><path d=\"M13.1,11.7H3.5V1.2h9.6V11.7zM13.1,0.4H3.5C3,0.4,2.6,0.8,2.6,1.2v2.2H0.9C0.4,3.4,0,3.8,0,4.3v5.2v1.5c0,0.8,0.8,1.5,1.8,1.5h1.7h0h7.4h2.2c0.5,0,0.9-0.4,0.9-0.9V1.2C14,0.8,13.6,0.4,13.1,0.4\"></path><polygon points=\"10.9,3 5.2,3 5.2,3.9 11.4,3.9 11.4,3\"></polygon><rect x=\"5.2\" y=\"4.7\" width=\"6.1\" height=\"0.9\"></rect><rect x=\"5.2\" y=\"6.5\" width=\"6.1\" height=\"0.9\"></rect></svg>Home Delivery</a></li><li class=\"css-tj0ten\"><a class=\"css-z6qatp\" href=\"https://www.nytimes.com/gift\" data-testid=\"site-index-subscribe-list-link\"><svg class=\"css-1o03u4n\" viewBox=\"0 0 10 13\"><path fill=\"#000\" d=\"M9.9,8c-0.4,1.1-1.2,1.9-2.3,2.4V8l1.3-1.2L7.6,5.7V4c1.2-0.1,2-1,2-2c0-1.4-1.3-1.9-2.1-1.9c-0.2,0-0.3,0-0.6,0.1v0.1c0.1,0,0.2,0,0.3,0c0.5,0,0.9,0.2,0.9,0.7c0,0.4-0.3,0.7-0.8,0.7C6,1.7,4.5,0.6,2.8,0.6c-1.5,0-2.5,1.1-2.5,2.2C0.3,4,1,4.3,1.6,4.6l0-0.1C1.4,4.4,1.3,4.1,1.3,3.8c0-0.5,0.5-0.9,1-0.9C3.7,2.9,6,4,7.4,4h0.1v1.7L6.2,6.8L7.5,8v2.4c-0.5,0.2-1.1,0.3-1.7,0.3c-2.2,0-3.6-1.3-3.6-3.5c0-0.5,0.1-1,0.2-1.5l1.1-0.5V10l2.2-1v-5L2.5,5.5c0.3-1,1-1.7,1.8-2l0,0C2.2,3.9,0.1,5.6,0.1,8c0,2.9,2.4,4.8,5.2,4.8C8.2,12.9,9.9,10.9,9.9,8L9.9,8z\"></path></svg>Gift Subscriptions</a></li></ul><ul class=\"css-1iruc8t\" data-testid=\"site-index-corporate-links\"><li><a class=\"css-1ea6cym\" href=\"/subscription/groups?Pardot_Campaign_Code_Form_Input=89FQX\">Group Subscriptions</a></li><li><a class=\"css-1ea6cym\" href=\"/gift-articles\">Gift Articles</a></li><li><a class=\"css-1ea6cym\" href=\"/newsletters\">Email Newsletters</a></li></ul><ul class=\"css-6td9kr\" data-testid=\"site-index-alternate-links\"><li><a class=\"css-1ea6cym\" href=\"https://nytlicensing.com/\">NYT Licensing</a></li><li><a class=\"css-1ea6cym\" href=\"https://nytimes.pressreader.com/\">Replica Edition</a></li><li><a class=\"css-1ea6cym\" href=\"https://store.nytimes.com/\">Times Store</a></li></ul></div></div></div></div></nav><footer class=\"css-1e1s8k7\" role=\"contentinfo\"><nav data-testid=\"footer\" class=\"css-1qa4qp6\"><h2 class=\"css-1dv1kvn\">Site Information Navigation</h2><ul class=\"css-1ho5u4o edvi3so0\"><li data-testid=\"copyright\"><a class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice\">© <span>2025</span> <span>The New York Times Company</span></a></li></ul><ul class=\"css-t8x4fj edvi3so1\"><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytco.com/\">NYTCo</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us\">Contact Us</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us/articles/115015727108-Accessibility\">Accessibility</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytco.com/careers/\">Work with us</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://advertising.nytimes.com/\">Advertise</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.tbrandstudio.com/\">T Brand Studio</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers\">Your Ad Choices</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytimes.com/privacy/privacy-policy\">Privacy Policy</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service\">Terms of Service</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale\">Terms of Sale</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"/sitemap/\">Site Map</a></li><li class=\"mobileOnly css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytimes.com/ca/\">Canada</a></li><li class=\"mobileOnly css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://www.nytimes.com/international/\">International</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" class=\"css-jq1cx6\" href=\"https://help.nytimes.com/hc/en-us\">Help</a></li><li class=\"css-a7htku edvi3so2\"><a data-testid=\"footer-link\" rel=\"nofollow\" class=\"css-jq1cx6\" href=\"https://www.nytimes.com/subscription?campaignId=37WXW\">Subscriptions</a></li></ul><ul class=\"css-t8x4fj edvi3so1\"><li class=\"css-a7htku edvi3so2\"><a data-testid=\"privacy-preferences-link\" rel=\"noreferrer noopener\" target=\"_blank\" class=\"css-jq1cx6\" href=\"/privacy/manage-settings\">Manage Privacy Preferences</a></li></ul></nav></footer></div></div></div></div></div>\n",
      "    <script>window.__preloadedData = {\"initialData\":{\"data\":{\"article\":{\"__typename\":\"Article\",\"adTargetingParams\":[{\"__typename\":\"AdTargetingParam\",\"key\":\"typ_materials\",\"value\":\"#archives#\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"at\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"edn\",\"value\":\"us\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"ledemedsz\",\"value\":\"none\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"plat\",\"value\":\"web\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"per\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"typ\",\"value\":\"art\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"slug\",\"value\":\"would\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"si_section\",\"value\":\"archives\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"id\",\"value\":\"1979010100110993241\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"tt\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"bsc\",\"value\":\"80000200,80222001,80312001,80222008,80312008,80012021,80222006,80312006,80022003,80312022,80222022,80222002,80312002,80022005,80222004,80312004,80222009,80312009,80222010,80312010,80222005,80312005,80222011,80312011,80222014,80312014,80222012,80312012,80122003,80222003,80312003\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"geo\",\"value\":\"middleeast\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"des\",\"value\":\"israeliarabconflict\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"spon\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"coll\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"artlen\",\"value\":\"short\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"section\",\"value\":\"archives\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"prop\",\"value\":\"nyt\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"gui\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"is_viral\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"abs\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"brandsensitive\",\"value\":\"false\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"col\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"trend\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"mt\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"gscat\",\"value\":\"gs_t\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"als_test\",\"value\":\"1736532870245\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"is_viral_on_social\",\"value\":\"false\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"pt\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"org\",\"value\":\"\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"auth\",\"value\":\"jonathankandell\"},{\"__typename\":\"AdTargetingParam\",\"key\":\"template\",\"value\":\"article\"}],\"addendums\":[],\"advertisingProperties\":{\"__typename\":\"CreativeWorkAdvertisingProperties\",\"sensitivity\":\"SHOW_ADS\"},\"archiveProperties\":{\"__typename\":\"ArticleArchiveProperties\",\"lede\":\"JERUSALEM, Dec. 31 — The Israeli Government decided today to continue its peace‐treaty talks with Egypt, and Prime Minister Menachem Begin suggested the negotiations could resume “within the week or the next week.”\",\"thumbnails\":[{\"__typename\":\"ArticleArchivePropertiesThumbnail\",\"height\":276,\"url\":\"https:\\u002F\\u002Fs1.nyt.com\\u002Ftimesmachine\\u002Fpages\\u002F1\\u002F1979\\u002F01\\u002F01\\u002F110993241_180W.png\",\"width\":180},{\"__typename\":\"ArticleArchivePropertiesThumbnail\",\"height\":551,\"url\":\"https:\\u002F\\u002Fs1.nyt.com\\u002Ftimesmachine\\u002Fpages\\u002F1\\u002F1979\\u002F01\\u002F01\\u002F110993241_360W.png\",\"width\":360}],\"timesMachineUrl\":\"http:\\u002F\\u002Ftimesmachine.nytimes.com\\u002Ftimesmachine\\u002F1979\\u002F01\\u002F01\\u002F110993241.html\"},\"associatedAssets\":[{\"__typename\":\"AssociatedArticleAssetBlock\",\"asset\":{\"__typename\":\"Capsule\",\"uri\":\"nyt:\\u002F\\u002Fcapsule\\u002F90137812-f2e5-58aa-a34c-b4a2307b9349\"},\"assetName\":\"email-signup-your-places-global-update-maps\",\"parentTest\":\"\",\"region\":\"ABOVE_MAIN_CONTENT\",\"ruleName\":\"maps-global-update-email-signup\",\"testName\":\"\"}],\"associatedNewsletter\":null,\"bylines\":[{\"__typename\":\"Byline\",\"creatorSnapshots\":[{\"__typename\":\"PersonSnapshot\",\"uri\":\"nyt:\\u002F\\u002Fperson\\u002F536bfac1-0191-5209-aaf4-278e572c5583\"}],\"creators\":[{\"__typename\":\"Person\",\"bioUrl\":\"\",\"contactDetails\":{\"__typename\":\"ContactDetails\",\"socialMedia\":[]},\"displayName\":\"Jonathan Kandell\",\"id\":\"UGVyc29uOm55dDovL3BlcnNvbi81MzZiZmFjMS0wMTkxLTUyMDktYWFmNC0yNzhlNTcyYzU1ODM=\",\"legacyData\":{\"__typename\":\"PersonLegacyData\",\"htmlShortBiography\":\"\"},\"url\":\"\"}],\"renderedRepresentation\":\"By Jonathan Kandell;Special to The New York Times\"}],\"collections\":[],\"column\":null,\"commentProperties\":{\"__typename\":\"CreativeWorkCommentProperties\",\"approvedCommentsCount\":null,\"prompt\":\"\",\"status\":\"NO_COMMENTS\"},\"compatibility\":{\"__typename\":\"CompatibilityFeatures\",\"hasInlineEmbeddedInteractives\":false,\"hasOakConversionError\":false,\"hasVideo\":false,\"isArtReview\":false,\"isBookReview\":false,\"isDiningReview\":false,\"isMovieReview\":false,\"isOak\":false,\"isTheaterReview\":false},\"curatedAssetComments\":null,\"desk\":\"None\",\"dfpTaxonomyException\":null,\"displayProperties\":{\"__typename\":\"CreativeWorkDisplayProperties\",\"fullBleedDisplayStyle\":\"\",\"serveAsNyt4\":false},\"episodeProperties\":null,\"eventId\":\"pubp:\\u002F\\u002Fevent\\u002Fd897512268424ffda1a5bb6a28fa53e9\",\"featuredAudio\":null,\"firstPublished\":\"1979-01-01T05:00:00.000Z\",\"headline\":{\"__typename\":\"CreativeWorkHeadline\",\"default\":\"Israelis Decide to Continue Talks With Egypt on Treaty\",\"seo\":\"\"},\"id\":\"QXJ0aWNsZTpueXQ6Ly9hcnRpY2xlLzAyNGQzNjE1LWMzZjMtNWRiZS05NTcyLTkyZjFjNGIxNmY0NQ==\",\"kicker\":\"\",\"language\":null,\"lastMajorModification\":\"1979-01-01T05:00:00.000Z\",\"lastModified\":\"2018-12-27T15:46:50.552Z\",\"legacy\":{\"__typename\":\"ArticleLegacyData\",\"htmlExtendedAuthorOrArticleInformation\":\"\",\"htmlInfoBox\":\"\",\"reviewInformation\":\"\"},\"newsStatus\":\"DEFAULT\",\"originalDesk\":\"\",\"printInformation\":{\"__typename\":\"PrintInformation\",\"edition\":\"The New York Times on the Web\",\"headline\":\"Israelis Decide to Continue Talks With Egypt on Treaty\",\"page\":\"2\",\"publicationDate\":\"1979-01-01T05:00:00.000Z\",\"section\":\"\"},\"promotionalImage\":null,\"promotionalMedia\":null,\"requestToCommentEnabled\":false,\"reviewItems\":[],\"reviewSummary\":\"\",\"section\":{\"__typename\":\"Section\",\"displayName\":\"Archives\",\"id\":\"U2VjdGlvbjpueXQ6Ly9zZWN0aW9uLzliNTFlYzY1LTUzNGItNTRjMi05NDgzLWIyY2M5YTQwYmJmYg==\",\"name\":\"archives\",\"uri\":\"nyt:\\u002F\\u002Fsection\\u002F9b51ec65-534b-54c2-9483-b2cc9a40bbfb\",\"url\":\"\"},\"slug\":\"israelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would\",\"source\":{\"__typename\":\"Organization\",\"displayName\":\"New York Times\",\"id\":\"T3JnYW5pemF0aW9uOm55dDovL29yZ2FuaXphdGlvbi9jMjc5MTM4OC02YjE2LTVmZmQtYTExOS05NmVhY2IxOTg5YzE=\"},\"sourceId\":\"1979010100110993241\",\"sourcePublisher\":\"archive-repub\",\"sprinkled\":{\"__typename\":\"SprinkledContent\",\"configs\":[{\"__typename\":\"SprinkledConfig\",\"name\":\"mobile\",\"stride\":4,\"threshold\":3},{\"__typename\":\"SprinkledConfig\",\"name\":\"desktop\",\"stride\":7,\"threshold\":3},{\"__typename\":\"SprinkledConfig\",\"name\":\"mobileHoldout\",\"stride\":4,\"threshold\":2},{\"__typename\":\"SprinkledConfig\",\"name\":\"desktopHoldout\",\"stride\":5,\"threshold\":3},{\"__typename\":\"SprinkledConfig\",\"name\":\"hybrid\",\"stride\":4,\"threshold\":3}]},\"sprinkledBody\":{\"__typename\":\"DocumentBlock\",\"content\":[{\"__typename\":\"HeaderLegacyBlock\",\"byline\":{\"__typename\":\"BylineBlock\",\"bylines\":[{\"__typename\":\"Byline\",\"creators\":[{\"__typename\":\"Person\",\"bioUrl\":\"\",\"displayName\":\"Jonathan Kandell\",\"id\":\"UGVyc29uOm55dDovL3BlcnNvbi81MzZiZmFjMS0wMTkxLTUyMDktYWFmNC0yNzhlNTcyYzU1ODM=\",\"promotionalMedia\":null}],\"prefix\":\"By\",\"renderedRepresentation\":\"By Jonathan Kandell;Special to The New York Times\"}],\"hideHeadshots\":false,\"role\":[],\"textAlign\":\"DEFAULT\"},\"headline\":{\"__typename\":\"Heading1Block\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Israelis Decide to Continue Talks With Egypt on Treaty\"}],\"textAlign\":\"DEFAULT\"},\"label\":null,\"ledeMedia\":null,\"subhead\":null,\"timestampBlock\":{\"__typename\":\"TimestampBlock\",\"align\":\"DEFAULT\",\"showUpdatedTimestamp\":null,\"timestamp\":\"1979-01-01T05:00:00.000Z\"}},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"JERUSALEM, Dec. 31 — The Israeli Government decided today to continue its peace‐treaty talks with Egypt, and Prime Minister Menachem Begin suggested the negotiations could resume “within the week or the next week.”\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":0},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Mr. Begin said no decision had yet been reached on where the new negotiations would take place. He gave no indication whether the talks would be held between himself, President Carter and President Anwar el‐Sadat of Egypt, or would take place at a lower level.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":1},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"The peace negotiations have been stalled for several months; recently, Israel rejected proposals worked out between Egypt and Secretary of State Cyrus R. Vance that would qualify by means of interpretive letters and notes the “framework for peace” arrived at during the Camp David, Md., summit conferente in September.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":true,\"bad\":false,\"index\":2},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"As a result of this disagreement, Israel and Egypt failed to meet a Dec. 17 deadline set at Camp David for the signing of a peace treaty. Mr. Vance's trip to the Middle East to resolve the differences was unsuccessful, and created bitterness here because the Israelis felt that Washington had taken Egypt's side in the debate.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":true,\"adsDesktopHoldout\":true,\"adsHybrid\":true,\"adsMobile\":true,\"adsMobileHoldout\":false,\"bad\":false,\"index\":3},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"A low point was reached on Dec. 15 when the Israeli Cabinet, in a unanimous vote, appeared to close the door to further negotiations by rejecting all Egyptian proposals to amend the draft treaty. Since then, Mr. Begin has said that Israel is willing to discuss some but not all the Egyptian demands. The Government decision today and Prime Minister Begin's later remarks are part of the gradual movement back to the negotiating table.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":4},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[{\"__typename\":\"BoldFormat\",\"type\":null}],\"text\":\"Israel Would Review Security\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"In announcing agreement to resume the talks, Mr. Begin told reporters that Israel was prepared to discuss with Egypt its demand to review security arrangments in the Sinai Peninsula five years after a peace treaty is signed. Sinai, now under Israeli occupation, would be returned to Egypt under the peace treaty, but Egypt wants to eventually renegotiate the size of the military force it can deploy there.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":5},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Mr. Begin also said that Israel was prepared to discuss with the Egyptians further arrangements for Palestinian autonomy on the West Bank and Gaza. But the Prime Minister insisted that Israel would continue to resist Egyptian demands for setting a target date for the beginning of Palestinian autonomy.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":true,\"bad\":false,\"index\":6},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Egypt has tried to establish a connection between a peace treaty with Israel and the achievement of Palestinian selfrule. In recent days, Egyptian officials have also made clear that they expect Palestinian autonomy to lead to a Palestinian state.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":true,\"adsMobile\":true,\"adsMobileHoldout\":false,\"bad\":false,\"index\":7},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"The Israelis are strongly opposed to the creation of a Palestinian state, which they say would be a base for Soviet penetration of the area and for continued Palestinian terrorist attacks against Israel.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":true,\"adsDesktopHoldout\":true,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":8},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"The Israelis resisted linking a peace treaty to Palestinian autonomy because they contend that no one can predict the outcome of talks on autonomy, since such talks would involve Jordan and the Palestinians as well as Israel and Egypt. Until now, Jordan and the Palestinians have rejected any role in such talks.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":9},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[{\"__typename\":\"BoldFormat\",\"type\":null}],\"text\":\"Demands on Article VI Rejected\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Mr. Begin, in his remarks today, also turned down an Egyptian demand to revise Article VI of the draft treaty, which Egypt contends would make the pact with Israel supersede Egypt's defense treaties with other Arab nations. Mr. Begin contends that amending Article VI would render the treaty meaningless because, if another war broke out, Egypt might join other Arab countries against Israel.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":true,\"bad\":false,\"index\":10},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"“Israel will approach the United States Government with a view to insuring the sole and unequivocal meaning of this article of the peace treaty,” Mr. Begin said.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":true,\"adsMobile\":true,\"adsMobileHoldout\":false,\"bad\":false,\"index\":11},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"While the Cabinet met today to decide on the resumption of peace talks, the Israeli Army blocked an attempt by rightwing extremists to establish an illegal Jewish settlement on the West Bank. The squatters, members of Gush Emunim, or Faith Block, have been attempting to establish new settlements in the occupied areas, which provoke angry reactions from the Egyptian and American Governments.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":12},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"The Gush Emunim settlers justify their actions, by saying that the West Bank is part of Israel because it was inhabited by Jews in biblical times.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":true,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":13},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"In today's incident, army troops stopped a convoy of cars and trucks carrying 30 families to an area on the outskirts of Nablus, an Arab town. The squatters then stalled one of their trucks on the highway and piled stones across the road to block access to the Nablus area.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":true,\"bad\":false,\"index\":14},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[{\"__typename\":\"BoldFormat\",\"type\":null}],\"text\":\"Ambivalent Position on Settlements\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Israel's position on the new West Bank settlements has been ambivalent. The Government insists that Jews should have a right to live on the West Bank even after Palestinian autonomy comes, and considers the settlements part of an early‐warning defense system in case of another war. But in order not to interfere with the negotiations with Egypt, the Government froze the establishment of new camps on the West Bank until Dec. 17, when the peace treaty was to be signed.\"}],\"textAlign\":\"DEFAULT\"},{\"__typename\":\"Dropzone\",\"adsDesktop\":false,\"adsDesktopHoldout\":false,\"adsHybrid\":false,\"adsMobile\":false,\"adsMobileHoldout\":false,\"bad\":false,\"index\":15},{\"__typename\":\"ParagraphBlock\",\"content\":[{\"__typename\":\"TextInline\",\"formats\":[],\"text\":\"Since then, Government spokesmen have said that the existing 48 settlements there are being expanded and that preparations for new ones are under way. But attempts by Gush Emunim to start new settlements have been resisted on the ground that it is the Government's prerogative to decide when and where new camps should be established.\"}],\"textAlign\":\"DEFAULT\"}]},\"storyFormat\":null,\"storylines\":[],\"subsection\":null,\"summary\":\"Begins says Israel will continue talks with Egypt; illus (M)\",\"timesTags\":[{\"__typename\":\"Location\",\"associatedLegacyCollections\":[],\"displayName\":\"Middle East\",\"isAdvertisingBrandSensitive\":false,\"uri\":\"nyt:\\u002F\\u002Flocation\\u002F86f1b3c6-f5f2-5306-9c3c-1e3810df7b77\",\"vernacular\":\"Middle East\"},{\"__typename\":\"Subject\",\"associatedLegacyCollections\":[],\"displayName\":\"ISRAELI-ARAB CONFLICT\",\"isAdvertisingBrandSensitive\":false,\"uri\":\"nyt:\\u002F\\u002Fsubject\\u002F70c02663-e9ae-5604-894f-d6e79a059b64\",\"vernacular\":\"\"}],\"tone\":\"NO_TONE_SET\",\"translations\":[],\"type\":\"article\",\"typeOfMaterials\":[\"Archives\"],\"uri\":\"nyt:\\u002F\\u002Farticle\\u002F024d3615-c3f3-5dbe-9572-92f1c4b16f45\",\"url\":\"https:\\u002F\\u002Fwww.nytimes.com\\u002F1979\\u002F01\\u002F01\\u002Farchives\\u002Fisraelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"wordCount\":0}}},\"initialState\":{},\"config\":{\"gqlUrlClient\":\"https:\\u002F\\u002Fsamizdat-graphql.nytimes.com\\u002Fgraphql\\u002Fv2\",\"gqlRequestHeaders\":{\"nyt-app-type\":\"project-vi\",\"nyt-app-version\":\"0.0.5\",\"nyt-token\":\"MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAs+\\u002FoUCTBmD\\u002FcLdmcecrnBMHiU\\u002FpxQCn2DDyaPKUOXxi4p0uUSZQzsuq1pJ1m5z1i0YGPd1U1OeGHAChWtqoxC7bFMCXcwnE1oyui9G1uobgpm1GdhtwkR7ta7akVTcsF8zxiXx7DNXIPd2nIJFH83rmkZueKrC4JVaNzjvD+Z03piLn5bHWU6+w+rA+kyJtGgZNTXKyPh6EC6o5N+rknNMG5+CdTq35p8f99WjFawSvYgP9V64kgckbTbtdJ6YhVP58TnuYgr12urtwnIqWP9KSJ1e5vmgf3tunMqWNm6+AnsqNj8mCLdCuc5cEB74CwUeQcP2HQQmbCddBy2y0mEwIDAQAB\",\"x-nyt-internal-meter-override\":undefined,\"x-nyt-targeting-dimensions-map\":\"newsTenure=anon_user\"},\"gqlFetchTimeout\":1500,\"disablePersistedQueries\":false,\"initialDeviceType\":\"smartphone\",\"fastlyAbraConfig\":{\".ver\":\"22839.000\",\"AMS_FrictionCircumventionDesktop_cwv\":\"2_low-mid-truncation\",\"AMS_FrictionCircumventionMobile_cwv\":\"2_low-mid-truncation\",\"DFP_TopAd_Anon_0124\":\"0_Control\",\"HOME_cwv_chartbeat\":\"0_Control\",\"STYLN_synth_voice_web\":\"1_synth\"},\"fastlyEntitlements\":[],\"platform\":undefined,\"internalPreviewConfig\":{\"meter\":undefined,\"swg\":undefined},\"webviewEnvironment\":{\"isInWebview\":false,\"isPreloaded\":false},\"isOptimisticallyTruncated\":false,\"optimisticTruncationDropzone\":6,\"requestPath\":\"\\u002F1979\\u002F01\\u002F01\\u002Farchives\\u002Fisraelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"isProvisionallyLoggedIn\":false,\"routeName\":\"vi-story\",\"serviceWorkerFile\":\"service-worker-test-1736527629209.js\",\"preloadedServiceWorkerFile\":\"\\u002Fvi-assets\\u002Fstatic-assets\\u002Fpreloaded-service-worker-1736527809396.js\"},\"ssrQuery\":{},\"initialLocation\":{\"pathname\":\"\\u002F1979\\u002F01\\u002F01\\u002Farchives\\u002Fisraelis-decide-to-continue-talks-with-egypt-on-treaty-israel-would.html\",\"search\":\"\"}};</script>\n",
      "    \n",
      "    \n",
      "    \n",
      "    \n",
      "    <script>!function(){try{var e=\"undefined\"!=typeof window?window:\"undefined\"!=typeof global?global:\"undefined\"!=typeof self?self:{},a=(new Error).stack;a&&(e._sentryDebugIds=e._sentryDebugIds||{},e._sentryDebugIds[a]=\"b2311685-7f0c-4ae8-9731-833625fee65f\",e._sentryDebugIdIdentifier=\"sentry-dbid-b2311685-7f0c-4ae8-9731-833625fee65f\")}catch(e){}}();var _global=\"undefined\"!=typeof window?window:\"undefined\"!=typeof global?global:\"undefined\"!=typeof self?self:{};_global.SENTRY_RELEASE={id:\"74e0f0702bdea699e5b8f969d4a04ef588eead6b\"},function(e){function a(a){for(var c,f,s=a[0],t=a[1],r=a[2],i=0,l=[];i<s.length;i++)f=s[i],Object.prototype.hasOwnProperty.call(n,f)&&n[f]&&l.push(n[f][0]),n[f]=0;for(c in t)Object.prototype.hasOwnProperty.call(t,c)&&(e[c]=t[c]);for(b&&b(a);l.length;)l.shift()();return o.push.apply(o,r||[]),d()}function d(){for(var e,a=0;a<o.length;a++){for(var d=o[a],c=!0,s=1;s<d.length;s++){var t=d[s];0!==n[t]&&(c=!1)}c&&(o.splice(a--,1),e=f(f.s=d[0]))}return e}var c={},n={157:0},o=[];function f(a){if(c[a])return c[a].exports;var d=c[a]={i:a,l:!1,exports:{}};return e[a].call(d.exports,d,d.exports,f),d.l=!0,d.exports}f.e=function(e){var a=[],d=n[e];if(0!==d)if(d)a.push(d[2]);else{var c=new Promise((function(a,c){d=n[e]=[a,c]}));a.push(d[2]=c);var o,s=document.createElement(\"script\");s.charset=\"utf-8\",s.timeout=120,f.nc&&s.setAttribute(\"nonce\",f.nc),s.src=function(e){return f.p+\"\"+({0:\"vendor\",1:\"vendors~accessCodeLPAllAccess~accessCodeLPAudio~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHy~ae19e677\",2:\"vendors~account~byline~capsule~collections~explainer~getstarted~liveAsset~livePanel~newsletter~newsl~4452fd02\",4:\"vendors~audio~bestsellers~card~collections~explainer~home~liveAsset~markets~paidpost~reviews~search~~b0abd9a2\",5:\"vendors~audio~byline~capsule~card~cardpanel~clientSideCapsule~collections~explainer~liveAsset~livePa~5a3d4357\",6:\"vendors~activateAudioLoginPage~allAccessLandingPage~athleticGiftLandingPage~audioLandingPage~brandLa~c146d5af\",7:\"vendors~activateAudioLoginPage~allAccessLandingPage~athleticGiftLandingPage~brandLandingPage~gamesGi~c8843a55\",8:\"vendors~audio~byline~capsule~carddeck~cardpanel~clientSideCapsule~home~livePanel~paidpost~trending~video\",9:\"vendors~accessCodeLPAllAccess~accessCodeLPAudio~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHy~8802538a\",10:\"vendors~accessCodeLPAllAccess~accessCodeLPAudio~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHy~bb6edae8\",11:\"vendors~accessCodeLPAllAccess~accessCodeLPAudio~accessCodeLPCooking~accessCodeLPGames~accessCodeLPHy~ed77dc00\",12:\"vendors~allAccessLandingPage~athleticLandingPage~audioLandingPage~cookingLandingPage~gamesLandingPag~099147f0\",13:\"vendors~getstarted~newsletter~newsletters~newsletterssubscriberonly~recirculation~welcomesubscriber~~a6f3c374\",14:\"bestsellers~markets~reviews~search~trending~your-list\",15:\"vendors~athleticGiftLandingPage~audioLandingPage~brandLandingPage~cookingLandingPage~gamesGiftLandin~ec1ed55f\",16:\"account~activateaccess~newslettersmanage~newslettersoptout~newslettersreengagement\",17:\"giftArticles~onboardingTopicsBottomSheet~subRecircBottomSheet~timeswire\",18:\"newsletter~newsletters~newsletterssubscriberonly~your-places-global-update\",19:\"vendors~CardDeck~carddeck~cardpanel~home\",20:\"vendors~card~clientSideCapsule~slideshow\",21:\"vendors~giftArticles~timeswire~your-list\",24:\"caHamburgerNestedNavData~nestedNav\",25:\"commentsForm~commentsV2\",26:\"emailsignup~your-space\",27:\"internationalHamburgerNestedNavData\",28:\"markets~reviews\",29:\"nestedNav~usHamburgerNestedNavData\",30:\"onboardingTopicsBottomSheet~subRecircBottomSheet\",31:\"vendors~account~newslettersoptout\",32:\"vendors~gamesOnboardingOfferLandingPage~newsOnboardingOfferLandingPage\",33:\"vendors~getstarted~welcomesubscriber\",34:\"vendors~groupsHigherEdLandingPage~groupsLandingPage\",39:\"CardDeck\",40:\"ChineseHanLogo\",41:\"DealbookLogo\",42:\"InsiderLogo\",43:\"NYTCommunitiesFundHeader\",44:\"Rio2016\",45:\"SportsFromTheAthleticLogo\",46:\"TMagazineLogo\",47:\"UpshotLogo\",48:\"WorldCupLogo2018\",49:\"accessCodeLPAllAccess\",50:\"accessCodeLPAudio\",51:\"accessCodeLPCooking\",52:\"accessCodeLPGames\",53:\"accessCodeLPHyundaicard\",54:\"accessCodeLPNews\",55:\"accessCodeLPNexo\",56:\"accessCodeLPTheAthletic\",57:\"accessCodeLPWirecutter\",58:\"account\",59:\"activateAudioLoginPage\",60:\"activateaccess\",61:\"additionalPlaylists\",63:\"allAccessLandingPage\",64:\"ask\",65:\"athleticGiftLandingPage\",66:\"athleticLandingPage\",67:\"audio\",68:\"audioApp\",69:\"audioLandingPage\",70:\"audioblock\",71:\"autoSave\",72:\"bestsellers\",73:\"blank\",74:\"book-review\",75:\"brandLandingPage\",76:\"byline\",77:\"caHamburgerNestedNavData\",78:\"canadaSiteIndexData\",79:\"canonicalUrlOverride\",80:\"capsule\",81:\"card\",82:\"carddeck\",83:\"carddeckadslot\",84:\"cardpanel\",85:\"clientSideCapsule\",86:\"collectionnewsletterform\",87:\"collections\",88:\"commentsForm\",89:\"commentsV2\",90:\"cookingAppDownloadLandingPage\",91:\"cookingLandingPage\",92:\"datasubjectrequest\",93:\"datasubjectrequestverification\",94:\"dealbook\",95:\"defaultSiteIndexData\",96:\"desktopLogoNav\",97:\"emailsignup\",98:\"episodefooter\",99:\"esHamburgerNestedNavData\",100:\"explainer\",101:\"explainerPostHeader\",102:\"explainerRecirculation\",103:\"fabActual\",104:\"featuredproperties\",105:\"foo\",106:\"gamesGiftLandingPage\",107:\"gamesLandingPage\",108:\"gamesOnboardingOfferLandingPage\",109:\"gatewayLandingPage\",110:\"getstarted\",111:\"giftArticles\",112:\"giftLandingPage\",113:\"groupsHigherEdLandingPage\",114:\"groupsLandingPage\",115:\"hamburgerDrawer\",116:\"headerfullbleedhorizontal\",117:\"headerfullbleedvertical\",118:\"headerlivebriefingvi\",119:\"home\",120:\"homeDeliveryLandingPage\",121:\"hyundaiCardLandingPage\",122:\"instacartLandingPage\",124:\"internationalSiteIndexData\",125:\"leMondeLandingPage\",126:\"lens\",127:\"liveAsset\",128:\"livePanel\",129:\"livePostHeader\",130:\"lottieJSON\",132:\"markets\",133:\"mortgagecalculator\",134:\"nestedNav\",135:\"newsAppLandingPage\",136:\"newsOnboardingOfferLandingPage\",137:\"newsletter\",138:\"newsletterRecirculation\",139:\"newsletters\",140:\"newslettersmanage\",141:\"newslettersoptout\",142:\"newslettersreengagement\",143:\"newsletterssubscriberonly\",144:\"onboardingTopicsBottomSheet\",145:\"onsiteMessagingExampleLP\",146:\"opinion\",147:\"paidpost\",148:\"privacy\",149:\"producernotes\",150:\"query-and-select\",151:\"recirculation\",152:\"related-coverage-chunk\",153:\"reviewheader\",154:\"reviews\",158:\"search\",159:\"siteIndexContent\",160:\"sitemap\",161:\"slideshow\",162:\"slideshowinline\",163:\"stickyfilljs\",164:\"story\",165:\"subRecircBottomSheet\",166:\"subscribeWithGoogleLP\",167:\"surveywithdrawconsent\",168:\"tabActual\",169:\"timeswire\",170:\"trending\",171:\"upshot\",172:\"usHamburgerNestedNavData\",173:\"vanity\",175:\"vendors~athleticLandingPage\",176:\"vendors~audioblock\",177:\"vendors~bestsellers\",178:\"vendors~carddeck\",179:\"vendors~charlatan-select\",180:\"vendors~commentsForm\",181:\"vendors~cookingAppDownloadLandingPage\",182:\"vendors~emailsignup\",183:\"vendors~episodefooter\",184:\"vendors~explainerRecirculation\",185:\"vendors~giftArticles\",186:\"vendors~headerfullbleedhorizontal\",187:\"vendors~headerfullbleedvertical\",188:\"vendors~homeDeliveryLandingPage\",189:\"vendors~instacartLandingPage\",190:\"vendors~mortgagecalculator\",191:\"vendors~newsAppLandingPage\",192:\"vendors~producernotes\",193:\"vendors~recirculation\",194:\"vendors~reviewheader\",195:\"vendors~search\",196:\"vendors~slideshowinline\",197:\"vendors~subscribeWithGoogleLP\",198:\"vendors~viToolbar\",199:\"vendors~videoblock\",200:\"vendors~wellContent\",201:\"viToolbar\",202:\"video\",203:\"videoblock\",204:\"welcomeBannerGames\",205:\"welcomesubscriber\",206:\"wellContent\",207:\"wirecutterLandingPage\",208:\"world-cup-2019\",209:\"xpnMobileCooking\",210:\"xpnMobileWirecutter\",211:\"your-list\",212:\"your-places-global-update\",213:\"your-space\"}[e]||e)+\"-\"+{0:\"70116d46c67dc77184bd\",1:\"c2e4431013c53a459a8a\",2:\"0fb68f92f6e882b5349c\",3:\"3055f7937d7e435c358e\",4:\"56ab4f4701ee63d3261e\",5:\"e6967ec074864fcb0df7\",6:\"fc570e1cdf42789ccedf\",7:\"4451c910959b096072df\",8:\"a0c6dd032d669c9f2564\",9:\"c2a3497612e344be2f74\",10:\"751b7e498babcb8d9b60\",11:\"204b6425b03cc931482b\",12:\"c873d9aea929b7e68512\",13:\"02a9f64efc1b35a3cc63\",14:\"5844f56e5efd8b97b996\",15:\"07f945762fe42f70c5bb\",16:\"5492bd7f84d924498c23\",17:\"499b0915d1bc96e0d821\",18:\"48f1742508842deb8b88\",19:\"70cc5ae4534e8c599255\",20:\"50279f10c07331cd949f\",21:\"d7a71c3d5f2f67018b4b\",22:\"d748d858b400ca5d46ec\",23:\"296c1e4baa50e6e6f183\",24:\"5c482618b1bc9289c5c5\",25:\"0a794fbb0dd7e244ae82\",26:\"f56cd23d304bb7bab718\",27:\"775fc340d2d253f99883\",28:\"653d35c327f7bdc42a1a\",29:\"01af666039d8436038d2\",30:\"063b6412ca7f1930ba6d\",31:\"b0d611c347dbab6e2479\",32:\"98673e765a76a997cfa1\",33:\"c928c13ecfbbdb099a5b\",34:\"b318dd7fc2f8c1470141\",35:\"22f6060ca37bab2aca2d\",36:\"7f2bcd38dc720cecc9b0\",37:\"28406ac0272296a34bf6\",38:\"5f303cc428c26b402386\",39:\"0d00124af6702f91cc21\",40:\"a152505736b4d3b5b85a\",41:\"70dfaba16bcaa6ccbeff\",42:\"b4960b085454f84041b8\",43:\"11f644ca0cfee24994b6\",44:\"dec4455c4ceef51a50e0\",45:\"afd8ff38444e212f5ddf\",46:\"ed9ab8d97adee6583695\",47:\"8673e0cf75876c8706ae\",48:\"260f2c476592a2946c3a\",49:\"3e06a9ffc7cf2f28eae5\",50:\"187280416391b4caa37a\",51:\"79032accffb744b158b3\",52:\"e09345ad6375ca701c0a\",53:\"00720efaddbb5b264da7\",54:\"bc53f44d41ab5f236612\",55:\"a241742b64f28b08dfe8\",56:\"90f1d8735b8a8f28dadf\",57:\"017d10503daae26f6630\",58:\"fe64199e4683d1810ef7\",59:\"5e42cedbbbea50d17812\",60:\"c7ff3dea9df5b268383c\",61:\"5a8423fd7859dfce38da\",63:\"7418daad738f50768fe7\",64:\"1e4fa9febee15b3bc522\",65:\"5ac0005bc39461659adc\",66:\"e83060d4a3659c820907\",67:\"aafb445d0ca440beae94\",68:\"483540fa8376dabc7738\",69:\"ff00ea64aa7ec12fc8ac\",70:\"3f0952afd176bf250059\",71:\"06c8c822f4fd1d06fc73\",72:\"524eeffa2e40ae24b7e9\",73:\"8cf35d00bcaca1179d1a\",74:\"50f882f7bc112c50e517\",75:\"702ab7961b2f44027b7a\",76:\"cac7fa4d32968d8a253f\",77:\"68f520838d64b4420d0e\",78:\"e6c5111965ce34911389\",79:\"10bf36b6f4438fd8afdd\",80:\"5d4d7c135bea99d97b76\",81:\"23d5eed41d34bcd62270\",82:\"4cf86443c6d0c7bac8cc\",83:\"6ae05f177db5761e2557\",84:\"dc600a9334067f5dae94\",85:\"78e22084cd47d586343e\",86:\"adca8dd86c70e8ec293b\",87:\"9a599d3804a6f1c1db78\",88:\"de6e39e2cf220c4e3201\",89:\"9070f577f9e16d01c241\",90:\"ac7a56cea8a2aaca2316\",91:\"3dd47122c147009bd827\",92:\"6f2de7ce33e09eda94fa\",93:\"2d8f0438099ceae4b293\",94:\"2f8e5ac46833f54a643d\",95:\"29533c81f7cda40294c0\",96:\"b921b7739dc8c0bdbd8f\",97:\"f70685b70c24fa50c2ce\",98:\"24f771ac38271d91acc7\",99:\"a2b5d3d1e733c8e08b77\",100:\"f655ea0a67fe97102a80\",101:\"60928cde978d38683103\",102:\"d7415231127e0cc2cbe3\",103:\"9e91e01634cbd6ec339c\",104:\"5e754174415f1b78f2dc\",105:\"8fc4aade34920a4aada4\",106:\"4e6d5da468bf25cd5095\",107:\"c71bb384db86ed79f44c\",108:\"a75887e393ec2e3e12f2\",109:\"ad6b5503f9b7d6614088\",110:\"3dad5056f891acfd0d5e\",111:\"667cbf504f1172977f96\",112:\"15a47697adc7edef17ee\",113:\"240d7897dd8c036e5df6\",114:\"70f72342d5146b87d2f3\",115:\"8e03ceae280706dca587\",116:\"14a594a93fa72ade78e4\",117:\"41c895ecad2aff17936f\",118:\"a4fd64dd1ad652a891df\",119:\"02c22d6c0c0b7fff1bbc\",120:\"a9d45ee2e895f1f5a449\",121:\"8939b746cc6e5ae75f8b\",122:\"a5cff675f739dd9ef63d\",124:\"95b891cd64fd2e4aaeed\",125:\"4fcd701dc7453682db7e\",126:\"df06a3311e5d673f3d5c\",127:\"0dc2567b294e0295e740\",128:\"5c04dbcfd800215e618a\",129:\"f7a61950c7cb1e7cb4c7\",130:\"f611e8570c19f44024b8\",132:\"121d34e8c70b9ed31f90\",133:\"6ffb6fbf1f19a4459014\",134:\"18897ef7245226e80b6e\",135:\"fa190ba6daa818252e11\",136:\"56dd48a875fec8b694c5\",137:\"55abc33f95d786e389fb\",138:\"37be7b4e0ee42618cf5f\",139:\"8904b81ba0b4cbb7919c\",140:\"6bc5b21c8ed6c4bb2add\",141:\"0cd530b0a11c9f8e3253\",142:\"840cedab5cb8fbd2727e\",143:\"c64723fa7dfc45ecc44b\",144:\"286e4a464469421569d2\",145:\"3f22482f807886c98b76\",146:\"0579cc594686e88d649a\",147:\"66d5f3bc74d3b3603a50\",148:\"f9e5eb1215e7c915e57a\",149:\"18aa6530ed92c5511a1b\",150:\"da5d5088507fb8f17100\",151:\"24fc420d1f14fc0f3a17\",152:\"c1a3a9cf391f11bbb1c6\",153:\"74c61aab762d8431ee83\",154:\"6a7651f655a10c999d6f\",158:\"00acdab7eed697940ff9\",159:\"b760ead686926196fca8\",160:\"6289ac2de025a40fc009\",161:\"523b9229b7fa80b024eb\",162:\"b6fc081fb4855db3c42a\",163:\"adcbed4248f51590efdf\",164:\"50e88d504092ff7d5be0\",165:\"b0b4c5bfa177c3d2015c\",166:\"be30a7ee4611cbf6ac16\",167:\"a63a66835e68675d93c0\",168:\"2672ac97bf453f75a426\",169:\"001571e5c86963b02b24\",170:\"03cabcae0a969ec62680\",171:\"106423b709fd55d80bb7\",172:\"709926913169fbffb9b8\",173:\"1cf13fbd75bd1dd49195\",175:\"e3ab590cbf3e0882ceeb\",176:\"ddf175adda7f4e8b5b19\",177:\"2b27e0b7682a5c4d42b5\",178:\"f2c1c8c51e057c4f49df\",179:\"b4167a07334934972863\",180:\"0d699e0fe6e4422e0dfc\",181:\"02f16c0a3e88d3b6472f\",182:\"92bdb3068a3ec7f979b1\",183:\"e19869ca4203cb154430\",184:\"a5753a2f00db6d285cdb\",185:\"4c6a1d6acead43266f9c\",186:\"8fe875eb694142a9480b\",187:\"924207da1885a98d3d9a\",188:\"790e1a74ada943d47432\",189:\"3c3c640342639cc0701b\",190:\"2407d26bcd97c88376db\",191:\"79b54192d90f7d98223d\",192:\"e1d3aae6f1d196b2f6d9\",193:\"14e23870bae856660afc\",194:\"e68b009411a16d024be5\",195:\"f339cf800c47e3ece353\",196:\"841ca6d8f813ecfcd852\",197:\"d674459e44e9e4293ae6\",198:\"a39639f05e148a06ddc3\",199:\"771dda1103026fb68865\",200:\"beb038859e50e60765cd\",201:\"f12f636d81cb24f3b377\",202:\"ead49f1471ef9c9c0d6f\",203:\"991105146d8d1b2ae2b4\",204:\"4ffb39440fd10aa1608f\",205:\"cd261f8aa743305edf49\",206:\"c1f81c615e4e504a15c8\",207:\"c75e5d3c785d92236a62\",208:\"9549db63bef3a7b69884\",209:\"8d62919189ffc9df3cf9\",210:\"5b38afc639c1a5ef6a5f\",211:\"67baf1473fb4e15755af\",212:\"bd0cfa744e6f9eebf413\",213:\"1acff8778f44a121142d\",214:\"a3ab34c8137f2a6bf948\",215:\"ab30fb21ba1397b62ab8\",216:\"71c22f7e256b4870541b\",217:\"caf71a5a4244e7c37586\",218:\"f15fc440884fd6e714cf\",219:\"03c59d273ad2eded42c0\",220:\"d83d00e733f14453c29b\",221:\"4ed53e5a6d35ec60a9d4\",222:\"1fc5d94f1e328e5c5a71\",223:\"a461e82ae73967806e9f\",224:\"f32d8b634cbd44d71569\",225:\"5ff01d86cefa7a40d283\",226:\"2cb5d0acaa9309a282ec\",227:\"172af9c5ac911df41865\",228:\"0d958b659cda67cfdb92\",229:\"a8544163537a2b0292d1\",230:\"b8e62377145ea50cf637\",231:\"217fdee3aebbe84e2ab4\",232:\"76de2faa19d622abd165\"}[e]+\".js\"}(e);var t=new Error;o=function(a){s.onerror=s.onload=null,clearTimeout(r);var d=n[e];if(0!==d){if(d){var c=a&&(\"load\"===a.type?\"missing\":a.type),o=a&&a.target&&a.target.src;t.message=\"Loading chunk \"+e+\" failed.\\n(\"+c+\": \"+o+\")\",t.name=\"ChunkLoadError\",t.type=c,t.request=o,d[1](t)}n[e]=void 0}};var r=setTimeout((function(){o({type:\"timeout\",target:s})}),12e4);s.onerror=s.onload=o,document.head.appendChild(s)}return Promise.all(a)},f.m=e,f.c=c,f.d=function(e,a,d){f.o(e,a)||Object.defineProperty(e,a,{enumerable:!0,get:d})},f.r=function(e){\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(e,\"__esModule\",{value:!0})},f.t=function(e,a){if(1&a&&(e=f(e)),8&a)return e;if(4&a&&\"object\"==typeof e&&e&&e.__esModule)return e;var d=Object.create(null);if(f.r(d),Object.defineProperty(d,\"default\",{enumerable:!0,value:e}),2&a&&\"string\"!=typeof e)for(var c in e)f.d(d,c,function(a){return e[a]}.bind(null,c));return d},f.n=function(e){var a=e&&e.__esModule?function(){return e.default}:function(){return e};return f.d(a,\"a\",a),a},f.o=function(e,a){return Object.prototype.hasOwnProperty.call(e,a)},f.p=\"/vi-assets/static-assets/\",f.oe=function(e){throw console.error(e),e};var s=window.webpackJsonp=window.webpackJsonp||[],t=s.push.bind(s);s.push=a,s=s.slice();for(var r=0;r<s.length;r++)a(s[r]);var b=t;d()}([]);\n",
      "//# sourceMappingURL=runtime~main-545de8f35673a33ce5a3.js.map</script>\n",
      "    <script defer src=\"/vi-assets/static-assets/vendor-70116d46c67dc77184bd.js\"></script>\n",
      "    <script defer src=\"/vi-assets/static-assets/story-50e88d504092ff7d5be0.js\"></script>\n",
      "<script defer src=\"/vi-assets/static-assets/defaultSiteIndexData-29533c81f7cda40294c0.js\"></script>\n",
      "<script defer src=\"/vi-assets/static-assets/siteIndexContent-b760ead686926196fca8.js\"></script>\n",
      "    \n",
      "    <script defer src=\"/vi-assets/static-assets/main-3d5c607f4241e8540d75.js\"></script>\n",
      "    <script>(function () { var _f=function(){try{var e=[\"first-paint\",\"first-contentful-paint\",\"userBtnRender\",\"appRenderTime\"];new window.PerformanceObserver(function(r){for(var n=r.getEntries(),a=0;a<n.length;a+=1){var t=n[a];if(e.indexOf(t.name)>-1){var i={};i[t.name]=Math.round(t.duration||t.startTime),(window.dataLayer=window.dataLayer||[]).push({event:\"performance\",pageview:{performance:i}})}}}).observe({entryTypes:[\"mark\",\"measure\",\"paint\"]})}catch(e){}};;_f.apply(null, []); })();(function () { var _f=function(){!function(){if(1===Math.floor(20*Math.random())&&(!window.BOOMR||!window.BOOMR.version&&!window.BOOMR.snippetExecuted)){window.BOOMR=window.BOOMR||{},window.BOOMR.snippetStart=(new Date).getTime(),window.BOOMR.snippetExecuted=!0,window.BOOMR.snippetVersion=14,window.BOOMR.url=\"https://s.go-mpulse.net/boomerang/ATH8A-MAMN8-XPXCH-N5KAX-8D239\";var e=(document.currentScript||document.getElementsByTagName(\"script\")[0]).parentNode,n=!1,t=document.createElement(\"link\");t.relList&&\"function\"==typeof t.relList.supports&&t.relList.supports(\"preload\")&&\"as\"in t?(window.BOOMR.snippetMethod=\"p\",t.href=window.BOOMR.url,t.rel=\"preload\",t.as=\"script\",t.addEventListener(\"load\",function(){if(!n){var t=document.createElement(\"script\");t.id=\"boomr-scr-as\",t.src=window.BOOMR.url,t.async=!0,e.appendChild(t),n=!0}}),t.addEventListener(\"error\",function(){o(!0)}),setTimeout(function(){n||o(!0)},3e3),BOOMR_lstart=(new Date).getTime(),e.appendChild(t)):o(!1),window.addEventListener?window.addEventListener(\"load\",i,!1):window.attachEvent&&window.attachEvent(\"onload\",i)}function o(t){n=!0;var o,i,d,a,r=document,s=window;if(window.BOOMR.snippetMethod=t?\"if\":\"i\",i=function(e,n){var t=r.createElement(\"script\");t.id=n||\"boomr-if-as\",t.src=window.BOOMR.url,BOOMR_lstart=(new Date).getTime(),(e=e||r.body).appendChild(t)},!window.addEventListener&&window.attachEvent&&navigator.userAgent.match(/MSIE [67]./))return window.BOOMR.snippetMethod=\"s\",void i(e,\"boomr-async\");(d=document.createElement(\"IFRAME\")).src=\"about:blank\",d.title=\"\",d.role=\"presentation\",d.loading=\"eager\",(a=(d.frameElement||d).style).width=0,a.height=0,a.border=0,a.display=\"none\",e.appendChild(d);try{s=d.contentWindow,r=s.document.open()}catch(e){o=document.domain,d.src=\"javascript:var d=document.open();d.domain='\"+o+\"';void 0;\",s=d.contentWindow,r=s.document.open()}o?(r._boomrl=function(){this.domain=o,i()},r.write(\"<body onload='document._boomrl();'>\")):(s._boomrl=function(){i()},s.addEventListener?s.addEventListener(\"load\",s._boomrl,!1):s.attachEvent&&s.attachEvent(\"onload\",s._boomrl)),r.close()}function i(e){window.BOOMR_onload=e&&e.timeStamp||(new Date).getTime()}}()};;_f.apply(null, []); })();</script>\n",
      "    \n",
      "    <script>\n",
      "    (function(){\n",
      "      if (document.cookie.indexOf('NYT-S') === -1) {\n",
      "        var iframe = document.createElement('iframe');\n",
      "        iframe.height = 0;\n",
      "        iframe.width = 0;\n",
      "        iframe.style.display = 'none';\n",
      "        iframe.style.visibility = 'hidden';\n",
      "        iframe.src = 'https://myaccount.nytimes.com/auth/prefetch-assets';\n",
      "        document.body.appendChild(iframe);\n",
      "      }\n",
      "    })();\n",
      "    </script>\n",
      "  \n",
      "    <script>\n",
      "(function(w, l) {\n",
      "  w[l] = w[l] || [];\n",
      "  w[l].push({\n",
      "    'gtm.start': new Date().getTime(),\n",
      "    event: 'gtm.js'\n",
      "  });\n",
      "})(window, 'dataLayer');\n",
      "</script>\n",
      "<script defer src=\"https://www.googletagmanager.com/gtm.js?id=GTM-P528B3&gtm_auth=tfAzqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x\"></script>\n",
      "<noscript>\n",
      "<iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-P528B3&gtm_auth=tfAzqo1rYDLgYhmTnSjPqw&gtm_preview=env-130&gtm_cookies_win=x\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe>\n",
      "</noscript>\n",
      "    <!-- RELEASE 74e0f0702bdea699e5b8f969d4a04ef588eead6b -->\n",
      "    \n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T18:26:34.622255Z",
     "start_time": "2025-01-10T18:26:28.639174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from newspaper import Article\n",
    "\n",
    "for url in [x['web_url'] for x in result.json()['response']['docs']]:\n",
    "    # Wait for the page to load and get the html\n",
    "    html = requests.get(url, headers=headers).text\n",
    "    article = Article(url)\n",
    "    article.download(input_html=html)\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    print(\"------------------\")\n",
    "    print(article.title)\n",
    "    print(article.text)\n",
    "    print()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Israelis Decide to Continue Talks With Egypt on Treaty\n",
      "A low point was reached on Dec. 15 when the Israeli Cabinet, in a unanimous vote, appeared to close the door to further negotiations by rejecting all Egyptian proposals to amend the draft treaty. Since then, Mr. Begin has said that Israel is willing to discuss some but not all the Egyptian demands. The Government decision today and Prime Minister Begin's later remarks are part of the gradual movement back to the negotiating table.\n",
      "\n",
      "Israel Would Review Security\n",
      "\n",
      "In announcing agreement to resume the talks, Mr. Begin told reporters that Israel was prepared to discuss with Egypt its demand to review security arrangments in the Sinai Peninsula five years after a peace treaty is signed. Sinai, now under Israeli occupation, would be returned to Egypt under the peace treaty, but Egypt wants to eventually renegotiate the size of the military force it can deploy there.\n",
      "\n",
      "Mr. Begin also said that Israel was prepared to discuss with the Egyptians further arrangements for Palestinian autonomy on the West Bank and Gaza. But the Prime Minister insisted that Israel would continue to resist Egyptian demands for setting a target date for the beginning of Palestinian autonomy.\n",
      "\n",
      "Egypt has tried to establish a connection between a peace treaty with Israel and the achievement of Palestinian selfrule. In recent days, Egyptian officials have also made clear that they expect Palestinian autonomy to lead to a Palestinian state.\n",
      "\n",
      "The Israelis are strongly opposed to the creation of a Palestinian state, which they say would be a base for Soviet penetration of the area and for continued Palestinian terrorist attacks against Israel.\n",
      "\n",
      "------------------\n",
      "New Quarters of Badillo Are a Credit to His Office\n",
      "The desirable City Hall office that belonged to David W. Brown is going to Mr. Brown's title of Deputy Mayor for Policy. The office, which has glass doors ands vaulted ceiling, is twice the size of Mr, Badillo's former office, which was down a back passageway from the Mayor's, Mr, Badillo's new space is at the end of the main hallway of City Hall.\n",
      "\n",
      "Mayor. Koch has gone out of his way to reassure Mr. Bailie and his other Deputy Mayors that no one had been downgraded during the recent reshuffling of key jobs, He opened a cabinet meeting the other morning by telling his Deputy Mayors that he thought he had given all of them what they wanted. Mr. Badillo had told several people close to him that he was hurt by news paper reports that he had not Seen the big winner in the job shifts.\n",
      "\n",
      "“Herman Badillo's considerable talents have not been utilized fully during the lait year,” Mr. Koch said last week. “I intend to change that in the corning year.”\n",
      "\n",
      "In addition to getting Mr. Brown's office, Mr. Badillo will also get the half hour a day with the Mayor that had been part of Mr. Brown's schedule. But Mr. Koch agreed that he and Mr. Badillo did not have the “special relationship” based on 10 years of friendship that he and Mr. Brown have.\n",
      "\n",
      "------------------\n",
      "Rockland Seeks Way to Restrict Nuclear Wastes\n",
      "NEW CITY, N.Y., Dec. 29 — Following reports that radioactive wastes and materials from atomic reactor plants in the Northeast were being shipped regularly through Rockland County to processing areas in the South and West, the county's officials are considering following the lead of New York City in severely limiting such shipments.\n",
      "\n",
      "On Jan. 17, the Rockland County Board of Health is scheduled to consider a request by the County Legislature to investigate the feasibility of adopting a measure similar to New York City's, which requires a permit to ship large quantities of such materials into or through the county's borders.\n",
      "\n",
      "According to local officials, Rockland County would become the second governmental body in the state to enact such controls if the proposed measure is adopted. The New York City ban was enacted almost three years ago and has been allowed to staid by Federal authorities who are, nevertheless, aparently considering moving into this field with their own regulations.\n",
      "\n",
      "Marie Naismith, president of the Rockland County Board of Health, said today that she was unable to gauge sentiment so far among the seven board members because they had not yet met to discuss the proposed measure. “We're awaiting reports from various groups on what's Wing transported, how and on what routes,” she said.\n",
      "\n",
      "------------------\n",
      "The New York Times\n",
      "About the Archive\n",
      "\n",
      "This is a digitized version of an article from The Times’s print archive, before the start of online publication in 1996. To preserve these articles as they originally appeared, The Times does not alter, edit or update them.\n",
      "\n",
      "Occasionally the digitization process introduces transcription errors or other problems; we are continuing to work to improve these archived versions.\n",
      "\n",
      "------------------\n",
      "U.S. and Philippines Reach Accord On Aid and Use of Military Bases\n",
      "In addition, the Carter Administration will pledge its best efforts to obtain Congressional approval of $450 million to $500 million in aid to the Philippines, starting in the next fiscal year. The total is to be broken down into $50 million in grant military aid, $250 million in military credits and $150 to $200 million in economic support.\n",
      "\n",
      "Manila Already a Major Aid Recipient\n",
      "\n",
      "The Philippines already is a major recipient of American aid, getting about $37 million yearly in military assistance and about $100 million in economic aid, mostly in projects and agricultural goods under the Food for Peace program. The increase provided in the new program will be to raise the military aid to about $60 million a year.\n",
      "\n",
      "The agreement had been sought for a long time by the United States to end question about the ability of the American military forces to retain key bases in the Pacific.\n",
      "\n",
      "“The bdses in the Philippines, Clark Air Base, and the Subic Bay Naval complex, are important to our ability to project United States military strength throughout the Pacific,” Thomas Reston, a State Department spokesman, said today.\n",
      "\n",
      "“The steps we will take to give clearer expression to Filipino sovereignty over the bases will assure the durability of our defense relationship and thereby serve to preserve peace and stability in the region,” he said.\n",
      "\n",
      "------------------\n",
      "An Author of Books Is Not Entitled To News Protection, a Justice Says\n",
      "The author of a book is not a journalist and is not entitled to a journalist's protections under the New York State “shield law” and the Constitution of the United States, a State Supreme Court justice in Brooklyn has ruled.\n",
      "\n",
      "In what some legal authorities believe Is the first time the matter has been decided by any court, Justice Sybil Hart Hooper drew a distinction between the rights of working journalists and of authors of books in her refusal to quash a subpoena served on Lee Hays, a former television producer.\n",
      "\n",
      "Mr. Hays, who won the Peabody Award for his television work, is writing a book about the family of Navatro LeGrand. Various members of the Brooklyn family have been linked to a total of six murders. Mr. LeGrand is facing an upcoming trial for two of them.\n",
      "\n",
      "An Appeal Is Expected\n",
      "\n",
      "Joel Ezra, a lawyer for Mr. LeGrand, had asked for notes and tapes of interviews that Mr. Hays had conducted with Willie Frank Holman, who is expected to be a prosecution witness at Mr. LeGrand's trial.\n",
      "\n",
      "------------------\n",
      "U.S. EMBASSY IN IRAN ADVISES DEPARTURE OF ALL DEPENDENTS\n",
      "Diplomats said that a survey would be made of people who want to go and that arrangements would be made for them to fly out on scheduled commercial flights and perhaps on chartered flights. An embassy official .said it was expected the United States Government would pay only the air fares of the dependents of Government employees.\n",
      "\n",
      "Diplomats expressed muted hope that conciliation efforts by some opposition leaders might mollify the oilfield strikers to permit an increase in oil production. Iran's lucrative oil exports have come to a halt, and production is only a fraction of the country's domestic needs.\n",
      "\n",
      "One diplomat said: “If this works, emotions may calm down somewhat. But if it doesn't and we do reach the point in day or two where the flour mills cease to function, we may see some most grisly scenes.”\n",
      "\n",
      "No Deaths Reported in Capital\n",
      "\n",
      "Crowds of youths continued to pour through downtown Teheran yesterday, chanting slogans against the Shah and Mr. Bakhtiar and lighting bonfires in the streets to harass the troops deployed around the city. Despite repeated gunfire, no deaths were reported here, and the level of rioting seemed to have declined somewhat since Saturday.\n",
      "\n",
      "But in Meshed, according to several opposition accounts, the violence was bitter, with dissidents publicly hanging at least one agent of Savak, the Shah's secret police. Troops were reported to have used armored vehicles against civilians and civilian targets, including the home of the 88‐year‐old Ayatollah Shirazi, who claims descent from the prophet Mo. hammed. The Ayatollah was said to have escaped unharmed.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnewspaper\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Article\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m url \u001B[38;5;129;01min\u001B[39;00m [x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweb_url\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m result\u001B[38;5;241m.\u001B[39mjson()[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocs\u001B[39m\u001B[38;5;124m'\u001B[39m]]:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# Wait for the page to load and get the html\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m     html \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m      6\u001B[0m     article \u001B[38;5;241m=\u001B[39m Article(url)\n\u001B[1;32m      7\u001B[0m     article\u001B[38;5;241m.\u001B[39mdownload(input_html\u001B[38;5;241m=\u001B[39mhtml)\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:464\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    462\u001B[0m     \u001B[38;5;66;03m# Trigger any extra validation we need to do.\u001B[39;00m\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 464\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_conn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    466\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mconn\u001B[38;5;241m.\u001B[39mtimeout)\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1093\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._validate_conn\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;66;03m# Force connect early to allow us to validate the connection.\u001B[39;00m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_closed:\n\u001B[0;32m-> 1093\u001B[0m     \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mis_verified \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m conn\u001B[38;5;241m.\u001B[39mproxy_is_verified:\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/connection.py:741\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    738\u001B[0m     \u001B[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001B[39;00m\n\u001B[1;32m    739\u001B[0m     server_hostname_rm_dot \u001B[38;5;241m=\u001B[39m server_hostname\u001B[38;5;241m.\u001B[39mrstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 741\u001B[0m     sock_and_verified \u001B[38;5;241m=\u001B[39m \u001B[43m_ssl_wrap_socket_and_match_hostname\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    742\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    743\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcert_reqs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_reqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    744\u001B[0m \u001B[43m        \u001B[49m\u001B[43mssl_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mssl_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    745\u001B[0m \u001B[43m        \u001B[49m\u001B[43mssl_minimum_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mssl_minimum_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    746\u001B[0m \u001B[43m        \u001B[49m\u001B[43mssl_maximum_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mssl_maximum_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[43m        \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    748\u001B[0m \u001B[43m        \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    749\u001B[0m \u001B[43m        \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    750\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcert_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    751\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    752\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    753\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname_rm_dot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[43m        \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mssl_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    755\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    756\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massert_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    757\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_fingerprint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massert_fingerprint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    758\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    759\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m sock_and_verified\u001B[38;5;241m.\u001B[39msocket\n\u001B[1;32m    761\u001B[0m \u001B[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001B[39;00m\n\u001B[1;32m    762\u001B[0m \u001B[38;5;66;03m# our lock so another connection can probe the origin.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/connection.py:920\u001B[0m, in \u001B[0;36m_ssl_wrap_socket_and_match_hostname\u001B[0;34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001B[0m\n\u001B[1;32m    917\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_ipaddress(normalized):\n\u001B[1;32m    918\u001B[0m         server_hostname \u001B[38;5;241m=\u001B[39m normalized\n\u001B[0;32m--> 920\u001B[0m ssl_sock \u001B[38;5;241m=\u001B[39m \u001B[43mssl_wrap_socket\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    921\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    922\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeyfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    923\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcertfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    924\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    931\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m assert_fingerprint:\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:460\u001B[0m, in \u001B[0;36mssl_wrap_socket\u001B[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001B[0m\n\u001B[1;32m    456\u001B[0m         context\u001B[38;5;241m.\u001B[39mload_cert_chain(certfile, keyfile, key_password)\n\u001B[1;32m    458\u001B[0m context\u001B[38;5;241m.\u001B[39mset_alpn_protocols(ALPN_PROTOCOLS)\n\u001B[0;32m--> 460\u001B[0m ssl_sock \u001B[38;5;241m=\u001B[39m \u001B[43m_ssl_wrap_socket_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtls_in_tls\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ssl_sock\n",
      "File \u001B[0;32m~/Documents/python-projects/oracle/.venv/lib/python3.12/site-packages/urllib3/util/ssl_.py:504\u001B[0m, in \u001B[0;36m_ssl_wrap_socket_impl\u001B[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001B[0m\n\u001B[1;32m    501\u001B[0m     SSLTransport\u001B[38;5;241m.\u001B[39m_validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001B[0;32m--> 504\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.12/ssl.py:455\u001B[0m, in \u001B[0;36mSSLContext.wrap_socket\u001B[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[1;32m    449\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrap_socket\u001B[39m(\u001B[38;5;28mself\u001B[39m, sock, server_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    450\u001B[0m                 do_handshake_on_connect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    451\u001B[0m                 suppress_ragged_eofs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    452\u001B[0m                 server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001B[39;00m\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;66;03m# ctx._wrap_socket()\u001B[39;00m\n\u001B[0;32m--> 455\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msslsocket_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.12/ssl.py:1042\u001B[0m, in \u001B[0;36mSSLSocket._create\u001B[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[1;32m   1039\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[1;32m   1040\u001B[0m                 \u001B[38;5;66;03m# non-blocking\u001B[39;00m\n\u001B[1;32m   1041\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1042\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m   1044\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/usr/lib/python3.12/ssl.py:1320\u001B[0m, in \u001B[0;36mSSLSocket.do_handshake\u001B[0;34m(self, block)\u001B[0m\n\u001B[1;32m   1318\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0.0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m block:\n\u001B[1;32m   1319\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1320\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1321\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m   1322\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(timeout)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T19:07:08.571155Z",
     "start_time": "2025-01-10T19:07:08.528090Z"
    }
   },
   "cell_type": "code",
   "source": "urls = [x['web_url'] for x in result.json()['response']['docs']]\n",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-10T19:07:08.832919Z",
     "start_time": "2025-01-10T19:07:08.831153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, url in enumerate(urls[:20]):\n",
    "    print(i, url)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 https://dealbook.nytimes.com/2006/06/21/facebook-and-that-2-billion/\n",
      "1 https://www.nytimes.com/1970/01/01/archives/hail-and-farewell.html\n",
      "2 https://www.nytimes.com/1970/01/01/archives/front-page-2-no-title.html\n",
      "3 https://www.nytimes.com/1970/01/01/archives/mississippi-adds-3-negroes-to-storm-relief-unit-governor-moves-to.html\n",
      "4 https://www.nytimes.com/1970/01/01/archives/icc-aide-is-named-as-acting-chairman.html\n",
      "5 https://www.nytimes.com/1970/01/01/archives/letters-to-the-editor-of-the-times.html\n",
      "6 https://www.nytimes.com/1970/01/01/archives/traffic-snarled-by-freezing-rain-road-and-rail-facilities-are.html\n",
      "7 https://www.nytimes.com/1970/01/01/archives/business-tax-bills-signed-by-shafer.html\n",
      "8 https://www.nytimes.com/1970/01/01/archives/article-4-no-title.html\n",
      "9 https://www.nytimes.com/1970/01/01/archives/cigarette-maker-loses-courtr-test-set-back-in-dispute-over-tv.html\n",
      "10 https://www.nytimes.com/1970/01/01/archives/builder-is-accused-of-perjury-in-cityplanning-bribery-case.html\n",
      "11 https://www.nytimes.com/1970/01/01/archives/quradrille-ball-funds-to-go-to-2-groups.html\n",
      "12 https://www.nytimes.com/1970/01/01/archives/hawks-defeat-bullets.html\n",
      "13 https://www.nytimes.com/1970/01/01/archives/few-us-blacks-migrate.html\n",
      "14 https://www.nytimes.com/1970/01/01/archives/dr-theodor-reik-freud-protege-is-dead-at-81-analyst-was-stanch.html\n",
      "15 https://www.nytimes.com/1970/01/01/archives/janice-winterling.html\n",
      "16 https://www.nytimes.com/1970/01/01/archives/richard-frankenfelder-beauty-chain-executive.html\n",
      "17 https://www.nytimes.com/1970/01/01/archives/lee-shippey-wrote-california-column.html\n",
      "18 https://www.nytimes.com/1970/01/01/archives/queens-honors-list-changes-name-on-the-marquee-to-sir-noel-coward.html\n",
      "19 https://www.nytimes.com/1970/01/01/archives/in-the-nation-the-devil-and-dean-rusk.html\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-17T07:17:11.711867Z",
     "start_time": "2025-01-17T07:17:11.696652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def key_padding_mask_to_attention_mask(key_padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convert a key_padding_mask of shape (B, S) to an attention_mask of shape (B, S, S).\n",
    "\n",
    "    Args:\n",
    "        key_padding_mask: Boolean tensor of shape (B, S) where True indicates padding tokens\n",
    "                         and False indicates actual tokens.\n",
    "\n",
    "    Returns:\n",
    "        attention_mask: Boolean tensor of shape (B, S, S) where False indicates allowed\n",
    "                       attention and True indicates masked (blocked) attention.\n",
    "    \"\"\"\n",
    "    batch_size, seq_len = key_padding_mask.size()\n",
    "\n",
    "    # First, we need to convert the key_padding_mask to the right shape\n",
    "    # We want each position to not attend to padding tokens\n",
    "    # So we expand the key_padding_mask to (B, 1, S) and broadcast it to (B, S, S)\n",
    "    expanded_mask = key_padding_mask.unsqueeze(1).expand(batch_size, seq_len, seq_len)\n",
    "\n",
    "    # The attention_mask should be False (1) where we want to allow attention\n",
    "    # and True (0) where we want to block it\n",
    "    attention_mask = expanded_mask\n",
    "\n",
    "    return attention_mask\n",
    "\n",
    "def fix_fully_masked_rows(attn_mask_3d: torch.Tensor, key_padding_mask: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    For any row b where key_padding_mask[b] is all True (i.e., fully masked),\n",
    "    replace that entire (L, L) block in attn_mask_3d with ~torch.eye(L).\n",
    "    This makes each token attend only to itself, preventing NaNs.\n",
    "    \"\"\"\n",
    "    B, L, _ = attn_mask_3d.shape\n",
    "    print(\"DEBUGGING FIX FULLY MASKED ROWS\")\n",
    "    print(attn_mask_3d)\n",
    "    print(key_padding_mask)\n",
    "    fully_masked_rows = key_padding_mask.all(dim=1)  # shape (B,)\n",
    "    print(fully_masked_rows)\n",
    "\n",
    "    attn_mask_3d[fully_masked_rows] = ~torch.eye(L, L, dtype=torch.bool, device=attn_mask_3d.device)\n",
    "    print(attn_mask_3d)\n",
    "    print(\"END DEBUGGING FIX FULLY MASKED ROWS\")\n",
    "    return attn_mask_3d\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, embed_dim=4, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.proj = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x, key_padding_mask):\n",
    "        \"\"\"\n",
    "        x:              Tensor of shape (B, L, E)\n",
    "        key_padding_mask: shape (B, L), where True indicates \"ignore\" that token.\n",
    "        \"\"\"\n",
    "        B, L, E = x.shape\n",
    "        print(\"x:\", x)\n",
    "        print(\"key_padding_mask:\", key_padding_mask)\n",
    "        # 1) Build an initial (B, L, L) attn_mask from key_padding_mask\n",
    "        attn_mask_3d = key_padding_mask_to_attention_mask(key_padding_mask).contiguous()\n",
    "\n",
    "        # 2) Replace fully-masked rows with the identity diagonal trick\n",
    "        attn_mask_3d = fix_fully_masked_rows(attn_mask_3d, key_padding_mask)\n",
    "\n",
    "        # 3) Forward pass with attn_mask only (no separate key_padding_mask!)\n",
    "        attn_out, _ = self.attn(\n",
    "            x, x, x,\n",
    "            attn_mask=attn_mask_3d\n",
    "        )\n",
    "\n",
    "        # 4) Zero out entire batch rows that are fully masked.\n",
    "        fully_masked_rows = key_padding_mask.all(dim=1)\n",
    "        print(\"Fully masked rows:\", fully_masked_rows)\n",
    "        attn_out[fully_masked_rows] = 0.0\n",
    "\n",
    "        # 5) Projection -> scalar\n",
    "        out = self.proj(attn_out).view(B, L)  # shape (B, L)\n",
    "        print(out)\n",
    "        print(~fully_masked_rows.unsqueeze(-1).expand(B, L))\n",
    "        # average for non masked elements\n",
    "        out_filtered = out * (~fully_masked_rows.unsqueeze(-1).expand(B, L))\n",
    "        return out_filtered.sum() / (~fully_masked_rows.unsqueeze(-1).expand(B, L)).sum()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# DEMO: B=2, second row fully masked\n",
    "# -----------------------------------------------------------------------\n",
    "print(\"==== Test 1: B=2, second row fully masked ====\")\n",
    "model = SimpleModel(embed_dim=4, num_heads=1)\n",
    "\n",
    "x = torch.randn(2, 5, 4, requires_grad=True)\n",
    "x2 = x.clone().detach()\n",
    "x2.requires_grad = True\n",
    "\n",
    "padding_mask = torch.zeros(2, 5, dtype=torch.bool)\n",
    "padding_mask[1, :] = True  # fully mask the second row\n",
    "\n",
    "# -- Forward/backward pass #1 --\n",
    "out = model(x, padding_mask)\n",
    "print(\"Forward output #1:\", out.item())\n",
    "out.backward()\n",
    "\n",
    "# Store gradients after the first pass\n",
    "grads_pass1 = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        grads_pass1[name] = param.grad.clone().detach()\n",
    "\n",
    "# Clear gradients\n",
    "model.zero_grad()\n",
    "\n",
    "# -----------------------------------------------------------------------\n",
    "# DEMO: B=1, single row fully masked\n",
    "# -----------------------------------------------------------------------\n",
    "print(\"\\n==== Test 2: B=1, single row fully masked ====\")\n",
    "x_single = x2[:1, :, :]  # (2, 5, 4) => (1, 5, 4)\n",
    "padding_mask_single = torch.zeros(1, 5, dtype=torch.bool)  # all True => fully masked\n",
    "\n",
    "# -- Forward/backward #1 --\n",
    "out_single_1 = model(x_single, padding_mask_single)\n",
    "print(\"Forward output #2:\", out_single_1.item())\n",
    "out_single_1.backward()\n",
    "\n",
    "# Grab gradients from pass #1\n",
    "grads_pass2 = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.grad is not None:\n",
    "        grads_pass2[name] = param.grad.clone().detach()\n",
    "\n",
    "model.zero_grad()\n",
    "# Compare\n",
    "for name in grads_pass2:\n",
    "    print(f\"Param: {name}\")\n",
    "    print(f\"  Grad pass1 norm = {grads_pass2[name].norm(2).item():.4f}\")\n",
    "    print(f\"  Grad pass2 norm = {grads_pass1[name].norm(2).item():.4f}\")\n",
    "    # Check for NaNs\n",
    "    if torch.isnan(grads_pass2[name]).any() or torch.isnan(grads_pass2[name]).any():\n",
    "        print(\"    --> Found NaN in gradients!\\n\")\n",
    "\n",
    "print(\"\\nDone! We expect no NaNs and no errors in backward.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Test 1: B=2, second row fully masked ====\n",
      "x: tensor([[[ 2.0820,  1.7067,  2.3804, -1.1256],\n",
      "         [-0.3170, -1.0925, -0.0852, -0.0933],\n",
      "         [-0.7607, -1.5991,  0.0185, -0.7504],\n",
      "         [ 0.1854,  0.6211,  0.6382, -0.2460],\n",
      "         [-0.5344,  1.1687,  0.3945,  1.9415]],\n",
      "\n",
      "        [[ 0.7915, -0.0203, -0.4372,  1.6459],\n",
      "         [-2.4351, -0.0729, -0.0340,  0.9625],\n",
      "         [ 0.3492, -0.9215, -0.0562, -0.7015],\n",
      "         [-0.4637,  1.9218, -0.4025,  0.1239],\n",
      "         [ 1.1648,  0.9234,  1.3873,  1.3750]]], requires_grad=True)\n",
      "key_padding_mask: tensor([[False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True]])\n",
      "DEBUGGING FIX FULLY MASKED ROWS\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "tensor([[False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True]])\n",
      "tensor([False,  True])\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]],\n",
      "\n",
      "        [[False,  True,  True,  True,  True],\n",
      "         [ True, False,  True,  True,  True],\n",
      "         [ True,  True, False,  True,  True],\n",
      "         [ True,  True,  True, False,  True],\n",
      "         [ True,  True,  True,  True, False]]])\n",
      "END DEBUGGING FIX FULLY MASKED ROWS\n",
      "Fully masked rows: tensor([False,  True])\n",
      "tensor([[0.1339, 0.1816, 0.2195, 0.1721, 0.0966],\n",
      "        [0.1965, 0.1965, 0.1965, 0.1965, 0.1965]], grad_fn=<ViewBackward0>)\n",
      "tensor([[ True,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False]])\n",
      "Forward output #1: 0.16074633598327637\n",
      "\n",
      "==== Test 2: B=1, single row fully masked ====\n",
      "x: tensor([[[ 2.0820,  1.7067,  2.3804, -1.1256],\n",
      "         [-0.3170, -1.0925, -0.0852, -0.0933],\n",
      "         [-0.7607, -1.5991,  0.0185, -0.7504],\n",
      "         [ 0.1854,  0.6211,  0.6382, -0.2460],\n",
      "         [-0.5344,  1.1687,  0.3945,  1.9415]]], grad_fn=<SliceBackward0>)\n",
      "key_padding_mask: tensor([[False, False, False, False, False]])\n",
      "DEBUGGING FIX FULLY MASKED ROWS\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]]])\n",
      "tensor([[False, False, False, False, False]])\n",
      "tensor([False])\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]]])\n",
      "END DEBUGGING FIX FULLY MASKED ROWS\n",
      "Fully masked rows: tensor([False])\n",
      "tensor([[0.1339, 0.1816, 0.2195, 0.1721, 0.0966]], grad_fn=<ViewBackward0>)\n",
      "tensor([[True, True, True, True, True]])\n",
      "Forward output #2: 0.16074633598327637\n",
      "Param: attn.in_proj_weight\n",
      "  Grad pass1 norm = 0.1947\n",
      "  Grad pass2 norm = 0.1947\n",
      "Param: attn.in_proj_bias\n",
      "  Grad pass1 norm = 0.2065\n",
      "  Grad pass2 norm = 0.2065\n",
      "Param: attn.out_proj.weight\n",
      "  Grad pass1 norm = 0.4617\n",
      "  Grad pass2 norm = 0.4617\n",
      "Param: attn.out_proj.bias\n",
      "  Grad pass1 norm = 0.7133\n",
      "  Grad pass2 norm = 0.7133\n",
      "Param: proj.weight\n",
      "  Grad pass1 norm = 0.1528\n",
      "  Grad pass2 norm = 0.1528\n",
      "Param: proj.bias\n",
      "  Grad pass1 norm = 1.0000\n",
      "  Grad pass2 norm = 1.0000\n",
      "\n",
      "Done! We expect no NaNs and no errors in backward.\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
